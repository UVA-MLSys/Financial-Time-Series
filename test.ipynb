{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4951734-048e-4eb6-8a20-77775d9b94f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from run import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec6b8e20-baf6-40c0-896b-9a9858f968b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_content(args):\n",
    "    df = pd.read_csv(os.path.join(args.root_path, 'prompt_bank.csv'))\n",
    "    data_name = args.data_path.split('.')[0] \n",
    "    content = df[df['data']==data_name]['prompt'].values[0]\n",
    "    return content\n",
    "            \n",
    "def get_parser():\n",
    "\n",
    "    parser = get_basic_parser(\"TimeLLM\")\n",
    "\n",
    "    parser.add_argument(\n",
    "        '--model_id', default='ori', choices=['ori', 'removeLLM', \n",
    "        'randomInit', 'llm_to_trsf', 'llm_to_attn']\n",
    "    )\n",
    "    parser.add_argument('--model', type=str, default='TimeLLM', choices=['TimeLLM'])\n",
    "    \n",
    "    parser.add_argument('--patch_len', type=int, default=16, help='patch length')\n",
    "    parser.add_argument('--stride', type=int, default=8, help='stride')\n",
    "    parser.add_argument('--prompt_domain', type=int, default=1, help='')\n",
    "    parser.add_argument(\n",
    "        '--llm_model', type=str, default='GPT2', help='LLM model',\n",
    "        choices=['LLAMA', 'GPT2', 'BERT']) # \n",
    "    parser.add_argument('--llm_dim', type=int, default='768', \n",
    "        help='LLM model dimension. LLama7b:4096; GPT2-small:768; BERT-base:768')\n",
    "    parser.add_argument('--llm_layers', type=int, default=6)\n",
    "    \n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "476d9174-db67-4404-ab65-67b6a68b2e52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "argv = \"\"\"\n",
    "--n_features 1 --d_model 16 --features S \n",
    "--data_path Financial_Aid_State.csv --group_id GROUP_ID --freq a \n",
    "--batch_size 16 --itrs 3 --disable_progress\n",
    "--seq_len 10 --label_len 5 --pred_len 1\n",
    "--model_id ori --top_k 2\n",
    "--patch_len 4 --stride 2 --target need_amt --dump_output --itr_no 1\n",
    "\"\"\".split()\n",
    "\n",
    "parser = get_parser()\n",
    "args = parser.parse_args(argv)\n",
    "args.content = load_content(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cc20608-a0c2-4c02-b5db-285c5be290b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "initial_setup(args)\n",
    "set_random_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2af7b97c-9b74-4448-811f-659af5178788",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parent_seed = args.seed\n",
    "np.random.seed(parent_seed)\n",
    "experiment_seeds = np.random.randint(1e3, size=args.itrs)\n",
    "experiment_seeds = [int(seed) for seed in experiment_seeds]\n",
    "args.experiment_seeds = experiment_seeds\n",
    "original_itr = args.itr_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "973f627b-4085-4850-95a9-ea6e4147ad6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>>> itr_no: 1, seed: 648 <<<<<<\n",
      "Use GPU: cuda:0\n",
      "description: Yearly funding Aid to each USA state to support undergraduate education.\n",
      "Experiments will be saved in results\\Financial_Aid_State\\TimeLLM_sl_10_pl_1_id_ori\\1\n",
      "\n",
      "Experiment begins at 2024-09-26 11:43:36\n",
      "\n",
      "\n",
      ">>>>>>> testing :  <<<<<<<<<<<<<<<<<<<\n",
      "Scaling data.\n",
      "test 92\n",
      "Loading model from results\\Financial_Aid_State\\TimeLLM_sl_10_pl_1_id_ori\\1\\llm.pth\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Model:\n\tsize mismatch for output_projection.linear.weight: copying a param with shape torch.Size([1, 384]) from checkpoint, the shape in current model is torch.Size([1, 640]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m exp \u001b[38;5;241m=\u001b[39m Exp_Long_Term_Forecast(args)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdump_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump_output\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Financial-Time-Series\\exp\\exp_long_term_forecasting.py:271\u001b[0m, in \u001b[0;36mExp_Long_Term_Forecast.test\u001b[1;34m(self, load_model, flag, evaluate, dump_output, remove_negative)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;66;03m# percent 0 is for zero-shot learning, no need to load model\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (load_model \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtest) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpercent \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 271\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_best_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo need to load model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32md:\\Financial-Time-Series\\exp\\exp_basic.py:99\u001b[0m, in \u001b[0;36mExp_Basic.load_best_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoading model from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_model_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel:\n\u001b[1;32m---> 99\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_model_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_model()\n",
      "File \u001b[1;32mc:\\Users\\khair\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1671\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1666\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   1667\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1668\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[0;32m   1670\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1671\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1672\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   1673\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Model:\n\tsize mismatch for output_projection.linear.weight: copying a param with shape torch.Size([1, 384]) from checkpoint, the shape in current model is torch.Size([1, 640])."
     ]
    }
   ],
   "source": [
    "itr_no = args.itr_no\n",
    "            \n",
    "args.seed = experiment_seeds[itr_no-1]\n",
    "print(f'\\n>>>> itr_no: {itr_no}, seed: {args.seed} <<<<<<')\n",
    "set_random_seed(args.seed)\n",
    "args.itr_no = itr_no\n",
    "\n",
    "exp = Exp_Long_Term_Forecast(args)\n",
    "\n",
    "print('\\n>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<')\n",
    "exp.test(flag='test', dump_output=args.dump_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c54cf34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4 * 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb48a8c3-b9b1-4331-9a17-b3c1bd710632",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data, test_loader = exp.get_data('test')\n",
    "exp.load_best_model()\n",
    "model = exp.model\n",
    "device = exp.device\n",
    "\n",
    "disable_progress = args.disable_progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22771eba-a7db-45b5-80d1-b1a428ea4440",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "trues = []\n",
    "f_dim = -1 if args.features == 'MS' else 0\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in tqdm(\n",
    "        enumerate(test_loader), desc=\"Running inference\",\n",
    "        total=len(test_loader)\n",
    "    ):\n",
    "        batch_x = batch_x.float().to(device)\n",
    "        batch_y = batch_y.float().to(device)\n",
    "\n",
    "        batch_x_mark = batch_x_mark.float().to(device)\n",
    "        batch_y_mark = batch_y_mark.float().to(device)\n",
    "\n",
    "        # decoder input\n",
    "        dec_inp = torch.zeros_like(batch_y[:, -args.pred_len:, :]).float()\n",
    "        dec_inp = torch.cat([batch_y[:, :args.label_len, :], dec_inp], dim=1).float().to(device)\n",
    "\n",
    "        if args.model == 'CALF':\n",
    "            outputs = model(batch_x)\n",
    "            outputs = outputs['outputs_time']\n",
    "        elif args.model == 'OFA':\n",
    "            outputs = model(batch_x)\n",
    "        else:\n",
    "            outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "\n",
    "            if args.output_attention: outputs = outputs[0]\n",
    "\n",
    "        outputs = outputs[:, -args.pred_len:, f_dim:].detach().cpu().numpy()\n",
    "        batch_y = batch_y[:, -args.pred_len:, f_dim:].detach().cpu().numpy()\n",
    "\n",
    "        preds.append(outputs)\n",
    "        trues.append(batch_y)\n",
    "\n",
    "# this line handles different size of batch. E.g. last batch can be < batch_size.\n",
    "preds = np.concatenate(preds, axis=0)\n",
    "trues = np.concatenate(trues, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b8f884-fb94-49d2-ba16-6dd08ebc74d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(preds.shape[0]):\n",
    "    # date = test_data.index.loc[i, 'date']\n",
    "    scaler = test_data.scaler[i]\n",
    "    preds[i] = test_data.inverse_transform(scaler, preds[i])\n",
    "    trues[i] = test_data.inverse_transform(scaler, trues[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b492ac00-ae57-473e-8fb9-069cb0667597",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Removing negatives...\")\n",
    "preds[preds<0] = 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
