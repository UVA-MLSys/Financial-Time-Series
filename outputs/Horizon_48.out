Running for model:DLinear
Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='Apple.csv', features='M', n_features=5, target='OT', freq='d', no_scale=False, seq_len=96, label_len=48, pred_len=48, top_k=5, num_kernels=6, d_model=64, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, channel_independence=1, decomp_method='moving_avg', use_norm=1, down_sampling_layers=0, down_sampling_window=1, down_sampling_method=None, seg_len=48, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, dry_run=False, percent=100, model='DLinear', use_gpu=True, enc_in=5, dec_in=5, c_out=5, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Apple/DLinear_sl_96_pl_48/1

Experiment begins at 2024-09-06 00:57:57

>>>>>>> start training :>>>>>>>>>>
train 1869
val 206
Epoch: 1 | Time: 3.85 s | Train Loss: 3.7596 Vali Loss: 1.8172
Validation loss decreased (inf --> 1.817199).  Saving model ...
Epoch: 2 | Time: 2.25 s | Train Loss: 3.1875 Vali Loss: 1.6229
Validation loss decreased (1.817199 --> 1.622857).  Saving model ...
Epoch: 3 | Time: 2.23 s | Train Loss: 3.0068 Vali Loss: 1.5735
Validation loss decreased (1.622857 --> 1.573462).  Saving model ...
Epoch: 4 | Time: 2.23 s | Train Loss: 2.9569 Vali Loss: 1.5464
Validation loss decreased (1.573462 --> 1.546373).  Saving model ...
Epoch: 5 | Time: 2.23 s | Train Loss: 2.8938 Vali Loss: 1.4917
Validation loss decreased (1.546373 --> 1.491681).  Saving model ...
Epoch: 6 | Time: 2.23 s | Train Loss: 2.8295 Vali Loss: 1.4494
Validation loss decreased (1.491681 --> 1.449412).  Saving model ...
Epoch: 7 | Time: 2.23 s | Train Loss: 2.8151 Vali Loss: 1.4003
Validation loss decreased (1.449412 --> 1.400273).  Saving model ...
Epoch: 8 | Time: 2.23 s | Train Loss: 2.8056 Vali Loss: 1.3968
Validation loss decreased (1.400273 --> 1.396825).  Saving model ...
Epoch: 9 | Time: 2.23 s | Train Loss: 2.7778 Vali Loss: 1.4152
EarlyStopping counter: 1 out of 3
Epoch: 10 | Time: 2.23 s | Train Loss: 2.7796 Vali Loss: 1.4041
EarlyStopping counter: 2 out of 3

Training completed at 2024-09-06 00:58:24.
Model parameters: 9312
Total memory: 7967.4 MB
Allocated memory: 16.5 MB
Max allocated memory: 17.0 MB
Time per epoch: 2.7 sec.
Memory usage: Available 7967.4 MB, Allocated 16.5 MB, Max allocated 17.0 MB

Loading model from results/Apple/DLinear_sl_96_pl_48/1/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 204
Preds and Trues shape: (204, 48, 5) (204, 48, 5)
test scaled -- mse:3.3564, mae:1.4253
Upscaling data and removing negatives...
test -- mse:1.9509e+14, mae:4.1554e+06, rmsle: 0.19616 smape 11.372


>>>> itr_no: 2, seed: 506 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Apple/DLinear_sl_96_pl_48/2

Experiment begins at 2024-09-06 00:58:24

>>>>>>> start training :>>>>>>>>>>
train 1869
val 206
Epoch: 1 | Time: 2.2 s | Train Loss: 3.8316 Vali Loss: 1.8436
Validation loss decreased (inf --> 1.843578).  Saving model ...
Epoch: 2 | Time: 2.24 s | Train Loss: 3.1938 Vali Loss: 1.6579
Validation loss decreased (1.843578 --> 1.657898).  Saving model ...
Epoch: 3 | Time: 2.24 s | Train Loss: 3.0262 Vali Loss: 1.5779
Validation loss decreased (1.657898 --> 1.577925).  Saving model ...
Epoch: 4 | Time: 2.26 s | Train Loss: 2.9386 Vali Loss: 1.5127
Validation loss decreased (1.577925 --> 1.512737).  Saving model ...
Epoch: 5 | Time: 2.24 s | Train Loss: 2.8893 Vali Loss: 1.4757
Validation loss decreased (1.512737 --> 1.475710).  Saving model ...
Epoch: 6 | Time: 2.25 s | Train Loss: 2.8475 Vali Loss: 1.4684
Validation loss decreased (1.475710 --> 1.468415).  Saving model ...
Epoch: 7 | Time: 2.25 s | Train Loss: 2.8286 Vali Loss: 1.424
Validation loss decreased (1.468415 --> 1.423950).  Saving model ...
Epoch: 8 | Time: 2.26 s | Train Loss: 2.8003 Vali Loss: 1.3907
Validation loss decreased (1.423950 --> 1.390734).  Saving model ...
Epoch: 9 | Time: 2.23 s | Train Loss: 2.7818 Vali Loss: 1.3741
Validation loss decreased (1.390734 --> 1.374112).  Saving model ...
Epoch: 10 | Time: 2.23 s | Train Loss: 2.7686 Vali Loss: 1.384
EarlyStopping counter: 1 out of 3

Training completed at 2024-09-06 00:58:48.
Model parameters: 9312
Total memory: 7967.4 MB
Allocated memory: 16.5 MB
Max allocated memory: 17.0 MB
Time per epoch: 2.4 sec.
Memory usage: Available 7967.4 MB, Allocated 16.5 MB, Max allocated 17.0 MB

Loading model from results/Apple/DLinear_sl_96_pl_48/2/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 204
Preds and Trues shape: (204, 48, 5) (204, 48, 5)
test scaled -- mse:3.2271, mae:1.3912
Upscaling data and removing negatives...
test -- mse:1.9761e+14, mae:4.1719e+06, rmsle: 0.19627 smape 11.228


>>>> itr_no: 3, seed: 608 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Apple/DLinear_sl_96_pl_48/3

Experiment begins at 2024-09-06 00:58:49

>>>>>>> start training :>>>>>>>>>>
train 1869
val 206
Epoch: 1 | Time: 2.21 s | Train Loss: 3.7447 Vali Loss: 1.806
Validation loss decreased (inf --> 1.806045).  Saving model ...
Epoch: 2 | Time: 2.23 s | Train Loss: 3.1678 Vali Loss: 1.6512
Validation loss decreased (1.806045 --> 1.651162).  Saving model ...
Epoch: 3 | Time: 2.23 s | Train Loss: 3.0111 Vali Loss: 1.5489
Validation loss decreased (1.651162 --> 1.548876).  Saving model ...
Epoch: 4 | Time: 2.23 s | Train Loss: 2.9469 Vali Loss: 1.5026
Validation loss decreased (1.548876 --> 1.502635).  Saving model ...
Epoch: 5 | Time: 2.24 s | Train Loss: 2.8871 Vali Loss: 1.4672
Validation loss decreased (1.502635 --> 1.467155).  Saving model ...
Epoch: 6 | Time: 2.23 s | Train Loss: 2.8375 Vali Loss: 1.4623
Validation loss decreased (1.467155 --> 1.462300).  Saving model ...
Epoch: 7 | Time: 2.23 s | Train Loss: 2.8413 Vali Loss: 1.3934
Validation loss decreased (1.462300 --> 1.393426).  Saving model ...
Epoch: 8 | Time: 2.23 s | Train Loss: 2.811 Vali Loss: 1.4119
EarlyStopping counter: 1 out of 3
Epoch: 9 | Time: 2.23 s | Train Loss: 2.7964 Vali Loss: 1.4041
EarlyStopping counter: 2 out of 3
Epoch: 10 | Time: 2.23 s | Train Loss: 2.7499 Vali Loss: 1.3997
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 00:59:12.
Model parameters: 9312
Total memory: 7967.4 MB
Allocated memory: 16.5 MB
Max allocated memory: 17.0 MB
Time per epoch: 2.4 sec.
Memory usage: Available 7967.4 MB, Allocated 16.5 MB, Max allocated 17.0 MB

Loading model from results/Apple/DLinear_sl_96_pl_48/3/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 204
Preds and Trues shape: (204, 48, 5) (204, 48, 5)
test scaled -- mse:3.1385, mae:1.3727
Upscaling data and removing negatives...
test -- mse:1.9105e+14, mae:4.0941e+06, rmsle: 0.19342 smape 11.082

Running for model:PatchTST
Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='Apple.csv', features='M', n_features=5, target='OT', freq='d', no_scale=False, seq_len=96, label_len=48, pred_len=48, top_k=5, num_kernels=6, d_model=64, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, channel_independence=1, decomp_method='moving_avg', use_norm=1, down_sampling_layers=0, down_sampling_window=1, down_sampling_method=None, seg_len=48, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, dry_run=False, percent=100, model='PatchTST', use_gpu=True, enc_in=5, dec_in=5, c_out=5, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Apple/PatchTST_sl_96_pl_48/1

Experiment begins at 2024-09-06 00:59:27

>>>>>>> start training :>>>>>>>>>>
train 1869
val 206
Epoch: 1 | Time: 10 s | Train Loss: 3.2143 Vali Loss: 1.7501
Validation loss decreased (inf --> 1.750148).  Saving model ...
Epoch: 2 | Time: 2.66 s | Train Loss: 2.7023 Vali Loss: 1.5129
Validation loss decreased (1.750148 --> 1.512865).  Saving model ...
Epoch: 3 | Time: 2.67 s | Train Loss: 2.4323 Vali Loss: 1.6247
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 2.66 s | Train Loss: 2.2285 Vali Loss: 1.6849
EarlyStopping counter: 2 out of 3
Epoch: 5 | Time: 2.67 s | Train Loss: 1.9923 Vali Loss: 1.6353
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 00:59:49.
Model parameters: 105008
Total memory: 7967.4 MB
Allocated memory: 19.2 MB
Max allocated memory: 169.0 MB
Time per epoch: 4.4 sec.
Memory usage: Available 7967.4 MB, Allocated 19.2 MB, Max allocated 169.0 MB

Loading model from results/Apple/PatchTST_sl_96_pl_48/1/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 204
Preds and Trues shape: (204, 48, 5) (204, 48, 5)
test scaled -- mse:4.1354, mae:1.5474
Upscaling data and removing negatives...
test -- mse:1.7421e+14, mae:3.5693e+06, rmsle: 0.19301 smape 11.413


>>>> itr_no: 2, seed: 506 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Apple/PatchTST_sl_96_pl_48/2

Experiment begins at 2024-09-06 00:59:49

>>>>>>> start training :>>>>>>>>>>
train 1869
val 206
Epoch: 1 | Time: 2.65 s | Train Loss: 3.2709 Vali Loss: 1.583
Validation loss decreased (inf --> 1.582988).  Saving model ...
Epoch: 2 | Time: 2.69 s | Train Loss: 2.7481 Vali Loss: 1.594
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 2.67 s | Train Loss: 2.5008 Vali Loss: 1.6858
EarlyStopping counter: 2 out of 3
Epoch: 4 | Time: 2.68 s | Train Loss: 2.3107 Vali Loss: 1.7923
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:00:00.
Model parameters: 105008
Total memory: 7967.4 MB
Allocated memory: 19.2 MB
Max allocated memory: 169.0 MB
Time per epoch: 2.8 sec.
Memory usage: Available 7967.4 MB, Allocated 19.2 MB, Max allocated 169.0 MB

Loading model from results/Apple/PatchTST_sl_96_pl_48/2/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 204
Preds and Trues shape: (204, 48, 5) (204, 48, 5)
test scaled -- mse:2.9713, mae:1.3285
Upscaling data and removing negatives...
test -- mse:2.0971e+14, mae:4.1885e+06, rmsle: 0.20511 smape 11.133


>>>> itr_no: 3, seed: 608 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Apple/PatchTST_sl_96_pl_48/3

Experiment begins at 2024-09-06 01:00:01

>>>>>>> start training :>>>>>>>>>>
train 1869
val 206
Epoch: 1 | Time: 2.67 s | Train Loss: 3.3281 Vali Loss: 1.9789
Validation loss decreased (inf --> 1.978857).  Saving model ...
Epoch: 2 | Time: 2.67 s | Train Loss: 2.8719 Vali Loss: 1.6164
Validation loss decreased (1.978857 --> 1.616443).  Saving model ...
Epoch: 3 | Time: 2.68 s | Train Loss: 2.6035 Vali Loss: 1.9235
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 2.67 s | Train Loss: 2.3188 Vali Loss: 1.8831
EarlyStopping counter: 2 out of 3
Epoch: 5 | Time: 2.7 s | Train Loss: 2.0639 Vali Loss: 1.5608
Validation loss decreased (1.616443 --> 1.560804).  Saving model ...
Epoch: 6 | Time: 2.68 s | Train Loss: 1.975 Vali Loss: 1.5481
Validation loss decreased (1.560804 --> 1.548091).  Saving model ...
Epoch: 7 | Time: 2.68 s | Train Loss: 1.9679 Vali Loss: 1.5844
EarlyStopping counter: 1 out of 3
Epoch: 8 | Time: 2.7 s | Train Loss: 1.9466 Vali Loss: 1.5718
EarlyStopping counter: 2 out of 3
Epoch: 9 | Time: 2.67 s | Train Loss: 1.9235 Vali Loss: 1.5519
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:00:26.
Model parameters: 105008
Total memory: 7967.4 MB
Allocated memory: 19.2 MB
Max allocated memory: 169.0 MB
Time per epoch: 2.8 sec.
Memory usage: Available 7967.4 MB, Allocated 19.2 MB, Max allocated 169.0 MB

Loading model from results/Apple/PatchTST_sl_96_pl_48/3/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 204
Preds and Trues shape: (204, 48, 5) (204, 48, 5)
test scaled -- mse:4.8588, mae:1.6651
Upscaling data and removing negatives...
test -- mse:1.6832e+14, mae:3.632e+06, rmsle: 0.20215 smape 12.096

Running for model:TimesNet
Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='Apple.csv', features='M', n_features=5, target='OT', freq='d', no_scale=False, seq_len=96, label_len=48, pred_len=48, top_k=5, num_kernels=6, d_model=64, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, channel_independence=1, decomp_method='moving_avg', use_norm=1, down_sampling_layers=0, down_sampling_window=1, down_sampling_method=None, seg_len=48, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, dry_run=False, percent=100, model='TimesNet', use_gpu=True, enc_in=5, dec_in=5, c_out=5, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Apple/TimesNet_sl_96_pl_48/1

Experiment begins at 2024-09-06 01:00:33

>>>>>>> start training :>>>>>>>>>>
train 1869
val 206
Epoch: 1 | Time: 36.2 s | Train Loss: 3.2224 Vali Loss: 2.3434
Validation loss decreased (inf --> 2.343395).  Saving model ...
Epoch: 2 | Time: 31.7 s | Train Loss: 2.4665 Vali Loss: 2.3731
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 33.4 s | Train Loss: 2.213 Vali Loss: 2.6149
EarlyStopping counter: 2 out of 3
Epoch: 4 | Time: 31.9 s | Train Loss: 1.8746 Vali Loss: 2.0678
Validation loss decreased (2.343395 --> 2.067765).  Saving model ...
Epoch: 5 | Time: 31 s | Train Loss: 1.669 Vali Loss: 2.1047
EarlyStopping counter: 1 out of 3
Epoch: 6 | Time: 31.1 s | Train Loss: 1.5919 Vali Loss: 2.1731
EarlyStopping counter: 2 out of 3
Epoch: 7 | Time: 31 s | Train Loss: 1.537 Vali Loss: 2.1769
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:04:22.
Model parameters: 9389525
Total memory: 7967.4 MB
Allocated memory: 170.0 MB
Max allocated memory: 1780.9 MB
Time per epoch: 32.7 sec.
Memory usage: Available 7967.4 MB, Allocated 170.0 MB, Max allocated 1780.9 MB

Loading model from results/Apple/TimesNet_sl_96_pl_48/1/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 204
Preds and Trues shape: (204, 48, 5) (204, 48, 5)
test scaled -- mse:3.9161, mae:1.5309
Upscaling data and removing negatives...
test -- mse:1.5351e+14, mae:3.1239e+06, rmsle: 0.17438 smape 10.735


>>>> itr_no: 2, seed: 506 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Apple/TimesNet_sl_96_pl_48/2

Experiment begins at 2024-09-06 01:04:26

>>>>>>> start training :>>>>>>>>>>
train 1869
val 206
Epoch: 1 | Time: 29.7 s | Train Loss: 3.1889 Vali Loss: 2.0562
Validation loss decreased (inf --> 2.056215).  Saving model ...
Epoch: 2 | Time: 28 s | Train Loss: 2.5029 Vali Loss: 2.1577
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 29.2 s | Train Loss: 2.0593 Vali Loss: 2.0239
Validation loss decreased (2.056215 --> 2.023878).  Saving model ...
Epoch: 4 | Time: 29.2 s | Train Loss: 1.6938 Vali Loss: 2.255
EarlyStopping counter: 1 out of 3
Epoch: 5 | Time: 27.3 s | Train Loss: 1.4662 Vali Loss: 2.2388
EarlyStopping counter: 2 out of 3
Epoch: 6 | Time: 26.9 s | Train Loss: 1.1779 Vali Loss: 2.2356
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:07:18.
Model parameters: 9389525
Total memory: 7967.4 MB
Allocated memory: 169.1 MB
Max allocated memory: 1783.0 MB
Time per epoch: 28.6 sec.
Memory usage: Available 7967.4 MB, Allocated 169.1 MB, Max allocated 1783.0 MB

Loading model from results/Apple/TimesNet_sl_96_pl_48/2/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 204
Preds and Trues shape: (204, 48, 5) (204, 48, 5)
test scaled -- mse:4.2932, mae:1.5919
Upscaling data and removing negatives...
test -- mse:1.563e+14, mae:3.1833e+06, rmsle: 0.17894 smape 11.13


>>>> itr_no: 3, seed: 608 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Apple/TimesNet_sl_96_pl_48/3

Experiment begins at 2024-09-06 01:07:20

>>>>>>> start training :>>>>>>>>>>
train 1869
val 206
Epoch: 1 | Time: 25.7 s | Train Loss: 3.4287 Vali Loss: 3.0134
Validation loss decreased (inf --> 3.013450).  Saving model ...
Epoch: 2 | Time: 25.5 s | Train Loss: 2.8229 Vali Loss: 2.8287
Validation loss decreased (3.013450 --> 2.828707).  Saving model ...
Epoch: 3 | Time: 25.1 s | Train Loss: 2.2972 Vali Loss: 2.426
Validation loss decreased (2.828707 --> 2.425952).  Saving model ...
Epoch: 4 | Time: 25.2 s | Train Loss: 1.7527 Vali Loss: 1.907
Validation loss decreased (2.425952 --> 1.906984).  Saving model ...
Epoch: 5 | Time: 25.2 s | Train Loss: 1.3715 Vali Loss: 2.3904
EarlyStopping counter: 1 out of 3
Epoch: 6 | Time: 25.1 s | Train Loss: 1.206 Vali Loss: 3.0106
EarlyStopping counter: 2 out of 3
Epoch: 7 | Time: 25 s | Train Loss: 0.94598 Vali Loss: 2.3777
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:10:19.
Model parameters: 9389525
Total memory: 7967.4 MB
Allocated memory: 172.3 MB
Max allocated memory: 1785.0 MB
Time per epoch: 25.6 sec.
Memory usage: Available 7967.4 MB, Allocated 172.3 MB, Max allocated 1785.0 MB

Loading model from results/Apple/TimesNet_sl_96_pl_48/3/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 204
Preds and Trues shape: (204, 48, 5) (204, 48, 5)
test scaled -- mse:4.525, mae:1.6235
Upscaling data and removing negatives...
test -- mse:1.5929e+14, mae:3.1434e+06, rmsle: 0.17979 smape 11.109

Running for model:iTransformer
Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='Apple.csv', features='M', n_features=5, target='OT', freq='d', no_scale=False, seq_len=96, label_len=48, pred_len=48, top_k=5, num_kernels=6, d_model=64, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, channel_independence=1, decomp_method='moving_avg', use_norm=1, down_sampling_layers=0, down_sampling_window=1, down_sampling_method=None, seg_len=48, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, dry_run=False, percent=100, model='iTransformer', use_gpu=True, enc_in=5, dec_in=5, c_out=5, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Apple/iTransformer_sl_96_pl_48/1

Experiment begins at 2024-09-06 01:10:28

>>>>>>> start training :>>>>>>>>>>
train 1869
val 206
Epoch: 1 | Time: 2.89 s | Train Loss: 3.4326 Vali Loss: 1.5962
Validation loss decreased (inf --> 1.596173).  Saving model ...
Epoch: 2 | Time: 2.59 s | Train Loss: 2.5916 Vali Loss: 1.4804
Validation loss decreased (1.596173 --> 1.480356).  Saving model ...
Epoch: 3 | Time: 2.58 s | Train Loss: 2.1233 Vali Loss: 1.5526
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 2.61 s | Train Loss: 1.7693 Vali Loss: 1.7543
EarlyStopping counter: 2 out of 3
Epoch: 5 | Time: 2.6 s | Train Loss: 1.5453 Vali Loss: 1.7892
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:10:42.
Model parameters: 76400
Total memory: 7967.4 MB
Allocated memory: 17.6 MB
Max allocated memory: 147.6 MB
Time per epoch: 2.9 sec.
Memory usage: Available 7967.4 MB, Allocated 17.6 MB, Max allocated 147.6 MB

Loading model from results/Apple/iTransformer_sl_96_pl_48/1/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 204
Preds and Trues shape: (204, 48, 5) (204, 48, 5)
test scaled -- mse:4.0797, mae:1.6002
Upscaling data and removing negatives...
test -- mse:2.0532e+14, mae:4.3883e+06, rmsle: 0.22764 smape 12.978


>>>> itr_no: 2, seed: 506 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Apple/iTransformer_sl_96_pl_48/2

Experiment begins at 2024-09-06 01:10:43

>>>>>>> start training :>>>>>>>>>>
train 1869
val 206
Epoch: 1 | Time: 2.63 s | Train Loss: 3.4001 Vali Loss: 1.5525
Validation loss decreased (inf --> 1.552529).  Saving model ...
Epoch: 2 | Time: 2.63 s | Train Loss: 2.5305 Vali Loss: 1.5686
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 2.62 s | Train Loss: 2.1292 Vali Loss: 1.7882
EarlyStopping counter: 2 out of 3
Epoch: 4 | Time: 2.62 s | Train Loss: 1.8728 Vali Loss: 1.754
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:10:54.
Model parameters: 76400
Total memory: 7967.4 MB
Allocated memory: 17.6 MB
Max allocated memory: 147.6 MB
Time per epoch: 2.7 sec.
Memory usage: Available 7967.4 MB, Allocated 17.6 MB, Max allocated 147.6 MB

Loading model from results/Apple/iTransformer_sl_96_pl_48/2/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 204
Preds and Trues shape: (204, 48, 5) (204, 48, 5)
test scaled -- mse:3.3584, mae:1.4568
Upscaling data and removing negatives...
test -- mse:2.1826e+14, mae:4.632e+06, rmsle: 0.21594 smape 12.232


>>>> itr_no: 3, seed: 608 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Apple/iTransformer_sl_96_pl_48/3

Experiment begins at 2024-09-06 01:10:54

>>>>>>> start training :>>>>>>>>>>
train 1869
val 206
Epoch: 1 | Time: 2.61 s | Train Loss: 3.4298 Vali Loss: 1.6432
Validation loss decreased (inf --> 1.643184).  Saving model ...
Epoch: 2 | Time: 2.63 s | Train Loss: 2.6194 Vali Loss: 1.8462
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 2.64 s | Train Loss: 2.2151 Vali Loss: 1.7604
EarlyStopping counter: 2 out of 3
Epoch: 4 | Time: 2.63 s | Train Loss: 1.9347 Vali Loss: 1.685
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:11:05.
Model parameters: 76400
Total memory: 7967.4 MB
Allocated memory: 17.6 MB
Max allocated memory: 147.6 MB
Time per epoch: 2.7 sec.
Memory usage: Available 7967.4 MB, Allocated 17.6 MB, Max allocated 147.6 MB

Loading model from results/Apple/iTransformer_sl_96_pl_48/3/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 204
Preds and Trues shape: (204, 48, 5) (204, 48, 5)
test scaled -- mse:4.0074, mae:1.5877
Upscaling data and removing negatives...
test -- mse:1.9418e+14, mae:4.1751e+06, rmsle: 0.20623 smape 12.35

Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='Apple.csv', features='M', n_features=5, target='OT', freq='d', no_scale=False, seq_len=96, label_len=96, pred_len=48, top_k=5, num_kernels=6, d_model=64, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, channel_independence=1, decomp_method='moving_avg', use_norm=1, down_sampling_layers=0, down_sampling_window=1, down_sampling_method=None, seg_len=48, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, dry_run=False, percent=100, model='MICN', use_gpu=True, enc_in=5, dec_in=5, c_out=5, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Apple/MICN_sl_96_pl_48/1

Experiment begins at 2024-09-06 01:11:11

>>>>>>> start training :>>>>>>>>>>
train 1869
val 206
Epoch: 1 | Time: 3.95 s | Train Loss: 3.4073 Vali Loss: 1.475
Validation loss decreased (inf --> 1.475002).  Saving model ...
Epoch: 2 | Time: 2.79 s | Train Loss: 2.7914 Vali Loss: 1.3168
Validation loss decreased (1.475002 --> 1.316811).  Saving model ...
Epoch: 3 | Time: 2.79 s | Train Loss: 2.5555 Vali Loss: 1.4686
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 2.8 s | Train Loss: 2.3987 Vali Loss: 1.6845
EarlyStopping counter: 2 out of 3
Epoch: 5 | Time: 2.79 s | Train Loss: 2.0942 Vali Loss: 1.7284
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:11:27.
Model parameters: 371829
Total memory: 7967.4 MB
Allocated memory: 23.3 MB
Max allocated memory: 179.9 MB
Time per epoch: 3.3 sec.
Memory usage: Available 7967.4 MB, Allocated 23.3 MB, Max allocated 179.9 MB

Loading model from results/Apple/MICN_sl_96_pl_48/1/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 204
Preds and Trues shape: (204, 48, 5) (204, 48, 5)
test scaled -- mse:3.007, mae:1.3225
Upscaling data and removing negatives...
test -- mse:1.5492e+14, mae:3.476e+06, rmsle: 0.17327 smape 10.21


>>>> itr_no: 2, seed: 506 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Apple/MICN_sl_96_pl_48/2

Experiment begins at 2024-09-06 01:11:28

>>>>>>> start training :>>>>>>>>>>
train 1869
val 206
Epoch: 1 | Time: 2.8 s | Train Loss: 3.3941 Vali Loss: 1.3886
Validation loss decreased (inf --> 1.388603).  Saving model ...
Epoch: 2 | Time: 2.81 s | Train Loss: 2.8141 Vali Loss: 1.2789
Validation loss decreased (1.388603 --> 1.278893).  Saving model ...
Epoch: 3 | Time: 2.8 s | Train Loss: 2.5863 Vali Loss: 1.3756
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 2.81 s | Train Loss: 2.4633 Vali Loss: 1.3878
EarlyStopping counter: 2 out of 3
Epoch: 5 | Time: 2.81 s | Train Loss: 2.2461 Vali Loss: 1.4556
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:11:43.
Model parameters: 371829
Total memory: 7967.4 MB
Allocated memory: 23.3 MB
Max allocated memory: 179.9 MB
Time per epoch: 2.9 sec.
Memory usage: Available 7967.4 MB, Allocated 23.3 MB, Max allocated 179.9 MB

Loading model from results/Apple/MICN_sl_96_pl_48/2/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 204
Preds and Trues shape: (204, 48, 5) (204, 48, 5)
test scaled -- mse:2.976, mae:1.3267
Upscaling data and removing negatives...
test -- mse:1.5419e+14, mae:3.4696e+06, rmsle: 0.17285 smape 10.209


>>>> itr_no: 3, seed: 608 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Apple/MICN_sl_96_pl_48/3

Experiment begins at 2024-09-06 01:11:43

>>>>>>> start training :>>>>>>>>>>
train 1869
val 206
Epoch: 1 | Time: 2.78 s | Train Loss: 3.436 Vali Loss: 1.4053
Validation loss decreased (inf --> 1.405306).  Saving model ...
Epoch: 2 | Time: 2.8 s | Train Loss: 2.8376 Vali Loss: 1.2935
Validation loss decreased (1.405306 --> 1.293533).  Saving model ...
Epoch: 3 | Time: 2.81 s | Train Loss: 2.6289 Vali Loss: 1.3356
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 2.8 s | Train Loss: 2.4827 Vali Loss: 1.3831
EarlyStopping counter: 2 out of 3
Epoch: 5 | Time: 2.81 s | Train Loss: 2.2566 Vali Loss: 1.4988
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:11:58.
Model parameters: 371829
Total memory: 7967.4 MB
Allocated memory: 23.3 MB
Max allocated memory: 179.9 MB
Time per epoch: 2.9 sec.
Memory usage: Available 7967.4 MB, Allocated 23.3 MB, Max allocated 179.9 MB

Loading model from results/Apple/MICN_sl_96_pl_48/3/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 204
Preds and Trues shape: (204, 48, 5) (204, 48, 5)
test scaled -- mse:2.8804, mae:1.3076
Upscaling data and removing negatives...
test -- mse:1.5605e+14, mae:3.5552e+06, rmsle: 0.17431 smape 10.223

Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='Apple.csv', features='M', n_features=5, target='OT', freq='d', no_scale=False, seq_len=96, label_len=0, pred_len=48, top_k=5, num_kernels=6, d_model=16, n_heads=4, e_layers=3, d_layers=1, d_ff=32, moving_avg=3, factor=3, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, channel_independence=1, decomp_method='moving_avg', use_norm=1, down_sampling_layers=3, down_sampling_window=2, down_sampling_method='avg', seg_len=48, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, dry_run=False, percent=100, model='TimeMixer', use_gpu=True, enc_in=5, dec_in=5, c_out=5, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Apple/TimeMixer_sl_96_pl_48/1

Experiment begins at 2024-09-06 01:12:05

>>>>>>> start training :>>>>>>>>>>
train 1869
val 206
Epoch: 1 | Time: 5.34 s | Train Loss: 3.5891 Vali Loss: 1.6357
Validation loss decreased (inf --> 1.635675).  Saving model ...
Epoch: 2 | Time: 4.31 s | Train Loss: 2.5848 Vali Loss: 1.3348
Validation loss decreased (1.635675 --> 1.334772).  Saving model ...
Epoch: 3 | Time: 4.28 s | Train Loss: 2.1912 Vali Loss: 1.5788
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 4.3 s | Train Loss: 1.943 Vali Loss: 1.8652
EarlyStopping counter: 2 out of 3
Epoch: 5 | Time: 4.33 s | Train Loss: 1.6397 Vali Loss: 1.8039
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:12:29.
Model parameters: 95457
Total memory: 7967.4 MB
Allocated memory: 18.2 MB
Max allocated memory: 82.9 MB
Time per epoch: 4.8 sec.
Memory usage: Available 7967.4 MB, Allocated 18.2 MB, Max allocated 82.9 MB

Loading model from results/Apple/TimeMixer_sl_96_pl_48/1/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 204
Preds and Trues shape: (204, 48, 5) (204, 48, 5)
test scaled -- mse:3.7397, mae:1.4806
Upscaling data and removing negatives...
test -- mse:1.6761e+14, mae:3.6022e+06, rmsle: 0.18788 smape 11.213


>>>> itr_no: 2, seed: 506 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Apple/TimeMixer_sl_96_pl_48/2

Experiment begins at 2024-09-06 01:12:29

>>>>>>> start training :>>>>>>>>>>
train 1869
val 206
Epoch: 1 | Time: 4.39 s | Train Loss: 3.7588 Vali Loss: 1.504
Validation loss decreased (inf --> 1.504030).  Saving model ...
Epoch: 2 | Time: 4.32 s | Train Loss: 2.6343 Vali Loss: 1.2332
Validation loss decreased (1.504030 --> 1.233237).  Saving model ...
Epoch: 3 | Time: 4.32 s | Train Loss: 2.2344 Vali Loss: 1.3812
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 4.34 s | Train Loss: 2.0274 Vali Loss: 1.6011
EarlyStopping counter: 2 out of 3
Epoch: 5 | Time: 4.36 s | Train Loss: 1.7795 Vali Loss: 1.4623
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:12:52.
Model parameters: 95457
Total memory: 7967.4 MB
Allocated memory: 18.2 MB
Max allocated memory: 82.9 MB
Time per epoch: 4.5 sec.
Memory usage: Available 7967.4 MB, Allocated 18.2 MB, Max allocated 82.9 MB

Loading model from results/Apple/TimeMixer_sl_96_pl_48/2/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 204
Preds and Trues shape: (204, 48, 5) (204, 48, 5)
test scaled -- mse:3.5434, mae:1.4475
Upscaling data and removing negatives...
test -- mse:1.7023e+14, mae:3.6703e+06, rmsle: 0.18697 smape 11.072


>>>> itr_no: 3, seed: 608 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Apple/TimeMixer_sl_96_pl_48/3

Experiment begins at 2024-09-06 01:12:52

>>>>>>> start training :>>>>>>>>>>
train 1869
val 206
Epoch: 1 | Time: 4.39 s | Train Loss: 4.2209 Vali Loss: 1.462
Validation loss decreased (inf --> 1.462021).  Saving model ...
Epoch: 2 | Time: 4.33 s | Train Loss: 2.7312 Vali Loss: 1.5079
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 4.39 s | Train Loss: 2.3429 Vali Loss: 1.3833
Validation loss decreased (1.462021 --> 1.383304).  Saving model ...
Epoch: 4 | Time: 4.39 s | Train Loss: 2.1251 Vali Loss: 1.6613
EarlyStopping counter: 1 out of 3
Epoch: 5 | Time: 4.38 s | Train Loss: 1.8995 Vali Loss: 1.4473
EarlyStopping counter: 2 out of 3
Epoch: 6 | Time: 4.38 s | Train Loss: 1.6635 Vali Loss: 1.4602
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:13:19.
Model parameters: 95457
Total memory: 7967.4 MB
Allocated memory: 18.2 MB
Max allocated memory: 82.9 MB
Time per epoch: 4.5 sec.
Memory usage: Available 7967.4 MB, Allocated 18.2 MB, Max allocated 82.9 MB

Loading model from results/Apple/TimeMixer_sl_96_pl_48/3/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 204
Preds and Trues shape: (204, 48, 5) (204, 48, 5)
test scaled -- mse:3.5946, mae:1.4506
Upscaling data and removing negatives...
test -- mse:1.7638e+14, mae:3.7743e+06, rmsle: 0.19198 smape 11.238

Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='Apple.csv', features='M', n_features=5, target='OT', freq='d', no_scale=False, seq_len=96, label_len=48, pred_len=48, top_k=5, num_kernels=6, d_model=768, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', dry_run=False, percent=100, model_id='ori', model='CALF', task_loss='l1', distill_loss='l1', logits_loss='l1', tmax=20, r=8, lora_alpha=32, lora_dropout=0.1, word_embedding_path='./utils/wte_pca_500.pt', task_w=1.0, feature_w=0.01, logits_w=1.0, gpt_layers=6, log_fine_name='CALF_result.txt', noise_scale=-100, bootstrap_eval=0, use_gpu=True, enc_in=5, dec_in=5, c_out=5, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
model_id  ori
Experiments will be saved in results/Apple/CALF_sl_96_pl_48_id_ori/1

Experiment begins at 2024-09-06 01:13:41

>>>>>>> start training :>>>>>>>>>>
train 1869
val 206
Loss function weights: 1.0 1.0 0.01
Orig-- ori
Epoch: 1 | Time: 7.81 s | Train Loss: 2.2598 Vali Loss: 2.3136
Validation loss decreased (inf --> 2.313574).  Saving model ...
Epoch: 2 | Time: 5.08 s | Train Loss: 2.4241 Vali Loss: 2.0712
Validation loss decreased (2.313574 --> 2.071229).  Saving model ...
Epoch: 3 | Time: 5.07 s | Train Loss: 2.2549 Vali Loss: 1.1956
Validation loss decreased (2.071229 --> 1.195571).  Saving model ...
Epoch: 4 | Time: 5.07 s | Train Loss: 3.8794 Vali Loss: 1.6504
EarlyStopping counter: 1 out of 3
Epoch: 5 | Time: 5.25 s | Train Loss: 6.8586 Vali Loss: 1.4786
EarlyStopping counter: 2 out of 3
Epoch: 6 | Time: 5.12 s | Train Loss: 8.2988 Vali Loss: 1.2849
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:14:39.
Model parameters: 180070448
Total memory: 7967.4 MB
Allocated memory: 946.8 MB
Max allocated memory: 1254.8 MB
Time per epoch: 9.7 sec.
Memory usage: Available 7967.4 MB, Allocated 946.8 MB, Max allocated 1254.8 MB

Loading model from results/Apple/CALF_sl_96_pl_48_id_ori/1/llm.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 204
Preds and Trues shape: (204, 48, 5) (204, 48, 5)
test scaled -- mse:3.5245, mae:1.516
Upscaling data and removing negatives...
test -- mse:2.146e+14, mae:4.745e+06, rmsle: 0.21255 smape 12.418


>>>> itr_no: 2, seed: 506 <<<<<<
Use GPU: cuda:0
model_id  ori
Experiments will be saved in results/Apple/CALF_sl_96_pl_48_id_ori/2

Experiment begins at 2024-09-06 01:14:41

>>>>>>> start training :>>>>>>>>>>
train 1869
val 206
Loss function weights: 1.0 1.0 0.01
Orig-- ori
Epoch: 1 | Time: 5.2 s | Train Loss: 2.1941 Vali Loss: 1.8473
Validation loss decreased (inf --> 1.847290).  Saving model ...
Epoch: 2 | Time: 5.08 s | Train Loss: 2.055 Vali Loss: 1.5283
Validation loss decreased (1.847290 --> 1.528304).  Saving model ...
Epoch: 3 | Time: 5.09 s | Train Loss: 1.9569 Vali Loss: 1.5692
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 5.08 s | Train Loss: 2.4549 Vali Loss: 1.7821
EarlyStopping counter: 2 out of 3
Epoch: 5 | Time: 5.08 s | Train Loss: 3.5781 Vali Loss: 1.9943
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:15:23.
Model parameters: 180070448
Total memory: 7967.4 MB
Allocated memory: 950.0 MB
Max allocated memory: 1637.3 MB
Time per epoch: 8.3 sec.
Memory usage: Available 7967.4 MB, Allocated 950.0 MB, Max allocated 1637.3 MB

Loading model from results/Apple/CALF_sl_96_pl_48_id_ori/2/llm.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 204
Preds and Trues shape: (204, 48, 5) (204, 48, 5)
test scaled -- mse:4.2377, mae:1.6602
Upscaling data and removing negatives...
test -- mse:2.3561e+14, mae:4.592e+06, rmsle: 0.21726 smape 12.797


>>>> itr_no: 3, seed: 608 <<<<<<
Use GPU: cuda:0
model_id  ori
Experiments will be saved in results/Apple/CALF_sl_96_pl_48_id_ori/3

Experiment begins at 2024-09-06 01:15:25

>>>>>>> start training :>>>>>>>>>>
train 1869
val 206
Loss function weights: 1.0 1.0 0.01
Orig-- ori
Epoch: 1 | Time: 5.09 s | Train Loss: 2.1723 Vali Loss: 1.5705
Validation loss decreased (inf --> 1.570544).  Saving model ...
Epoch: 2 | Time: 5.09 s | Train Loss: 2.0892 Vali Loss: 1.4296
Validation loss decreased (1.570544 --> 1.429559).  Saving model ...
Epoch: 3 | Time: 5.09 s | Train Loss: 2.2004 Vali Loss: 1.98
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 5.08 s | Train Loss: 2.9999 Vali Loss: 1.8327
EarlyStopping counter: 2 out of 3
Epoch: 5 | Time: 5.07 s | Train Loss: 4.3167 Vali Loss: 1.6888
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:16:06.
Model parameters: 180070448
Total memory: 7967.4 MB
Allocated memory: 948.3 MB
Max allocated memory: 1638.4 MB
Time per epoch: 8.3 sec.
Memory usage: Available 7967.4 MB, Allocated 948.3 MB, Max allocated 1638.4 MB

Loading model from results/Apple/CALF_sl_96_pl_48_id_ori/3/llm.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 204
Preds and Trues shape: (204, 48, 5) (204, 48, 5)
test scaled -- mse:3.8939, mae:1.5835
Upscaling data and removing negatives...
test -- mse:2.2216e+14, mae:4.5354e+06, rmsle: 0.20942 smape 12.293

Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='Apple.csv', features='M', n_features=5, target='OT', freq='d', no_scale=False, seq_len=96, label_len=48, pred_len=48, top_k=5, num_kernels=6, d_model=768, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', dry_run=False, percent=100, model_id='ori', model='OFA', gpt_layers=6, is_gpt=1, patch_size=16, kernel_size=25, pretrain=1, freeze=1, stride=8, max_len=-1, hid_dim=16, tmax=20, n_scale=-1, use_gpu=True, enc_in=5, dec_in=5, c_out=5, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Apple/OFA_sl_96_pl_48_id_ori/1

Experiment begins at 2024-09-06 01:16:18

>>>>>>> start training :>>>>>>>>>>
train 1869
val 206
Epoch: 1 | Time: 5.54 s | Train Loss: 1.2609 Vali Loss: 1.0647
Validation loss decreased (inf --> 1.064673).  Saving model ...
Epoch: 2 | Time: 5.23 s | Train Loss: 1.1335 Vali Loss: 1.015
Validation loss decreased (1.064673 --> 1.015040).  Saving model ...
Epoch: 3 | Time: 5.27 s | Train Loss: 1.0666 Vali Loss: 1.0935
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 5.22 s | Train Loss: 1.0415 Vali Loss: 1.0662
EarlyStopping counter: 2 out of 3
Epoch: 5 | Time: 5.24 s | Train Loss: 0.9875 Vali Loss: 1.0716
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:16:53.
Model parameters: 82368048
Total memory: 7967.4 MB
Allocated memory: 353.4 MB
Max allocated memory: 1243.0 MB
Time per epoch: 7.0 sec.
Memory usage: Available 7967.4 MB, Allocated 353.4 MB, Max allocated 1243.0 MB

Loading model from results/Apple/OFA_sl_96_pl_48_id_ori/1/llm.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 204
Preds and Trues shape: (204, 48, 5) (204, 48, 5)
test scaled -- mse:3.3502, mae:1.421
Upscaling data and removing negatives...
test -- mse:1.9565e+14, mae:4.1072e+06, rmsle: 0.19945 smape 11.338


>>>> itr_no: 2, seed: 506 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Apple/OFA_sl_96_pl_48_id_ori/2

Experiment begins at 2024-09-06 01:16:54

>>>>>>> start training :>>>>>>>>>>
train 1869
val 206
Epoch: 1 | Time: 5.25 s | Train Loss: 1.2684 Vali Loss: 1.0476
Validation loss decreased (inf --> 1.047577).  Saving model ...
Epoch: 2 | Time: 5.29 s | Train Loss: 1.1267 Vali Loss: 1.0466
Validation loss decreased (1.047577 --> 1.046617).  Saving model ...
Epoch: 3 | Time: 5.31 s | Train Loss: 1.0884 Vali Loss: 1.0498
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 5.25 s | Train Loss: 1.0322 Vali Loss: 1.086
EarlyStopping counter: 2 out of 3
Epoch: 5 | Time: 5.27 s | Train Loss: 1.0016 Vali Loss: 0.99984
Validation loss decreased (1.046617 --> 0.999841).  Saving model ...
Epoch: 6 | Time: 5.32 s | Train Loss: 0.95974 Vali Loss: 1.0108
EarlyStopping counter: 1 out of 3
Epoch: 7 | Time: 5.27 s | Train Loss: 0.94835 Vali Loss: 1.0036
EarlyStopping counter: 2 out of 3
Epoch: 8 | Time: 5.28 s | Train Loss: 0.91682 Vali Loss: 1.0146
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:17:48.
Model parameters: 82368048
Total memory: 7967.4 MB
Allocated memory: 354.5 MB
Max allocated memory: 1245.0 MB
Time per epoch: 6.8 sec.
Memory usage: Available 7967.4 MB, Allocated 354.5 MB, Max allocated 1245.0 MB

Loading model from results/Apple/OFA_sl_96_pl_48_id_ori/2/llm.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 204
Preds and Trues shape: (204, 48, 5) (204, 48, 5)
test scaled -- mse:3.7046, mae:1.4711
Upscaling data and removing negatives...
test -- mse:1.87e+14, mae:3.7873e+06, rmsle: 0.20858 smape 11.641


>>>> itr_no: 3, seed: 608 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Apple/OFA_sl_96_pl_48_id_ori/3

Experiment begins at 2024-09-06 01:17:50

>>>>>>> start training :>>>>>>>>>>
train 1869
val 206
Epoch: 1 | Time: 5.28 s | Train Loss: 1.2678 Vali Loss: 1.0441
Validation loss decreased (inf --> 1.044138).  Saving model ...
Epoch: 2 | Time: 5.33 s | Train Loss: 1.1263 Vali Loss: 1.0344
Validation loss decreased (1.044138 --> 1.034379).  Saving model ...
Epoch: 3 | Time: 5.29 s | Train Loss: 1.0667 Vali Loss: 1.0004
Validation loss decreased (1.034379 --> 1.000439).  Saving model ...
Epoch: 4 | Time: 5.3 s | Train Loss: 1.0343 Vali Loss: 1.0286
EarlyStopping counter: 1 out of 3
Epoch: 5 | Time: 5.26 s | Train Loss: 0.98697 Vali Loss: 1.0249
EarlyStopping counter: 2 out of 3
Epoch: 6 | Time: 5.27 s | Train Loss: 0.95082 Vali Loss: 1.0221
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:18:34.
Model parameters: 82368048
Total memory: 7967.4 MB
Allocated memory: 353.1 MB
Max allocated memory: 1245.0 MB
Time per epoch: 7.3 sec.
Memory usage: Available 7967.4 MB, Allocated 353.1 MB, Max allocated 1245.0 MB

Loading model from results/Apple/OFA_sl_96_pl_48_id_ori/3/llm.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 204
Preds and Trues shape: (204, 48, 5) (204, 48, 5)
test scaled -- mse:3.4932, mae:1.4286
Upscaling data and removing negatives...
test -- mse:1.907e+14, mae:3.9108e+06, rmsle: 0.20261 smape 11.4

Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='Apple.csv', features='M', n_features=5, target='OT', freq='d', no_scale=False, seq_len=96, label_len=48, pred_len=48, top_k=5, num_kernels=6, d_model=16, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=16, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', dry_run=False, percent=100, model_id='ori', model='TimeLLM', patch_len=16, stride=8, prompt_domain=1, llm_model='GPT2', llm_dim=768, llm_layers=6, use_gpu=True, enc_in=5, dec_in=5, c_out=5, task_name='long_term_forecast', content='Apple stock prices. Apple Inc. designs a wide variety of consumer electronic devices.  The company generates roughly 40% of its revenue from the Americas.')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
description: Apple stock prices. Apple Inc. designs a wide variety of consumer electronic devices.  The company generates roughly 40% of its revenue from the Americas.
Experiments will be saved in results/Apple/TimeLLM_sl_96_pl_48_id_ori/1

Experiment begins at 2024-09-06 01:18:52

>>>>>>> start training :>>>>>>>>>>
train 1869
val 206
Traceback (most recent call last):
  File "/u/mi3se/projects/Financial-Time-Series/run_TimeLLM.py", line 95, in <module>
    main(args)
  File "/u/mi3se/projects/Financial-Time-Series/run_TimeLLM.py", line 50, in main
    exp.train()
  File "/u/mi3se/projects/Financial-Time-Series/exp/exp_long_term_forecasting.py", line 211, in train
    loss.backward()
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/torch/_tensor.py", line 525, in backward
    torch.autograd.backward(
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/torch/autograd/__init__.py", line 267, in backward
    _engine_run_backward(
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 138.00 MiB. GPU 
Running for model:DLinear
Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='Crude_oil.csv', features='M', n_features=5, target='OT', freq='d', no_scale=False, seq_len=96, label_len=48, pred_len=48, top_k=5, num_kernels=6, d_model=64, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, channel_independence=1, decomp_method='moving_avg', use_norm=1, down_sampling_layers=0, down_sampling_window=1, down_sampling_method=None, seg_len=48, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, dry_run=False, percent=100, model='DLinear', use_gpu=True, enc_in=5, dec_in=5, c_out=5, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Crude_oil/DLinear_sl_96_pl_48/1

Experiment begins at 2024-09-06 01:19:02

>>>>>>> start training :>>>>>>>>>>
Traceback (most recent call last):
  File "/u/mi3se/projects/Financial-Time-Series/run.py", line 87, in <module>
    main(args)
  File "/u/mi3se/projects/Financial-Time-Series/run.py", line 60, in main
    exp.train()
  File "/u/mi3se/projects/Financial-Time-Series/exp/exp_long_term_forecasting.py", line 145, in train
    _, train_loader = self.get_data(flag='train')
  File "/u/mi3se/projects/Financial-Time-Series/exp/exp_basic.py", line 71, in get_data
    self.dataset_map[flag] = data_provider(self.args, flag)
  File "/u/mi3se/projects/Financial-Time-Series/data_provider/data_factory.py", line 14, in data_provider
    dataset = Dataset_Custom(args, flag=flag)
  File "/u/mi3se/projects/Financial-Time-Series/data_provider/data_loader.py", line 41, in __init__
    self.__read_data__()
  File "/u/mi3se/projects/Financial-Time-Series/data_provider/data_loader.py", line 45, in __read_data__
    df_raw = pd.read_csv(
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/pandas/io/parsers/readers.py", line 1026, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/pandas/io/parsers/readers.py", line 620, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/pandas/io/parsers/readers.py", line 1620, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/pandas/io/parsers/readers.py", line 1880, in _make_engine
    self.handles = get_handle(
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/pandas/io/common.py", line 873, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: './data/Crude_oil.csv'
Running for model:PatchTST
Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='Crude_oil.csv', features='M', n_features=5, target='OT', freq='d', no_scale=False, seq_len=96, label_len=48, pred_len=48, top_k=5, num_kernels=6, d_model=64, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, channel_independence=1, decomp_method='moving_avg', use_norm=1, down_sampling_layers=0, down_sampling_window=1, down_sampling_method=None, seg_len=48, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, dry_run=False, percent=100, model='PatchTST', use_gpu=True, enc_in=5, dec_in=5, c_out=5, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Crude_oil/PatchTST_sl_96_pl_48/1

Experiment begins at 2024-09-06 01:19:07

>>>>>>> start training :>>>>>>>>>>
Traceback (most recent call last):
  File "/u/mi3se/projects/Financial-Time-Series/run.py", line 87, in <module>
    main(args)
  File "/u/mi3se/projects/Financial-Time-Series/run.py", line 60, in main
    exp.train()
  File "/u/mi3se/projects/Financial-Time-Series/exp/exp_long_term_forecasting.py", line 145, in train
    _, train_loader = self.get_data(flag='train')
  File "/u/mi3se/projects/Financial-Time-Series/exp/exp_basic.py", line 71, in get_data
    self.dataset_map[flag] = data_provider(self.args, flag)
  File "/u/mi3se/projects/Financial-Time-Series/data_provider/data_factory.py", line 14, in data_provider
    dataset = Dataset_Custom(args, flag=flag)
  File "/u/mi3se/projects/Financial-Time-Series/data_provider/data_loader.py", line 41, in __init__
    self.__read_data__()
  File "/u/mi3se/projects/Financial-Time-Series/data_provider/data_loader.py", line 45, in __read_data__
    df_raw = pd.read_csv(
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/pandas/io/parsers/readers.py", line 1026, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/pandas/io/parsers/readers.py", line 620, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/pandas/io/parsers/readers.py", line 1620, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/pandas/io/parsers/readers.py", line 1880, in _make_engine
    self.handles = get_handle(
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/pandas/io/common.py", line 873, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: './data/Crude_oil.csv'
Running for model:TimesNet
Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='Crude_oil.csv', features='M', n_features=5, target='OT', freq='d', no_scale=False, seq_len=96, label_len=48, pred_len=48, top_k=5, num_kernels=6, d_model=64, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, channel_independence=1, decomp_method='moving_avg', use_norm=1, down_sampling_layers=0, down_sampling_window=1, down_sampling_method=None, seg_len=48, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, dry_run=False, percent=100, model='TimesNet', use_gpu=True, enc_in=5, dec_in=5, c_out=5, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Crude_oil/TimesNet_sl_96_pl_48/1

Experiment begins at 2024-09-06 01:19:12

>>>>>>> start training :>>>>>>>>>>
Traceback (most recent call last):
  File "/u/mi3se/projects/Financial-Time-Series/run.py", line 87, in <module>
    main(args)
  File "/u/mi3se/projects/Financial-Time-Series/run.py", line 60, in main
    exp.train()
  File "/u/mi3se/projects/Financial-Time-Series/exp/exp_long_term_forecasting.py", line 145, in train
    _, train_loader = self.get_data(flag='train')
  File "/u/mi3se/projects/Financial-Time-Series/exp/exp_basic.py", line 71, in get_data
    self.dataset_map[flag] = data_provider(self.args, flag)
  File "/u/mi3se/projects/Financial-Time-Series/data_provider/data_factory.py", line 14, in data_provider
    dataset = Dataset_Custom(args, flag=flag)
  File "/u/mi3se/projects/Financial-Time-Series/data_provider/data_loader.py", line 41, in __init__
    self.__read_data__()
  File "/u/mi3se/projects/Financial-Time-Series/data_provider/data_loader.py", line 45, in __read_data__
    df_raw = pd.read_csv(
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/pandas/io/parsers/readers.py", line 1026, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/pandas/io/parsers/readers.py", line 620, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/pandas/io/parsers/readers.py", line 1620, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/pandas/io/parsers/readers.py", line 1880, in _make_engine
    self.handles = get_handle(
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/pandas/io/common.py", line 873, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: './data/Crude_oil.csv'
Running for model:iTransformer
Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='Crude_oil.csv', features='M', n_features=5, target='OT', freq='d', no_scale=False, seq_len=96, label_len=48, pred_len=48, top_k=5, num_kernels=6, d_model=64, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, channel_independence=1, decomp_method='moving_avg', use_norm=1, down_sampling_layers=0, down_sampling_window=1, down_sampling_method=None, seg_len=48, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, dry_run=False, percent=100, model='iTransformer', use_gpu=True, enc_in=5, dec_in=5, c_out=5, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Crude_oil/iTransformer_sl_96_pl_48/1

Experiment begins at 2024-09-06 01:19:17

>>>>>>> start training :>>>>>>>>>>
Traceback (most recent call last):
  File "/u/mi3se/projects/Financial-Time-Series/run.py", line 87, in <module>
    main(args)
  File "/u/mi3se/projects/Financial-Time-Series/run.py", line 60, in main
    exp.train()
  File "/u/mi3se/projects/Financial-Time-Series/exp/exp_long_term_forecasting.py", line 145, in train
    _, train_loader = self.get_data(flag='train')
  File "/u/mi3se/projects/Financial-Time-Series/exp/exp_basic.py", line 71, in get_data
    self.dataset_map[flag] = data_provider(self.args, flag)
  File "/u/mi3se/projects/Financial-Time-Series/data_provider/data_factory.py", line 14, in data_provider
    dataset = Dataset_Custom(args, flag=flag)
  File "/u/mi3se/projects/Financial-Time-Series/data_provider/data_loader.py", line 41, in __init__
    self.__read_data__()
  File "/u/mi3se/projects/Financial-Time-Series/data_provider/data_loader.py", line 45, in __read_data__
    df_raw = pd.read_csv(
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/pandas/io/parsers/readers.py", line 1026, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/pandas/io/parsers/readers.py", line 620, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/pandas/io/parsers/readers.py", line 1620, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/pandas/io/parsers/readers.py", line 1880, in _make_engine
    self.handles = get_handle(
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/pandas/io/common.py", line 873, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: './data/Crude_oil.csv'
Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='Crude_oil.csv', features='M', n_features=5, target='OT', freq='d', no_scale=False, seq_len=96, label_len=96, pred_len=48, top_k=5, num_kernels=6, d_model=64, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, channel_independence=1, decomp_method='moving_avg', use_norm=1, down_sampling_layers=0, down_sampling_window=1, down_sampling_method=None, seg_len=48, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, dry_run=False, percent=100, model='MICN', use_gpu=True, enc_in=5, dec_in=5, c_out=5, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Crude_oil/MICN_sl_96_pl_48/1

Experiment begins at 2024-09-06 01:19:21

>>>>>>> start training :>>>>>>>>>>
Traceback (most recent call last):
  File "/u/mi3se/projects/Financial-Time-Series/run.py", line 87, in <module>
    main(args)
  File "/u/mi3se/projects/Financial-Time-Series/run.py", line 60, in main
    exp.train()
  File "/u/mi3se/projects/Financial-Time-Series/exp/exp_long_term_forecasting.py", line 145, in train
    _, train_loader = self.get_data(flag='train')
  File "/u/mi3se/projects/Financial-Time-Series/exp/exp_basic.py", line 71, in get_data
    self.dataset_map[flag] = data_provider(self.args, flag)
  File "/u/mi3se/projects/Financial-Time-Series/data_provider/data_factory.py", line 14, in data_provider
    dataset = Dataset_Custom(args, flag=flag)
  File "/u/mi3se/projects/Financial-Time-Series/data_provider/data_loader.py", line 41, in __init__
    self.__read_data__()
  File "/u/mi3se/projects/Financial-Time-Series/data_provider/data_loader.py", line 45, in __read_data__
    df_raw = pd.read_csv(
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/pandas/io/parsers/readers.py", line 1026, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/pandas/io/parsers/readers.py", line 620, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/pandas/io/parsers/readers.py", line 1620, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/pandas/io/parsers/readers.py", line 1880, in _make_engine
    self.handles = get_handle(
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/pandas/io/common.py", line 873, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: './data/Crude_oil.csv'
Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='Crude_oil.csv', features='M', n_features=5, target='OT', freq='d', no_scale=False, seq_len=96, label_len=0, pred_len=48, top_k=5, num_kernels=6, d_model=16, n_heads=4, e_layers=3, d_layers=1, d_ff=32, moving_avg=3, factor=3, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, channel_independence=1, decomp_method='moving_avg', use_norm=1, down_sampling_layers=3, down_sampling_window=2, down_sampling_method='avg', seg_len=48, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, dry_run=False, percent=100, model='TimeMixer', use_gpu=True, enc_in=5, dec_in=5, c_out=5, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Crude_oil/TimeMixer_sl_96_pl_48/1

Experiment begins at 2024-09-06 01:19:26

>>>>>>> start training :>>>>>>>>>>
Traceback (most recent call last):
  File "/u/mi3se/projects/Financial-Time-Series/run.py", line 87, in <module>
    main(args)
  File "/u/mi3se/projects/Financial-Time-Series/run.py", line 60, in main
    exp.train()
  File "/u/mi3se/projects/Financial-Time-Series/exp/exp_long_term_forecasting.py", line 145, in train
    _, train_loader = self.get_data(flag='train')
  File "/u/mi3se/projects/Financial-Time-Series/exp/exp_basic.py", line 71, in get_data
    self.dataset_map[flag] = data_provider(self.args, flag)
  File "/u/mi3se/projects/Financial-Time-Series/data_provider/data_factory.py", line 14, in data_provider
    dataset = Dataset_Custom(args, flag=flag)
  File "/u/mi3se/projects/Financial-Time-Series/data_provider/data_loader.py", line 41, in __init__
    self.__read_data__()
  File "/u/mi3se/projects/Financial-Time-Series/data_provider/data_loader.py", line 45, in __read_data__
    df_raw = pd.read_csv(
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/pandas/io/parsers/readers.py", line 1026, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/pandas/io/parsers/readers.py", line 620, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/pandas/io/parsers/readers.py", line 1620, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/pandas/io/parsers/readers.py", line 1880, in _make_engine
    self.handles = get_handle(
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/pandas/io/common.py", line 873, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: './data/Crude_oil.csv'
Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='Crude_oil.csv', features='M', n_features=5, target='OT', freq='d', no_scale=False, seq_len=96, label_len=48, pred_len=48, top_k=5, num_kernels=6, d_model=768, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', dry_run=False, percent=100, model_id='ori', model='CALF', task_loss='l1', distill_loss='l1', logits_loss='l1', tmax=20, r=8, lora_alpha=32, lora_dropout=0.1, word_embedding_path='./utils/wte_pca_500.pt', task_w=1.0, feature_w=0.01, logits_w=1.0, gpt_layers=6, log_fine_name='CALF_result.txt', noise_scale=-100, bootstrap_eval=0, use_gpu=True, enc_in=5, dec_in=5, c_out=5, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
model_id  ori
Experiments will be saved in results/Crude_oil/CALF_sl_96_pl_48_id_ori/1

Experiment begins at 2024-09-06 01:19:31

>>>>>>> start training :>>>>>>>>>>
Traceback (most recent call last):
  File "/u/mi3se/projects/Financial-Time-Series/run_CALF.py", line 106, in <module>
    main(args)
  File "/u/mi3se/projects/Financial-Time-Series/run_CALF.py", line 41, in main
    exp.train()
  File "/u/mi3se/projects/Financial-Time-Series/exp/exp_long_term_forecasting.py", line 145, in train
    _, train_loader = self.get_data(flag='train')
  File "/u/mi3se/projects/Financial-Time-Series/exp/exp_basic.py", line 71, in get_data
    self.dataset_map[flag] = data_provider(self.args, flag)
  File "/u/mi3se/projects/Financial-Time-Series/data_provider/data_factory.py", line 14, in data_provider
    dataset = Dataset_Custom(args, flag=flag)
  File "/u/mi3se/projects/Financial-Time-Series/data_provider/data_loader.py", line 41, in __init__
    self.__read_data__()
  File "/u/mi3se/projects/Financial-Time-Series/data_provider/data_loader.py", line 45, in __read_data__
    df_raw = pd.read_csv(
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/pandas/io/parsers/readers.py", line 1026, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/pandas/io/parsers/readers.py", line 620, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/pandas/io/parsers/readers.py", line 1620, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/pandas/io/parsers/readers.py", line 1880, in _make_engine
    self.handles = get_handle(
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/pandas/io/common.py", line 873, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: './data/Crude_oil.csv'
Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='Crude_oil.csv', features='M', n_features=5, target='OT', freq='d', no_scale=False, seq_len=96, label_len=48, pred_len=48, top_k=5, num_kernels=6, d_model=768, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', dry_run=False, percent=100, model_id='ori', model='OFA', gpt_layers=6, is_gpt=1, patch_size=16, kernel_size=25, pretrain=1, freeze=1, stride=8, max_len=-1, hid_dim=16, tmax=20, n_scale=-1, use_gpu=True, enc_in=5, dec_in=5, c_out=5, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Crude_oil/OFA_sl_96_pl_48_id_ori/1

Experiment begins at 2024-09-06 01:19:36

>>>>>>> start training :>>>>>>>>>>
Traceback (most recent call last):
  File "/u/mi3se/projects/Financial-Time-Series/run_OFA.py", line 92, in <module>
    main(args)
  File "/u/mi3se/projects/Financial-Time-Series/run_OFA.py", line 44, in main
    exp.train()
  File "/u/mi3se/projects/Financial-Time-Series/exp/exp_long_term_forecasting.py", line 145, in train
    _, train_loader = self.get_data(flag='train')
  File "/u/mi3se/projects/Financial-Time-Series/exp/exp_basic.py", line 71, in get_data
    self.dataset_map[flag] = data_provider(self.args, flag)
  File "/u/mi3se/projects/Financial-Time-Series/data_provider/data_factory.py", line 14, in data_provider
    dataset = Dataset_Custom(args, flag=flag)
  File "/u/mi3se/projects/Financial-Time-Series/data_provider/data_loader.py", line 41, in __init__
    self.__read_data__()
  File "/u/mi3se/projects/Financial-Time-Series/data_provider/data_loader.py", line 45, in __read_data__
    df_raw = pd.read_csv(
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/pandas/io/parsers/readers.py", line 1026, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/pandas/io/parsers/readers.py", line 620, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/pandas/io/parsers/readers.py", line 1620, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/pandas/io/parsers/readers.py", line 1880, in _make_engine
    self.handles = get_handle(
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/pandas/io/common.py", line 873, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: './data/Crude_oil.csv'
Quadro RTX 4000
Traceback (most recent call last):
  File "/u/mi3se/projects/Financial-Time-Series/run_TimeLLM.py", line 95, in <module>
    main(args)
  File "/u/mi3se/projects/Financial-Time-Series/run_TimeLLM.py", line 19, in main
    args.content = load_content(args)
  File "/u/mi3se/projects/Financial-Time-Series/run_TimeLLM.py", line 13, in load_content
    content = df[df['data']==data_name]['prompt'].values[0]
IndexError: index 0 is out of bounds for axis 0 with size 0
Running for model:DLinear
Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='Exchange_Rate_Report.csv', features='M', n_features=7, target='OT', freq='d', no_scale=False, seq_len=96, label_len=48, pred_len=48, top_k=5, num_kernels=6, d_model=64, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, channel_independence=1, decomp_method='moving_avg', use_norm=1, down_sampling_layers=0, down_sampling_window=1, down_sampling_method=None, seg_len=48, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, dry_run=False, percent=100, model='DLinear', use_gpu=True, enc_in=7, dec_in=7, c_out=7, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Exchange_Rate_Report/DLinear_sl_96_pl_48/1

Experiment begins at 2024-09-06 01:19:47

>>>>>>> start training :>>>>>>>>>>
train 1837
val 201
Epoch: 1 | Time: 1.79 s | Train Loss: 5.6108 Vali Loss: 2.534
Validation loss decreased (inf --> 2.534004).  Saving model ...
Epoch: 2 | Time: 1.71 s | Train Loss: 5.0576 Vali Loss: 2.3362
Validation loss decreased (2.534004 --> 2.336220).  Saving model ...
Epoch: 3 | Time: 1.69 s | Train Loss: 4.8754 Vali Loss: 2.2637
Validation loss decreased (2.336220 --> 2.263668).  Saving model ...
Epoch: 4 | Time: 1.69 s | Train Loss: 4.7411 Vali Loss: 2.2144
Validation loss decreased (2.263668 --> 2.214362).  Saving model ...
Epoch: 5 | Time: 1.69 s | Train Loss: 4.6782 Vali Loss: 2.1584
Validation loss decreased (2.214362 --> 2.158447).  Saving model ...
Epoch: 6 | Time: 1.69 s | Train Loss: 4.6393 Vali Loss: 2.136
Validation loss decreased (2.158447 --> 2.136050).  Saving model ...
Epoch: 7 | Time: 1.68 s | Train Loss: 4.6261 Vali Loss: 2.1479
EarlyStopping counter: 1 out of 3
Epoch: 8 | Time: 1.69 s | Train Loss: 4.5876 Vali Loss: 2.1157
Validation loss decreased (2.136050 --> 2.115675).  Saving model ...
Epoch: 9 | Time: 1.68 s | Train Loss: 4.6006 Vali Loss: 2.1332
EarlyStopping counter: 1 out of 3
Epoch: 10 | Time: 1.69 s | Train Loss: 4.5508 Vali Loss: 2.0872
Validation loss decreased (2.115675 --> 2.087232).  Saving model ...

Training completed at 2024-09-06 01:20:06.
Model parameters: 9312
Total memory: 7967.4 MB
Allocated memory: 16.6 MB
Max allocated memory: 17.2 MB
Time per epoch: 1.9 sec.
Memory usage: Available 7967.4 MB, Allocated 16.6 MB, Max allocated 17.2 MB

Loading model from results/Exchange_Rate_Report/DLinear_sl_96_pl_48/1/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 200
Preds and Trues shape: (200, 48, 7) (200, 48, 7)
test scaled -- mse:1.3912, mae:0.8742
Upscaling data and removing negatives...
test -- mse:1.944, mae:0.4604, rmsle: 0.011596 smape 1.109


>>>> itr_no: 2, seed: 506 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Exchange_Rate_Report/DLinear_sl_96_pl_48/2

Experiment begins at 2024-09-06 01:20:06

>>>>>>> start training :>>>>>>>>>>
train 1837
val 201
Epoch: 1 | Time: 1.66 s | Train Loss: 5.6042 Vali Loss: 2.5467
Validation loss decreased (inf --> 2.546695).  Saving model ...
Epoch: 2 | Time: 1.69 s | Train Loss: 5.0025 Vali Loss: 2.3298
Validation loss decreased (2.546695 --> 2.329802).  Saving model ...
Epoch: 3 | Time: 1.69 s | Train Loss: 4.826 Vali Loss: 2.2656
Validation loss decreased (2.329802 --> 2.265589).  Saving model ...
Epoch: 4 | Time: 1.68 s | Train Loss: 4.7545 Vali Loss: 2.1924
Validation loss decreased (2.265589 --> 2.192369).  Saving model ...
Epoch: 5 | Time: 1.68 s | Train Loss: 4.8289 Vali Loss: 2.1561
Validation loss decreased (2.192369 --> 2.156126).  Saving model ...
Epoch: 6 | Time: 1.69 s | Train Loss: 4.6899 Vali Loss: 2.1425
Validation loss decreased (2.156126 --> 2.142469).  Saving model ...
Epoch: 7 | Time: 1.68 s | Train Loss: 4.6231 Vali Loss: 2.1194
Validation loss decreased (2.142469 --> 2.119396).  Saving model ...
Epoch: 8 | Time: 1.69 s | Train Loss: 4.5942 Vali Loss: 2.1046
Validation loss decreased (2.119396 --> 2.104645).  Saving model ...
Epoch: 9 | Time: 1.69 s | Train Loss: 4.5663 Vali Loss: 2.0835
Validation loss decreased (2.104645 --> 2.083454).  Saving model ...
Epoch: 10 | Time: 1.69 s | Train Loss: 4.5639 Vali Loss: 2.0701
Validation loss decreased (2.083454 --> 2.070104).  Saving model ...

Training completed at 2024-09-06 01:20:25.
Model parameters: 9312
Total memory: 7967.4 MB
Allocated memory: 16.6 MB
Max allocated memory: 17.2 MB
Time per epoch: 1.8 sec.
Memory usage: Available 7967.4 MB, Allocated 16.6 MB, Max allocated 17.2 MB

Loading model from results/Exchange_Rate_Report/DLinear_sl_96_pl_48/2/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 200
Preds and Trues shape: (200, 48, 7) (200, 48, 7)
test scaled -- mse:1.4418, mae:0.88726
Upscaling data and removing negatives...
test -- mse:1.9283, mae:0.455, rmsle: 0.011683 smape 1.1244


>>>> itr_no: 3, seed: 608 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Exchange_Rate_Report/DLinear_sl_96_pl_48/3

Experiment begins at 2024-09-06 01:20:25

>>>>>>> start training :>>>>>>>>>>
train 1837
val 201
Epoch: 1 | Time: 1.66 s | Train Loss: 5.6278 Vali Loss: 2.5555
Validation loss decreased (inf --> 2.555530).  Saving model ...
Epoch: 2 | Time: 1.69 s | Train Loss: 4.9916 Vali Loss: 2.3334
Validation loss decreased (2.555530 --> 2.333433).  Saving model ...
Epoch: 3 | Time: 1.68 s | Train Loss: 4.8539 Vali Loss: 2.2394
Validation loss decreased (2.333433 --> 2.239377).  Saving model ...
Epoch: 4 | Time: 1.69 s | Train Loss: 4.7346 Vali Loss: 2.1861
Validation loss decreased (2.239377 --> 2.186127).  Saving model ...
Epoch: 5 | Time: 1.68 s | Train Loss: 4.6805 Vali Loss: 2.1624
Validation loss decreased (2.186127 --> 2.162399).  Saving model ...
Epoch: 6 | Time: 1.69 s | Train Loss: 4.6474 Vali Loss: 2.1445
Validation loss decreased (2.162399 --> 2.144506).  Saving model ...
Epoch: 7 | Time: 1.69 s | Train Loss: 4.6415 Vali Loss: 2.12
Validation loss decreased (2.144506 --> 2.120025).  Saving model ...
Epoch: 8 | Time: 1.68 s | Train Loss: 4.6001 Vali Loss: 2.0886
Validation loss decreased (2.120025 --> 2.088600).  Saving model ...
Epoch: 9 | Time: 1.68 s | Train Loss: 4.5656 Vali Loss: 2.0948
EarlyStopping counter: 1 out of 3
Epoch: 10 | Time: 1.69 s | Train Loss: 4.5982 Vali Loss: 2.0899
EarlyStopping counter: 2 out of 3

Training completed at 2024-09-06 01:20:43.
Model parameters: 9312
Total memory: 7967.4 MB
Allocated memory: 16.6 MB
Max allocated memory: 17.2 MB
Time per epoch: 1.8 sec.
Memory usage: Available 7967.4 MB, Allocated 16.6 MB, Max allocated 17.2 MB

Loading model from results/Exchange_Rate_Report/DLinear_sl_96_pl_48/3/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 200
Preds and Trues shape: (200, 48, 7) (200, 48, 7)
test scaled -- mse:1.4388, mae:0.88874
Upscaling data and removing negatives...
test -- mse:1.95, mae:0.45867, rmsle: 0.011708 smape 1.1267

Running for model:PatchTST
Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='Exchange_Rate_Report.csv', features='M', n_features=7, target='OT', freq='d', no_scale=False, seq_len=96, label_len=48, pred_len=48, top_k=5, num_kernels=6, d_model=64, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, channel_independence=1, decomp_method='moving_avg', use_norm=1, down_sampling_layers=0, down_sampling_window=1, down_sampling_method=None, seg_len=48, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, dry_run=False, percent=100, model='PatchTST', use_gpu=True, enc_in=7, dec_in=7, c_out=7, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Exchange_Rate_Report/PatchTST_sl_96_pl_48/1

Experiment begins at 2024-09-06 01:20:50

>>>>>>> start training :>>>>>>>>>>
train 1837
val 201
Epoch: 1 | Time: 2.51 s | Train Loss: 5.1145 Vali Loss: 2.3501
Validation loss decreased (inf --> 2.350138).  Saving model ...
Epoch: 2 | Time: 2.19 s | Train Loss: 4.8071 Vali Loss: 2.184
Validation loss decreased (2.350138 --> 2.184040).  Saving model ...
Epoch: 3 | Time: 2.19 s | Train Loss: 4.7115 Vali Loss: 2.4045
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 2.2 s | Train Loss: 4.6952 Vali Loss: 2.2768
EarlyStopping counter: 2 out of 3
Epoch: 5 | Time: 2.18 s | Train Loss: 4.6659 Vali Loss: 2.2005
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:21:03.
Model parameters: 105008
Total memory: 7967.4 MB
Allocated memory: 19.3 MB
Max allocated memory: 177.4 MB
Time per epoch: 2.5 sec.
Memory usage: Available 7967.4 MB, Allocated 19.3 MB, Max allocated 177.4 MB

Loading model from results/Exchange_Rate_Report/PatchTST_sl_96_pl_48/1/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 200
Preds and Trues shape: (200, 48, 7) (200, 48, 7)
test scaled -- mse:1.4169, mae:0.88838
Upscaling data and removing negatives...
test -- mse:2.1367, mae:0.48827, rmsle: 0.011924 smape 1.1278


>>>> itr_no: 2, seed: 506 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Exchange_Rate_Report/PatchTST_sl_96_pl_48/2

Experiment begins at 2024-09-06 01:21:03

>>>>>>> start training :>>>>>>>>>>
train 1837
val 201
Epoch: 1 | Time: 2.17 s | Train Loss: 5.1092 Vali Loss: 2.0904
Validation loss decreased (inf --> 2.090438).  Saving model ...
Epoch: 2 | Time: 2.19 s | Train Loss: 4.7504 Vali Loss: 2.4334
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 2.19 s | Train Loss: 4.7011 Vali Loss: 2.3087
EarlyStopping counter: 2 out of 3
Epoch: 4 | Time: 2.2 s | Train Loss: 4.6289 Vali Loss: 2.1208
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:21:12.
Model parameters: 105008
Total memory: 7967.4 MB
Allocated memory: 19.3 MB
Max allocated memory: 177.4 MB
Time per epoch: 2.3 sec.
Memory usage: Available 7967.4 MB, Allocated 19.3 MB, Max allocated 177.4 MB

Loading model from results/Exchange_Rate_Report/PatchTST_sl_96_pl_48/2/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 200
Preds and Trues shape: (200, 48, 7) (200, 48, 7)
test scaled -- mse:1.504, mae:0.90904
Upscaling data and removing negatives...
test -- mse:1.9761, mae:0.45916, rmsle: 0.011905 smape 1.1532


>>>> itr_no: 3, seed: 608 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Exchange_Rate_Report/PatchTST_sl_96_pl_48/3

Experiment begins at 2024-09-06 01:21:13

>>>>>>> start training :>>>>>>>>>>
train 1837
val 201
Epoch: 1 | Time: 2.16 s | Train Loss: 5.0924 Vali Loss: 2.1706
Validation loss decreased (inf --> 2.170568).  Saving model ...
Epoch: 2 | Time: 2.19 s | Train Loss: 4.7422 Vali Loss: 2.3017
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 2.2 s | Train Loss: 4.7111 Vali Loss: 2.4012
EarlyStopping counter: 2 out of 3
Epoch: 4 | Time: 2.18 s | Train Loss: 4.6366 Vali Loss: 2.1822
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:21:22.
Model parameters: 105008
Total memory: 7967.4 MB
Allocated memory: 19.3 MB
Max allocated memory: 177.4 MB
Time per epoch: 2.3 sec.
Memory usage: Available 7967.4 MB, Allocated 19.3 MB, Max allocated 177.4 MB

Loading model from results/Exchange_Rate_Report/PatchTST_sl_96_pl_48/3/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 200
Preds and Trues shape: (200, 48, 7) (200, 48, 7)
test scaled -- mse:1.5452, mae:0.92748
Upscaling data and removing negatives...
test -- mse:2.2198, mae:0.49863, rmsle: 0.012352 smape 1.1847

Running for model:TimesNet
Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='Exchange_Rate_Report.csv', features='M', n_features=7, target='OT', freq='d', no_scale=False, seq_len=96, label_len=48, pred_len=48, top_k=5, num_kernels=6, d_model=64, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, channel_independence=1, decomp_method='moving_avg', use_norm=1, down_sampling_layers=0, down_sampling_window=1, down_sampling_method=None, seg_len=48, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, dry_run=False, percent=100, model='TimesNet', use_gpu=True, enc_in=7, dec_in=7, c_out=7, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Exchange_Rate_Report/TimesNet_sl_96_pl_48/1

Experiment begins at 2024-09-06 01:21:28

>>>>>>> start training :>>>>>>>>>>
train 1837
val 201
Epoch: 1 | Time: 24 s | Train Loss: 4.7647 Vali Loss: 3.1297
Validation loss decreased (inf --> 3.129712).  Saving model ...
Epoch: 2 | Time: 23.7 s | Train Loss: 2.8735 Vali Loss: 3.7953
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 24.8 s | Train Loss: 1.6813 Vali Loss: 3.8568
EarlyStopping counter: 2 out of 3
Epoch: 4 | Time: 26.1 s | Train Loss: 1.2071 Vali Loss: 4.0777
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:23:08.
Model parameters: 9390039
Total memory: 7967.4 MB
Allocated memory: 169.2 MB
Max allocated memory: 1757.0 MB
Time per epoch: 25.0 sec.
Memory usage: Available 7967.4 MB, Allocated 169.2 MB, Max allocated 1757.0 MB

Loading model from results/Exchange_Rate_Report/TimesNet_sl_96_pl_48/1/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 200
Preds and Trues shape: (200, 48, 7) (200, 48, 7)
test scaled -- mse:2.0894, mae:1.1341
Upscaling data and removing negatives...
test -- mse:3.3067, mae:0.59414, rmsle: 0.015322 smape 1.4564


>>>> itr_no: 2, seed: 506 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Exchange_Rate_Report/TimesNet_sl_96_pl_48/2

Experiment begins at 2024-09-06 01:23:10

>>>>>>> start training :>>>>>>>>>>
train 1837
val 201
Epoch: 1 | Time: 36 s | Train Loss: 4.7033 Vali Loss: 3.2176
Validation loss decreased (inf --> 3.217592).  Saving model ...
Epoch: 2 | Time: 31.4 s | Train Loss: 3.0005 Vali Loss: 4.1204
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 29.1 s | Train Loss: 1.8727 Vali Loss: 5.054
EarlyStopping counter: 2 out of 3
Epoch: 4 | Time: 27.9 s | Train Loss: 1.3337 Vali Loss: 4.8615
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:25:15.
Model parameters: 9390039
Total memory: 7967.4 MB
Allocated memory: 172.0 MB
Max allocated memory: 1780.5 MB
Time per epoch: 31.3 sec.
Memory usage: Available 7967.4 MB, Allocated 172.0 MB, Max allocated 1780.5 MB

Loading model from results/Exchange_Rate_Report/TimesNet_sl_96_pl_48/2/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 200
Preds and Trues shape: (200, 48, 7) (200, 48, 7)
test scaled -- mse:2.6127, mae:1.2752
Upscaling data and removing negatives...
test -- mse:4.9601, mae:0.73717, rmsle: 0.018116 smape 1.6905


>>>> itr_no: 3, seed: 608 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Exchange_Rate_Report/TimesNet_sl_96_pl_48/3

Experiment begins at 2024-09-06 01:25:18

>>>>>>> start training :>>>>>>>>>>
train 1837
val 201
Epoch: 1 | Time: 36.4 s | Train Loss: 4.7886 Vali Loss: 4.028
Validation loss decreased (inf --> 4.027951).  Saving model ...
Epoch: 2 | Time: 41.5 s | Train Loss: 2.9198 Vali Loss: 4.7083
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 37.6 s | Train Loss: 1.7443 Vali Loss: 4.8297
EarlyStopping counter: 2 out of 3
Epoch: 4 | Time: 36 s | Train Loss: 1.2013 Vali Loss: 5.0095
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:27:50.
Model parameters: 9390039
Total memory: 7967.4 MB
Allocated memory: 174.0 MB
Max allocated memory: 1785.6 MB
Time per epoch: 38.1 sec.
Memory usage: Available 7967.4 MB, Allocated 174.0 MB, Max allocated 1785.6 MB

Loading model from results/Exchange_Rate_Report/TimesNet_sl_96_pl_48/3/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 200
Preds and Trues shape: (200, 48, 7) (200, 48, 7)
test scaled -- mse:3.2583, mae:1.448
Upscaling data and removing negatives...
test -- mse:5.322, mae:0.76341, rmsle: 0.020232 smape 1.9363

Running for model:iTransformer
Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='Exchange_Rate_Report.csv', features='M', n_features=7, target='OT', freq='d', no_scale=False, seq_len=96, label_len=48, pred_len=48, top_k=5, num_kernels=6, d_model=64, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, channel_independence=1, decomp_method='moving_avg', use_norm=1, down_sampling_layers=0, down_sampling_window=1, down_sampling_method=None, seg_len=48, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, dry_run=False, percent=100, model='iTransformer', use_gpu=True, enc_in=7, dec_in=7, c_out=7, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Exchange_Rate_Report/iTransformer_sl_96_pl_48/1

Experiment begins at 2024-09-06 01:28:00

>>>>>>> start training :>>>>>>>>>>
train 1837
val 201
Epoch: 1 | Time: 2.41 s | Train Loss: 5.2569 Vali Loss: 2.0144
Validation loss decreased (inf --> 2.014351).  Saving model ...
Epoch: 2 | Time: 2.06 s | Train Loss: 4.5102 Vali Loss: 2.3564
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 2.05 s | Train Loss: 4.1828 Vali Loss: 2.7145
EarlyStopping counter: 2 out of 3
Epoch: 4 | Time: 2.05 s | Train Loss: 3.9384 Vali Loss: 2.4653
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:28:09.
Model parameters: 76400
Total memory: 7967.4 MB
Allocated memory: 17.6 MB
Max allocated memory: 148.2 MB
Time per epoch: 2.4 sec.
Memory usage: Available 7967.4 MB, Allocated 17.6 MB, Max allocated 148.2 MB

Loading model from results/Exchange_Rate_Report/iTransformer_sl_96_pl_48/1/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 200
Preds and Trues shape: (200, 48, 7) (200, 48, 7)
test scaled -- mse:1.6549, mae:0.95155
Upscaling data and removing negatives...
test -- mse:1.9831, mae:0.45657, rmsle: 0.012246 smape 1.2018


>>>> itr_no: 2, seed: 506 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Exchange_Rate_Report/iTransformer_sl_96_pl_48/2

Experiment begins at 2024-09-06 01:28:10

>>>>>>> start training :>>>>>>>>>>
train 1837
val 201
Epoch: 1 | Time: 2.02 s | Train Loss: 5.3159 Vali Loss: 2.06
Validation loss decreased (inf --> 2.059983).  Saving model ...
Epoch: 2 | Time: 2.07 s | Train Loss: 4.4702 Vali Loss: 2.2223
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 2.06 s | Train Loss: 4.1381 Vali Loss: 2.2039
EarlyStopping counter: 2 out of 3
Epoch: 4 | Time: 2.05 s | Train Loss: 3.8984 Vali Loss: 2.2926
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:28:18.
Model parameters: 76400
Total memory: 7967.4 MB
Allocated memory: 17.6 MB
Max allocated memory: 148.2 MB
Time per epoch: 2.2 sec.
Memory usage: Available 7967.4 MB, Allocated 17.6 MB, Max allocated 148.2 MB

Loading model from results/Exchange_Rate_Report/iTransformer_sl_96_pl_48/2/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 200
Preds and Trues shape: (200, 48, 7) (200, 48, 7)
test scaled -- mse:1.5686, mae:0.92522
Upscaling data and removing negatives...
test -- mse:1.8735, mae:0.4461, rmsle: 0.011895 smape 1.1863


>>>> itr_no: 3, seed: 608 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Exchange_Rate_Report/iTransformer_sl_96_pl_48/3

Experiment begins at 2024-09-06 01:28:19

>>>>>>> start training :>>>>>>>>>>
train 1837
val 201
Epoch: 1 | Time: 2.03 s | Train Loss: 5.2411 Vali Loss: 2.356
Validation loss decreased (inf --> 2.356014).  Saving model ...
Epoch: 2 | Time: 2.07 s | Train Loss: 4.5332 Vali Loss: 2.3847
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 2.07 s | Train Loss: 4.1939 Vali Loss: 2.5301
EarlyStopping counter: 2 out of 3
Epoch: 4 | Time: 2.08 s | Train Loss: 3.9994 Vali Loss: 2.6322
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:28:28.
Model parameters: 76400
Total memory: 7967.4 MB
Allocated memory: 17.6 MB
Max allocated memory: 148.2 MB
Time per epoch: 2.2 sec.
Memory usage: Available 7967.4 MB, Allocated 17.6 MB, Max allocated 148.2 MB

Loading model from results/Exchange_Rate_Report/iTransformer_sl_96_pl_48/3/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 200
Preds and Trues shape: (200, 48, 7) (200, 48, 7)
test scaled -- mse:2.1911, mae:1.1458
Upscaling data and removing negatives...
test -- mse:3.0215, mae:0.5663, rmsle: 0.014831 smape 1.491

Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='Exchange_Rate_Report.csv', features='M', n_features=7, target='OT', freq='d', no_scale=False, seq_len=96, label_len=96, pred_len=48, top_k=5, num_kernels=6, d_model=64, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, channel_independence=1, decomp_method='moving_avg', use_norm=1, down_sampling_layers=0, down_sampling_window=1, down_sampling_method=None, seg_len=48, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, dry_run=False, percent=100, model='MICN', use_gpu=True, enc_in=7, dec_in=7, c_out=7, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Exchange_Rate_Report/MICN_sl_96_pl_48/1

Experiment begins at 2024-09-06 01:28:34

>>>>>>> start training :>>>>>>>>>>
train 1837
val 201
Epoch: 1 | Time: 2.67 s | Train Loss: 5.4184 Vali Loss: 2.3741
Validation loss decreased (inf --> 2.374140).  Saving model ...
Epoch: 2 | Time: 2.2 s | Train Loss: 4.7238 Vali Loss: 2.2681
Validation loss decreased (2.374140 --> 2.268132).  Saving model ...
Epoch: 3 | Time: 2.17 s | Train Loss: 4.5371 Vali Loss: 2.2666
Validation loss decreased (2.268132 --> 2.266645).  Saving model ...
Epoch: 4 | Time: 2.17 s | Train Loss: 4.1144 Vali Loss: 2.4408
EarlyStopping counter: 1 out of 3
Epoch: 5 | Time: 2.15 s | Train Loss: 3.7088 Vali Loss: 2.4527
EarlyStopping counter: 2 out of 3
Epoch: 6 | Time: 2.14 s | Train Loss: 3.3897 Vali Loss: 2.6375
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:28:49.
Model parameters: 372343
Total memory: 7967.4 MB
Allocated memory: 23.4 MB
Max allocated memory: 180.1 MB
Time per epoch: 2.5 sec.
Memory usage: Available 7967.4 MB, Allocated 23.4 MB, Max allocated 180.1 MB

Loading model from results/Exchange_Rate_Report/MICN_sl_96_pl_48/1/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 200
Preds and Trues shape: (200, 48, 7) (200, 48, 7)
test scaled -- mse:1.4665, mae:0.92858
Upscaling data and removing negatives...
test -- mse:1.8732, mae:0.46194, rmsle: 0.011826 smape 1.1815


>>>> itr_no: 2, seed: 506 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Exchange_Rate_Report/MICN_sl_96_pl_48/2

Experiment begins at 2024-09-06 01:28:49

>>>>>>> start training :>>>>>>>>>>
train 1837
val 201
Epoch: 1 | Time: 2.11 s | Train Loss: 5.5802 Vali Loss: 2.3977
Validation loss decreased (inf --> 2.397732).  Saving model ...
Epoch: 2 | Time: 2.14 s | Train Loss: 4.7685 Vali Loss: 2.2618
Validation loss decreased (2.397732 --> 2.261768).  Saving model ...
Epoch: 3 | Time: 2.14 s | Train Loss: 4.4758 Vali Loss: 2.23
Validation loss decreased (2.261768 --> 2.229960).  Saving model ...
Epoch: 4 | Time: 2.15 s | Train Loss: 4.2393 Vali Loss: 2.2894
EarlyStopping counter: 1 out of 3
Epoch: 5 | Time: 2.16 s | Train Loss: 3.8232 Vali Loss: 2.7364
EarlyStopping counter: 2 out of 3
Epoch: 6 | Time: 2.15 s | Train Loss: 3.4257 Vali Loss: 2.5373
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:29:03.
Model parameters: 372343
Total memory: 7967.4 MB
Allocated memory: 23.4 MB
Max allocated memory: 180.1 MB
Time per epoch: 2.3 sec.
Memory usage: Available 7967.4 MB, Allocated 23.4 MB, Max allocated 180.1 MB

Loading model from results/Exchange_Rate_Report/MICN_sl_96_pl_48/2/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 200
Preds and Trues shape: (200, 48, 7) (200, 48, 7)
test scaled -- mse:1.526, mae:0.95053
Upscaling data and removing negatives...
test -- mse:1.9017, mae:0.46391, rmsle: 0.012023 smape 1.2057


>>>> itr_no: 3, seed: 608 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Exchange_Rate_Report/MICN_sl_96_pl_48/3

Experiment begins at 2024-09-06 01:29:03

>>>>>>> start training :>>>>>>>>>>
train 1837
val 201
Epoch: 1 | Time: 2.06 s | Train Loss: 5.4383 Vali Loss: 2.3795
Validation loss decreased (inf --> 2.379453).  Saving model ...
Epoch: 2 | Time: 2.14 s | Train Loss: 4.7524 Vali Loss: 2.2838
Validation loss decreased (2.379453 --> 2.283782).  Saving model ...
Epoch: 3 | Time: 2.14 s | Train Loss: 4.4956 Vali Loss: 2.348
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 2.14 s | Train Loss: 4.198 Vali Loss: 2.4204
EarlyStopping counter: 2 out of 3
Epoch: 5 | Time: 2.14 s | Train Loss: 3.9339 Vali Loss: 2.4283
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:29:15.
Model parameters: 372343
Total memory: 7967.4 MB
Allocated memory: 23.4 MB
Max allocated memory: 180.1 MB
Time per epoch: 2.2 sec.
Memory usage: Available 7967.4 MB, Allocated 23.4 MB, Max allocated 180.1 MB

Loading model from results/Exchange_Rate_Report/MICN_sl_96_pl_48/3/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 200
Preds and Trues shape: (200, 48, 7) (200, 48, 7)
test scaled -- mse:1.6677, mae:0.9947
Upscaling data and removing negatives...
test -- mse:1.9576, mae:0.47728, rmsle: 0.012579 smape 1.287

Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='Exchange_Rate_Report.csv', features='M', n_features=7, target='OT', freq='d', no_scale=False, seq_len=96, label_len=0, pred_len=48, top_k=5, num_kernels=6, d_model=16, n_heads=4, e_layers=3, d_layers=1, d_ff=32, moving_avg=3, factor=3, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, channel_independence=1, decomp_method='moving_avg', use_norm=1, down_sampling_layers=3, down_sampling_window=2, down_sampling_method='avg', seg_len=48, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, dry_run=False, percent=100, model='TimeMixer', use_gpu=True, enc_in=7, dec_in=7, c_out=7, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Exchange_Rate_Report/TimeMixer_sl_96_pl_48/1

Experiment begins at 2024-09-06 01:29:21

>>>>>>> start training :>>>>>>>>>>
train 1837
val 201
Epoch: 1 | Time: 4.13 s | Train Loss: 5.6659 Vali Loss: 2.2424
Validation loss decreased (inf --> 2.242390).  Saving model ...
Epoch: 2 | Time: 3.84 s | Train Loss: 4.5353 Vali Loss: 2.037
Validation loss decreased (2.242390 --> 2.037048).  Saving model ...
Epoch: 3 | Time: 3.86 s | Train Loss: 4.3019 Vali Loss: 2.2086
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 3.83 s | Train Loss: 4.0679 Vali Loss: 2.4751
EarlyStopping counter: 2 out of 3
Epoch: 5 | Time: 3.83 s | Train Loss: 3.6856 Vali Loss: 2.4918
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:29:42.
Model parameters: 95473
Total memory: 7967.4 MB
Allocated memory: 18.2 MB
Max allocated memory: 108.0 MB
Time per epoch: 4.1 sec.
Memory usage: Available 7967.4 MB, Allocated 18.2 MB, Max allocated 108.0 MB

Loading model from results/Exchange_Rate_Report/TimeMixer_sl_96_pl_48/1/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 200
Preds and Trues shape: (200, 48, 7) (200, 48, 7)
test scaled -- mse:1.5174, mae:0.91162
Upscaling data and removing negatives...
test -- mse:1.9207, mae:0.43872, rmsle: 0.012018 smape 1.1558


>>>> itr_no: 2, seed: 506 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Exchange_Rate_Report/TimeMixer_sl_96_pl_48/2

Experiment begins at 2024-09-06 01:29:42

>>>>>>> start training :>>>>>>>>>>
train 1837
val 201
Epoch: 1 | Time: 3.82 s | Train Loss: 5.6378 Vali Loss: 2.1896
Validation loss decreased (inf --> 2.189551).  Saving model ...
Epoch: 2 | Time: 3.91 s | Train Loss: 4.5878 Vali Loss: 2.0607
Validation loss decreased (2.189551 --> 2.060747).  Saving model ...
Epoch: 3 | Time: 3.99 s | Train Loss: 4.346 Vali Loss: 2.1677
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 3.89 s | Train Loss: 4.1603 Vali Loss: 2.2827
EarlyStopping counter: 2 out of 3
Epoch: 5 | Time: 3.83 s | Train Loss: 4.0099 Vali Loss: 2.2831
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:30:03.
Model parameters: 95473
Total memory: 7967.4 MB
Allocated memory: 18.2 MB
Max allocated memory: 108.0 MB
Time per epoch: 4.0 sec.
Memory usage: Available 7967.4 MB, Allocated 18.2 MB, Max allocated 108.0 MB

Loading model from results/Exchange_Rate_Report/TimeMixer_sl_96_pl_48/2/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 200
Preds and Trues shape: (200, 48, 7) (200, 48, 7)
test scaled -- mse:1.4644, mae:0.90394
Upscaling data and removing negatives...
test -- mse:1.9412, mae:0.45238, rmsle: 0.011824 smape 1.1463


>>>> itr_no: 3, seed: 608 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Exchange_Rate_Report/TimeMixer_sl_96_pl_48/3

Experiment begins at 2024-09-06 01:30:03

>>>>>>> start training :>>>>>>>>>>
train 1837
val 201
Epoch: 1 | Time: 3.81 s | Train Loss: 5.8459 Vali Loss: 2.1372
Validation loss decreased (inf --> 2.137176).  Saving model ...
Epoch: 2 | Time: 3.82 s | Train Loss: 4.5523 Vali Loss: 1.994
Validation loss decreased (2.137176 --> 1.994007).  Saving model ...
Epoch: 3 | Time: 3.81 s | Train Loss: 4.3812 Vali Loss: 2.0894
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 3.81 s | Train Loss: 4.2547 Vali Loss: 2.0574
EarlyStopping counter: 2 out of 3
Epoch: 5 | Time: 3.88 s | Train Loss: 4.1592 Vali Loss: 2.0541
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:30:23.
Model parameters: 95473
Total memory: 7967.4 MB
Allocated memory: 18.2 MB
Max allocated memory: 108.0 MB
Time per epoch: 3.9 sec.
Memory usage: Available 7967.4 MB, Allocated 18.2 MB, Max allocated 108.0 MB

Loading model from results/Exchange_Rate_Report/TimeMixer_sl_96_pl_48/3/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 200
Preds and Trues shape: (200, 48, 7) (200, 48, 7)
test scaled -- mse:1.5245, mae:0.91741
Upscaling data and removing negatives...
test -- mse:1.9776, mae:0.45237, rmsle: 0.012005 smape 1.164

Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='Exchange_Rate_Report.csv', features='M', n_features=7, target='OT', freq='d', no_scale=False, seq_len=96, label_len=48, pred_len=48, top_k=5, num_kernels=6, d_model=768, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', dry_run=False, percent=100, model_id='ori', model='CALF', task_loss='l1', distill_loss='l1', logits_loss='l1', tmax=20, r=8, lora_alpha=32, lora_dropout=0.1, word_embedding_path='./utils/wte_pca_500.pt', task_w=1.0, feature_w=0.01, logits_w=1.0, gpt_layers=6, log_fine_name='CALF_result.txt', noise_scale=-100, bootstrap_eval=0, use_gpu=True, enc_in=7, dec_in=7, c_out=7, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
model_id  ori
Experiments will be saved in results/Exchange_Rate_Report/CALF_sl_96_pl_48_id_ori/1

Experiment begins at 2024-09-06 01:30:30

>>>>>>> start training :>>>>>>>>>>
train 1837
val 201
Loss function weights: 1.0 1.0 0.01
Orig-- ori
Epoch: 1 | Time: 5.03 s | Train Loss: 2.3138 Vali Loss: 2.3672
Validation loss decreased (inf --> 2.367196).  Saving model ...
Epoch: 2 | Time: 4.39 s | Train Loss: 2.2502 Vali Loss: 2.4446
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 4.39 s | Train Loss: 2.6187 Vali Loss: 2.7793
EarlyStopping counter: 2 out of 3
Epoch: 4 | Time: 4.38 s | Train Loss: 3.5265 Vali Loss: 3.1088
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:31:01.
Model parameters: 180070448
Total memory: 7967.4 MB
Allocated memory: 937.9 MB
Max allocated memory: 1311.1 MB
Time per epoch: 7.6 sec.
Memory usage: Available 7967.4 MB, Allocated 937.9 MB, Max allocated 1311.1 MB

Loading model from results/Exchange_Rate_Report/CALF_sl_96_pl_48_id_ori/1/llm.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 200
Preds and Trues shape: (200, 48, 7) (200, 48, 7)
test scaled -- mse:1.9846, mae:1.1061
Upscaling data and removing negatives...
test -- mse:2.3283, mae:0.53267, rmsle: 0.013408 smape 1.4284


>>>> itr_no: 2, seed: 506 <<<<<<
Use GPU: cuda:0
model_id  ori
Experiments will be saved in results/Exchange_Rate_Report/CALF_sl_96_pl_48_id_ori/2

Experiment begins at 2024-09-06 01:31:03

>>>>>>> start training :>>>>>>>>>>
train 1837
val 201
Loss function weights: 1.0 1.0 0.01
Orig-- ori
Epoch: 1 | Time: 4.36 s | Train Loss: 2.3274 Vali Loss: 3.2878
Validation loss decreased (inf --> 3.287804).  Saving model ...
Epoch: 2 | Time: 4.39 s | Train Loss: 2.0645 Vali Loss: 2.2759
Validation loss decreased (3.287804 --> 2.275925).  Saving model ...
Epoch: 3 | Time: 4.39 s | Train Loss: 1.9991 Vali Loss: 2.6609
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 4.37 s | Train Loss: 2.7136 Vali Loss: 2.6729
EarlyStopping counter: 2 out of 3
Epoch: 5 | Time: 4.41 s | Train Loss: 3.4238 Vali Loss: 3.5352
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:31:53.
Model parameters: 180070448
Total memory: 7967.4 MB
Allocated memory: 945.3 MB
Max allocated memory: 1628.1 MB
Time per epoch: 9.9 sec.
Memory usage: Available 7967.4 MB, Allocated 945.3 MB, Max allocated 1628.1 MB

Loading model from results/Exchange_Rate_Report/CALF_sl_96_pl_48_id_ori/2/llm.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 200
Preds and Trues shape: (200, 48, 7) (200, 48, 7)
test scaled -- mse:1.7455, mae:1.004
Upscaling data and removing negatives...
test -- mse:2.202, mae:0.51644, rmsle: 0.012929 smape 1.3146


>>>> itr_no: 3, seed: 608 <<<<<<
Use GPU: cuda:0
model_id  ori
Experiments will be saved in results/Exchange_Rate_Report/CALF_sl_96_pl_48_id_ori/3

Experiment begins at 2024-09-06 01:31:54

>>>>>>> start training :>>>>>>>>>>
train 1837
val 201
Loss function weights: 1.0 1.0 0.01
Orig-- ori
Epoch: 1 | Time: 4.38 s | Train Loss: 2.2766 Vali Loss: 2.1663
Validation loss decreased (inf --> 2.166256).  Saving model ...
Epoch: 2 | Time: 4.52 s | Train Loss: 2.1651 Vali Loss: 2.2518
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 4.52 s | Train Loss: 2.421 Vali Loss: 2.536
EarlyStopping counter: 2 out of 3
Epoch: 4 | Time: 4.56 s | Train Loss: 3.2281 Vali Loss: 3.3401
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:32:21.
Model parameters: 180070448
Total memory: 7967.4 MB
Allocated memory: 941.3 MB
Max allocated memory: 1633.8 MB
Time per epoch: 6.6 sec.
Memory usage: Available 7967.4 MB, Allocated 941.3 MB, Max allocated 1633.8 MB

Loading model from results/Exchange_Rate_Report/CALF_sl_96_pl_48_id_ori/3/llm.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 200
Preds and Trues shape: (200, 48, 7) (200, 48, 7)
test scaled -- mse:1.8454, mae:1.0493
Upscaling data and removing negatives...
test -- mse:2.391, mae:0.52999, rmsle: 0.013266 smape 1.3553

Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='Exchange_Rate_Report.csv', features='M', n_features=7, target='OT', freq='d', no_scale=False, seq_len=96, label_len=48, pred_len=48, top_k=5, num_kernels=6, d_model=768, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', dry_run=False, percent=100, model_id='ori', model='OFA', gpt_layers=6, is_gpt=1, patch_size=16, kernel_size=25, pretrain=1, freeze=1, stride=8, max_len=-1, hid_dim=16, tmax=20, n_scale=-1, use_gpu=True, enc_in=7, dec_in=7, c_out=7, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Exchange_Rate_Report/OFA_sl_96_pl_48_id_ori/1

Experiment begins at 2024-09-06 01:32:29

>>>>>>> start training :>>>>>>>>>>
train 1837
val 201
Epoch: 1 | Time: 7.24 s | Train Loss: 1.3579 Vali Loss: 1.0808
Validation loss decreased (inf --> 1.080815).  Saving model ...
Epoch: 2 | Time: 7.01 s | Train Loss: 1.2591 Vali Loss: 1.0858
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 6.98 s | Train Loss: 1.2544 Vali Loss: 1.0847
EarlyStopping counter: 2 out of 3
Epoch: 4 | Time: 6.98 s | Train Loss: 1.2525 Vali Loss: 1.0745
Validation loss decreased (1.080815 --> 1.074502).  Saving model ...
Epoch: 5 | Time: 7.02 s | Train Loss: 1.2384 Vali Loss: 1.0766
EarlyStopping counter: 1 out of 3
Epoch: 6 | Time: 7.01 s | Train Loss: 1.2357 Vali Loss: 1.0833
EarlyStopping counter: 2 out of 3
Epoch: 7 | Time: 7.04 s | Train Loss: 1.2348 Vali Loss: 1.0829
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:33:28.
Model parameters: 82368048
Total memory: 7967.4 MB
Allocated memory: 353.7 MB
Max allocated memory: 1609.5 MB
Time per epoch: 8.3 sec.
Memory usage: Available 7967.4 MB, Allocated 353.7 MB, Max allocated 1609.5 MB

Loading model from results/Exchange_Rate_Report/OFA_sl_96_pl_48_id_ori/1/llm.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 200
Preds and Trues shape: (200, 48, 7) (200, 48, 7)
test scaled -- mse:1.5294, mae:0.91764
Upscaling data and removing negatives...
test -- mse:1.9315, mae:0.46067, rmsle: 0.011882 smape 1.1662


>>>> itr_no: 2, seed: 506 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Exchange_Rate_Report/OFA_sl_96_pl_48_id_ori/2

Experiment begins at 2024-09-06 01:33:29

>>>>>>> start training :>>>>>>>>>>
train 1837
val 201
Epoch: 1 | Time: 7.04 s | Train Loss: 1.36 Vali Loss: 1.0848
Validation loss decreased (inf --> 1.084753).  Saving model ...
Epoch: 2 | Time: 7.06 s | Train Loss: 1.2738 Vali Loss: 1.0867
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 7.04 s | Train Loss: 1.2584 Vali Loss: 1.0854
EarlyStopping counter: 2 out of 3
Epoch: 4 | Time: 7.06 s | Train Loss: 1.2496 Vali Loss: 1.0944
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:34:01.
Model parameters: 82368048
Total memory: 7967.4 MB
Allocated memory: 355.1 MB
Max allocated memory: 1615.3 MB
Time per epoch: 8.0 sec.
Memory usage: Available 7967.4 MB, Allocated 355.1 MB, Max allocated 1615.3 MB

Loading model from results/Exchange_Rate_Report/OFA_sl_96_pl_48_id_ori/2/llm.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 200
Preds and Trues shape: (200, 48, 7) (200, 48, 7)
test scaled -- mse:1.5634, mae:0.93018
Upscaling data and removing negatives...
test -- mse:2.0441, mae:0.46935, rmsle: 0.012115 smape 1.1793


>>>> itr_no: 3, seed: 608 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Exchange_Rate_Report/OFA_sl_96_pl_48_id_ori/3

Experiment begins at 2024-09-06 01:34:03

>>>>>>> start training :>>>>>>>>>>
train 1837
val 201
Epoch: 1 | Time: 7.06 s | Train Loss: 1.3646 Vali Loss: 1.0803
Validation loss decreased (inf --> 1.080256).  Saving model ...
Epoch: 2 | Time: 7.08 s | Train Loss: 1.2717 Vali Loss: 1.1013
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 7.02 s | Train Loss: 1.2524 Vali Loss: 1.0677
Validation loss decreased (1.080256 --> 1.067736).  Saving model ...
Epoch: 4 | Time: 7.11 s | Train Loss: 1.2446 Vali Loss: 1.0744
EarlyStopping counter: 1 out of 3
Epoch: 5 | Time: 7.04 s | Train Loss: 1.2399 Vali Loss: 1.0845
EarlyStopping counter: 2 out of 3
Epoch: 6 | Time: 7.05 s | Train Loss: 1.232 Vali Loss: 1.076
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:34:53.
Model parameters: 82368048
Total memory: 7967.4 MB
Allocated memory: 353.7 MB
Max allocated memory: 1615.3 MB
Time per epoch: 8.4 sec.
Memory usage: Available 7967.4 MB, Allocated 353.7 MB, Max allocated 1615.3 MB

Loading model from results/Exchange_Rate_Report/OFA_sl_96_pl_48_id_ori/3/llm.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 200
Preds and Trues shape: (200, 48, 7) (200, 48, 7)
test scaled -- mse:1.4807, mae:0.91075
Upscaling data and removing negatives...
test -- mse:1.9768, mae:0.47185, rmsle: 0.011854 smape 1.1608

Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='Exchange_Rate_Report.csv', features='M', n_features=7, target='OT', freq='d', no_scale=False, seq_len=96, label_len=48, pred_len=48, top_k=5, num_kernels=6, d_model=16, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=16, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', dry_run=False, percent=100, model_id='ori', model='TimeLLM', patch_len=16, stride=8, prompt_domain=1, llm_model='GPT2', llm_dim=768, llm_layers=6, use_gpu=True, enc_in=7, dec_in=7, c_out=7, task_name='long_term_forecast', content='Currency exchange rate between dollar and other international currencies')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
description: Currency exchange rate between dollar and other international currencies
Experiments will be saved in results/Exchange_Rate_Report/TimeLLM_sl_96_pl_48_id_ori/1

Experiment begins at 2024-09-06 01:35:01

>>>>>>> start training :>>>>>>>>>>
train 1837
val 201
Traceback (most recent call last):
  File "/u/mi3se/projects/Financial-Time-Series/run_TimeLLM.py", line 95, in <module>
    main(args)
  File "/u/mi3se/projects/Financial-Time-Series/run_TimeLLM.py", line 50, in main
    exp.train()
  File "/u/mi3se/projects/Financial-Time-Series/exp/exp_long_term_forecasting.py", line 191, in train
    outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/u/mi3se/projects/Financial-Time-Series/models/TimeLLM.py", line 240, in forward
    dec_out = self.forecast(x_enc, x_mark_enc, x_dec, x_mark_dec)
  File "/u/mi3se/projects/Financial-Time-Series/models/TimeLLM.py", line 342, in forecast
    dec_out = self.llm_model(inputs_embeds=llama_enc_out).last_hidden_state
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 1129, in forward
    outputs = block(
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 651, in forward
    feed_forward_hidden_states = self.mlp(hidden_states)
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 575, in forward
    hidden_states = self.act(hidden_states)
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/u/mi3se/anaconda3/envs/ml/lib/python3.10/site-packages/transformers/activations.py", line 56, in forward
    return 0.5 * input * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (input + 0.044715 * torch.pow(input, 3.0))))
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 168.00 MiB. GPU 
Running for model:DLinear
Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='Gold.csv', features='M', n_features=5, target='OT', freq='d', no_scale=False, seq_len=96, label_len=48, pred_len=48, top_k=5, num_kernels=6, d_model=64, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, channel_independence=1, decomp_method='moving_avg', use_norm=1, down_sampling_layers=0, down_sampling_window=1, down_sampling_method=None, seg_len=48, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, dry_run=False, percent=100, model='DLinear', use_gpu=True, enc_in=5, dec_in=5, c_out=5, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Gold/DLinear_sl_96_pl_48/1

Experiment begins at 2024-09-06 01:35:07

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Epoch: 1 | Time: 1.75 s | Train Loss: 3.6485 Vali Loss: 1.8439
Validation loss decreased (inf --> 1.843888).  Saving model ...
Epoch: 2 | Time: 1.67 s | Train Loss: 3.1204 Vali Loss: 1.7189
Validation loss decreased (1.843888 --> 1.718898).  Saving model ...
Epoch: 3 | Time: 1.65 s | Train Loss: 2.9829 Vali Loss: 1.6398
Validation loss decreased (1.718898 --> 1.639826).  Saving model ...
Epoch: 4 | Time: 1.7 s | Train Loss: 2.9185 Vali Loss: 1.6196
Validation loss decreased (1.639826 --> 1.619588).  Saving model ...
Epoch: 5 | Time: 1.67 s | Train Loss: 2.8778 Vali Loss: 1.6125
Validation loss decreased (1.619588 --> 1.612504).  Saving model ...
Epoch: 6 | Time: 1.65 s | Train Loss: 2.8515 Vali Loss: 1.5699
Validation loss decreased (1.612504 --> 1.569855).  Saving model ...
Epoch: 7 | Time: 1.65 s | Train Loss: 2.8298 Vali Loss: 1.5926
EarlyStopping counter: 1 out of 3
Epoch: 8 | Time: 1.62 s | Train Loss: 2.8166 Vali Loss: 1.5604
Validation loss decreased (1.569855 --> 1.560399).  Saving model ...
Epoch: 9 | Time: 1.63 s | Train Loss: 2.8101 Vali Loss: 1.555
Validation loss decreased (1.560399 --> 1.555028).  Saving model ...
Epoch: 10 | Time: 1.65 s | Train Loss: 2.8053 Vali Loss: 1.5714
EarlyStopping counter: 1 out of 3

Training completed at 2024-09-06 01:35:26.
Model parameters: 9312
Total memory: 7967.4 MB
Allocated memory: 16.6 MB
Max allocated memory: 17.1 MB
Time per epoch: 1.9 sec.
Memory usage: Available 7967.4 MB, Allocated 16.6 MB, Max allocated 17.1 MB

Loading model from results/Gold/DLinear_sl_96_pl_48/1/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:4.3293, mae:1.394
Upscaling data and removing negatives...
test -- mse:9.7675e+08, mae:11155, rmsle: 0.15796 smape 8.1781


>>>> itr_no: 2, seed: 506 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Gold/DLinear_sl_96_pl_48/2

Experiment begins at 2024-09-06 01:35:27

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Epoch: 1 | Time: 1.61 s | Train Loss: 3.6691 Vali Loss: 1.8906
Validation loss decreased (inf --> 1.890645).  Saving model ...
Epoch: 2 | Time: 1.64 s | Train Loss: 3.1411 Vali Loss: 1.7417
Validation loss decreased (1.890645 --> 1.741678).  Saving model ...
Epoch: 3 | Time: 1.64 s | Train Loss: 2.9918 Vali Loss: 1.7051
Validation loss decreased (1.741678 --> 1.705058).  Saving model ...
Epoch: 4 | Time: 1.63 s | Train Loss: 2.9356 Vali Loss: 1.6431
Validation loss decreased (1.705058 --> 1.643134).  Saving model ...
Epoch: 5 | Time: 1.64 s | Train Loss: 2.8856 Vali Loss: 1.6061
Validation loss decreased (1.643134 --> 1.606104).  Saving model ...
Epoch: 6 | Time: 1.64 s | Train Loss: 2.8606 Vali Loss: 1.5948
Validation loss decreased (1.606104 --> 1.594757).  Saving model ...
Epoch: 7 | Time: 1.65 s | Train Loss: 2.8372 Vali Loss: 1.5692
Validation loss decreased (1.594757 --> 1.569205).  Saving model ...
Epoch: 8 | Time: 1.63 s | Train Loss: 2.8268 Vali Loss: 1.5534
Validation loss decreased (1.569205 --> 1.553435).  Saving model ...
Epoch: 9 | Time: 1.65 s | Train Loss: 2.8087 Vali Loss: 1.5677
EarlyStopping counter: 1 out of 3
Epoch: 10 | Time: 1.67 s | Train Loss: 2.8048 Vali Loss: 1.55
Validation loss decreased (1.553435 --> 1.549966).  Saving model ...

Training completed at 2024-09-06 01:35:44.
Model parameters: 9312
Total memory: 7967.4 MB
Allocated memory: 16.6 MB
Max allocated memory: 17.1 MB
Time per epoch: 1.8 sec.
Memory usage: Available 7967.4 MB, Allocated 16.6 MB, Max allocated 17.1 MB

Loading model from results/Gold/DLinear_sl_96_pl_48/2/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:4.3398, mae:1.3944
Upscaling data and removing negatives...
test -- mse:9.8798e+08, mae:11190, rmsle: 0.1586 smape 8.1954


>>>> itr_no: 3, seed: 608 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Gold/DLinear_sl_96_pl_48/3

Experiment begins at 2024-09-06 01:35:45

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Epoch: 1 | Time: 1.63 s | Train Loss: 3.6239 Vali Loss: 1.8578
Validation loss decreased (inf --> 1.857762).  Saving model ...
Epoch: 2 | Time: 1.67 s | Train Loss: 3.1228 Vali Loss: 1.7178
Validation loss decreased (1.857762 --> 1.717822).  Saving model ...
Epoch: 3 | Time: 1.71 s | Train Loss: 2.9784 Vali Loss: 1.6826
Validation loss decreased (1.717822 --> 1.682619).  Saving model ...
Epoch: 4 | Time: 1.68 s | Train Loss: 2.9205 Vali Loss: 1.6116
Validation loss decreased (1.682619 --> 1.611600).  Saving model ...
Epoch: 5 | Time: 1.66 s | Train Loss: 2.8801 Vali Loss: 1.5983
Validation loss decreased (1.611600 --> 1.598335).  Saving model ...
Epoch: 6 | Time: 1.7 s | Train Loss: 2.8459 Vali Loss: 1.5846
Validation loss decreased (1.598335 --> 1.584592).  Saving model ...
Epoch: 7 | Time: 1.68 s | Train Loss: 2.8377 Vali Loss: 1.5937
EarlyStopping counter: 1 out of 3
Epoch: 8 | Time: 1.68 s | Train Loss: 2.8267 Vali Loss: 1.5393
Validation loss decreased (1.584592 --> 1.539335).  Saving model ...
Epoch: 9 | Time: 1.7 s | Train Loss: 2.8119 Vali Loss: 1.5726
EarlyStopping counter: 1 out of 3
Epoch: 10 | Time: 1.69 s | Train Loss: 2.8007 Vali Loss: 1.5243
Validation loss decreased (1.539335 --> 1.524308).  Saving model ...

Training completed at 2024-09-06 01:36:03.
Model parameters: 9312
Total memory: 7967.4 MB
Allocated memory: 16.6 MB
Max allocated memory: 17.1 MB
Time per epoch: 1.8 sec.
Memory usage: Available 7967.4 MB, Allocated 16.6 MB, Max allocated 17.1 MB

Loading model from results/Gold/DLinear_sl_96_pl_48/3/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:4.3269, mae:1.3963
Upscaling data and removing negatives...
test -- mse:9.6332e+08, mae:11050, rmsle: 0.15698 smape 8.1638

Running for model:PatchTST
Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='Gold.csv', features='M', n_features=5, target='OT', freq='d', no_scale=False, seq_len=96, label_len=48, pred_len=48, top_k=5, num_kernels=6, d_model=64, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, channel_independence=1, decomp_method='moving_avg', use_norm=1, down_sampling_layers=0, down_sampling_window=1, down_sampling_method=None, seg_len=48, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, dry_run=False, percent=100, model='PatchTST', use_gpu=True, enc_in=5, dec_in=5, c_out=5, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Gold/PatchTST_sl_96_pl_48/1

Experiment begins at 2024-09-06 01:36:09

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Epoch: 1 | Time: 2.28 s | Train Loss: 3.2919 Vali Loss: 1.7148
Validation loss decreased (inf --> 1.714828).  Saving model ...
Epoch: 2 | Time: 2.05 s | Train Loss: 2.8696 Vali Loss: 1.7396
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 2.02 s | Train Loss: 2.6862 Vali Loss: 1.6335
Validation loss decreased (1.714828 --> 1.633518).  Saving model ...
Epoch: 4 | Time: 2.04 s | Train Loss: 2.375 Vali Loss: 1.4692
Validation loss decreased (1.633518 --> 1.469222).  Saving model ...
Epoch: 5 | Time: 2.04 s | Train Loss: 2.0703 Vali Loss: 1.5908
EarlyStopping counter: 1 out of 3
Epoch: 6 | Time: 2.04 s | Train Loss: 1.9 Vali Loss: 1.982
EarlyStopping counter: 2 out of 3
Epoch: 7 | Time: 2.03 s | Train Loss: 1.676 Vali Loss: 2.145
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:36:25.
Model parameters: 105008
Total memory: 7967.4 MB
Allocated memory: 19.3 MB
Max allocated memory: 169.0 MB
Time per epoch: 2.3 sec.
Memory usage: Available 7967.4 MB, Allocated 19.3 MB, Max allocated 169.0 MB

Loading model from results/Gold/PatchTST_sl_96_pl_48/1/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:5.1324, mae:1.6014
Upscaling data and removing negatives...
test -- mse:1.3433e+09, mae:12892, rmsle: 0.38832 smape 10.178


>>>> itr_no: 2, seed: 506 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Gold/PatchTST_sl_96_pl_48/2

Experiment begins at 2024-09-06 01:36:26

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Epoch: 1 | Time: 2 s | Train Loss: 3.2777 Vali Loss: 2.1263
Validation loss decreased (inf --> 2.126308).  Saving model ...
Epoch: 2 | Time: 2.08 s | Train Loss: 2.8588 Vali Loss: 1.5587
Validation loss decreased (2.126308 --> 1.558702).  Saving model ...
Epoch: 3 | Time: 2.16 s | Train Loss: 2.5841 Vali Loss: 1.745
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 2.13 s | Train Loss: 2.324 Vali Loss: 1.3543
Validation loss decreased (1.558702 --> 1.354339).  Saving model ...
Epoch: 5 | Time: 2.16 s | Train Loss: 2.0934 Vali Loss: 1.7823
EarlyStopping counter: 1 out of 3
Epoch: 6 | Time: 2.11 s | Train Loss: 1.8831 Vali Loss: 1.6498
EarlyStopping counter: 2 out of 3
Epoch: 7 | Time: 2.12 s | Train Loss: 1.6882 Vali Loss: 1.5177
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:36:42.
Model parameters: 105008
Total memory: 7967.4 MB
Allocated memory: 19.3 MB
Max allocated memory: 169.0 MB
Time per epoch: 2.2 sec.
Memory usage: Available 7967.4 MB, Allocated 19.3 MB, Max allocated 169.0 MB

Loading model from results/Gold/PatchTST_sl_96_pl_48/2/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:5.8932, mae:1.6684
Upscaling data and removing negatives...
test -- mse:1.1147e+09, mae:11731, rmsle: 0.30775 smape 9.3172


>>>> itr_no: 3, seed: 608 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Gold/PatchTST_sl_96_pl_48/3

Experiment begins at 2024-09-06 01:36:42

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Epoch: 1 | Time: 1.99 s | Train Loss: 3.2887 Vali Loss: 1.6944
Validation loss decreased (inf --> 1.694354).  Saving model ...
Epoch: 2 | Time: 2.03 s | Train Loss: 2.9196 Vali Loss: 1.6857
Validation loss decreased (1.694354 --> 1.685686).  Saving model ...
Epoch: 3 | Time: 2.01 s | Train Loss: 2.7156 Vali Loss: 1.8088
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 2.02 s | Train Loss: 2.4044 Vali Loss: 1.2264
Validation loss decreased (1.685686 --> 1.226400).  Saving model ...
Epoch: 5 | Time: 2.01 s | Train Loss: 2.0956 Vali Loss: 1.8804
EarlyStopping counter: 1 out of 3
Epoch: 6 | Time: 2.01 s | Train Loss: 1.9256 Vali Loss: 1.6388
EarlyStopping counter: 2 out of 3
Epoch: 7 | Time: 2.01 s | Train Loss: 1.7333 Vali Loss: 1.5445
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:36:57.
Model parameters: 105008
Total memory: 7967.4 MB
Allocated memory: 19.3 MB
Max allocated memory: 169.0 MB
Time per epoch: 2.1 sec.
Memory usage: Available 7967.4 MB, Allocated 19.3 MB, Max allocated 169.0 MB

Loading model from results/Gold/PatchTST_sl_96_pl_48/3/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:5.9897, mae:1.7258
Upscaling data and removing negatives...
test -- mse:1.0987e+09, mae:11605, rmsle: 0.26879 smape 9.7802

Running for model:TimesNet
Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='Gold.csv', features='M', n_features=5, target='OT', freq='d', no_scale=False, seq_len=96, label_len=48, pred_len=48, top_k=5, num_kernels=6, d_model=64, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, channel_independence=1, decomp_method='moving_avg', use_norm=1, down_sampling_layers=0, down_sampling_window=1, down_sampling_method=None, seg_len=48, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, dry_run=False, percent=100, model='TimesNet', use_gpu=True, enc_in=5, dec_in=5, c_out=5, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Gold/TimesNet_sl_96_pl_48/1

Experiment begins at 2024-09-06 01:37:03

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Epoch: 1 | Time: 31.7 s | Train Loss: 3.1384 Vali Loss: 1.745
Validation loss decreased (inf --> 1.745000).  Saving model ...
Epoch: 2 | Time: 32.3 s | Train Loss: 2.6726 Vali Loss: 1.9366
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 33.5 s | Train Loss: 2.3663 Vali Loss: 2.2751
EarlyStopping counter: 2 out of 3
Epoch: 4 | Time: 34.9 s | Train Loss: 2.0893 Vali Loss: 2.177
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:39:17.
Model parameters: 9389525
Total memory: 7967.4 MB
Allocated memory: 167.6 MB
Max allocated memory: 1778.1 MB
Time per epoch: 33.5 sec.
Memory usage: Available 7967.4 MB, Allocated 167.6 MB, Max allocated 1778.1 MB

Loading model from results/Gold/TimesNet_sl_96_pl_48/1/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:5.0697, mae:1.5709
Upscaling data and removing negatives...
test -- mse:8.0025e+08, mae:9933.9, rmsle: 0.14798 smape 8.4235


>>>> itr_no: 2, seed: 506 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Gold/TimesNet_sl_96_pl_48/2

Experiment begins at 2024-09-06 01:39:20

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Epoch: 1 | Time: 48.1 s | Train Loss: 3.1958 Vali Loss: 1.5867
Validation loss decreased (inf --> 1.586701).  Saving model ...
Epoch: 2 | Time: 49.2 s | Train Loss: 2.6848 Vali Loss: 1.7673
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 49.9 s | Train Loss: 2.6308 Vali Loss: 1.7361
EarlyStopping counter: 2 out of 3
Epoch: 4 | Time: 52.6 s | Train Loss: 2.3738 Vali Loss: 1.7851
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:42:41.
Model parameters: 9389525
Total memory: 7967.4 MB
Allocated memory: 171.4 MB
Max allocated memory: 1784.7 MB
Time per epoch: 50.2 sec.
Memory usage: Available 7967.4 MB, Allocated 171.4 MB, Max allocated 1784.7 MB

Loading model from results/Gold/TimesNet_sl_96_pl_48/2/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:4.2219, mae:1.4043
Upscaling data and removing negatives...
test -- mse:7.9214e+08, mae:9914.8, rmsle: 0.14611 smape 7.8459


>>>> itr_no: 3, seed: 608 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Gold/TimesNet_sl_96_pl_48/3

Experiment begins at 2024-09-06 01:42:45

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Epoch: 1 | Time: 26.1 s | Train Loss: 3.3165 Vali Loss: 1.5871
Validation loss decreased (inf --> 1.587115).  Saving model ...
Epoch: 2 | Time: 28.3 s | Train Loss: 2.5331 Vali Loss: 1.5364
Validation loss decreased (1.587115 --> 1.536388).  Saving model ...
Epoch: 3 | Time: 29.5 s | Train Loss: 2.0148 Vali Loss: 1.7254
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 27.8 s | Train Loss: 1.5613 Vali Loss: 1.9205
EarlyStopping counter: 2 out of 3
Epoch: 5 | Time: 25.9 s | Train Loss: 1.1251 Vali Loss: 1.5352
Validation loss decreased (1.536388 --> 1.535248).  Saving model ...
Epoch: 6 | Time: 25.2 s | Train Loss: 0.96696 Vali Loss: 1.5904
EarlyStopping counter: 1 out of 3
Epoch: 7 | Time: 26.1 s | Train Loss: 0.87621 Vali Loss: 1.6869
EarlyStopping counter: 2 out of 3
Epoch: 8 | Time: 26.2 s | Train Loss: 0.82502 Vali Loss: 1.7408
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:46:22.
Model parameters: 9389525
Total memory: 7967.4 MB
Allocated memory: 169.9 MB
Max allocated memory: 1784.7 MB
Time per epoch: 27.2 sec.
Memory usage: Available 7967.4 MB, Allocated 169.9 MB, Max allocated 1784.7 MB

Loading model from results/Gold/TimesNet_sl_96_pl_48/3/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:5.4036, mae:1.5937
Upscaling data and removing negatives...
test -- mse:7.7738e+08, mae:9832.5, rmsle: 0.1468 smape 8.3125

Running for model:iTransformer
Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='Gold.csv', features='M', n_features=5, target='OT', freq='d', no_scale=False, seq_len=96, label_len=48, pred_len=48, top_k=5, num_kernels=6, d_model=64, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, channel_independence=1, decomp_method='moving_avg', use_norm=1, down_sampling_layers=0, down_sampling_window=1, down_sampling_method=None, seg_len=48, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, dry_run=False, percent=100, model='iTransformer', use_gpu=True, enc_in=5, dec_in=5, c_out=5, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Gold/iTransformer_sl_96_pl_48/1

Experiment begins at 2024-09-06 01:46:32

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Epoch: 1 | Time: 2.23 s | Train Loss: 3.4117 Vali Loss: 1.6621
Validation loss decreased (inf --> 1.662109).  Saving model ...
Epoch: 2 | Time: 2.01 s | Train Loss: 2.8687 Vali Loss: 1.6442
Validation loss decreased (1.662109 --> 1.644187).  Saving model ...
Epoch: 3 | Time: 2.02 s | Train Loss: 2.5409 Vali Loss: 1.6591
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 2.01 s | Train Loss: 2.2355 Vali Loss: 1.781
EarlyStopping counter: 2 out of 3
Epoch: 5 | Time: 2.01 s | Train Loss: 1.9292 Vali Loss: 1.7537
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:46:44.
Model parameters: 76400
Total memory: 7967.4 MB
Allocated memory: 17.7 MB
Max allocated memory: 147.6 MB
Time per epoch: 2.4 sec.
Memory usage: Available 7967.4 MB, Allocated 17.7 MB, Max allocated 147.6 MB

Loading model from results/Gold/iTransformer_sl_96_pl_48/1/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:4.2576, mae:1.417
Upscaling data and removing negatives...
test -- mse:1.3682e+09, mae:13539, rmsle: 0.18334 smape 9.067


>>>> itr_no: 2, seed: 506 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Gold/iTransformer_sl_96_pl_48/2

Experiment begins at 2024-09-06 01:46:44

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Epoch: 1 | Time: 1.97 s | Train Loss: 3.4363 Vali Loss: 1.6847
Validation loss decreased (inf --> 1.684689).  Saving model ...
Epoch: 2 | Time: 1.98 s | Train Loss: 2.8739 Vali Loss: 1.6534
Validation loss decreased (1.684689 --> 1.653440).  Saving model ...
Epoch: 3 | Time: 1.97 s | Train Loss: 2.5364 Vali Loss: 1.821
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 1.98 s | Train Loss: 2.1272 Vali Loss: 1.7581
EarlyStopping counter: 2 out of 3
Epoch: 5 | Time: 1.97 s | Train Loss: 1.8118 Vali Loss: 1.6617
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:46:55.
Model parameters: 76400
Total memory: 7967.4 MB
Allocated memory: 17.7 MB
Max allocated memory: 147.6 MB
Time per epoch: 2.1 sec.
Memory usage: Available 7967.4 MB, Allocated 17.7 MB, Max allocated 147.6 MB

Loading model from results/Gold/iTransformer_sl_96_pl_48/2/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:4.3324, mae:1.4294
Upscaling data and removing negatives...
test -- mse:1.433e+09, mae:13849, rmsle: 0.1937 smape 9.3939


>>>> itr_no: 3, seed: 608 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Gold/iTransformer_sl_96_pl_48/3

Experiment begins at 2024-09-06 01:46:55

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Epoch: 1 | Time: 1.94 s | Train Loss: 3.4294 Vali Loss: 1.6958
Validation loss decreased (inf --> 1.695778).  Saving model ...
Epoch: 2 | Time: 1.98 s | Train Loss: 2.8303 Vali Loss: 1.6847
Validation loss decreased (1.695778 --> 1.684710).  Saving model ...
Epoch: 3 | Time: 1.98 s | Train Loss: 2.509 Vali Loss: 1.6638
Validation loss decreased (1.684710 --> 1.663771).  Saving model ...
Epoch: 4 | Time: 1.98 s | Train Loss: 2.2722 Vali Loss: 1.7005
EarlyStopping counter: 1 out of 3
Epoch: 5 | Time: 1.98 s | Train Loss: 1.9691 Vali Loss: 1.8649
EarlyStopping counter: 2 out of 3
Epoch: 6 | Time: 1.96 s | Train Loss: 1.6966 Vali Loss: 1.9023
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:47:08.
Model parameters: 76400
Total memory: 7967.4 MB
Allocated memory: 17.7 MB
Max allocated memory: 147.6 MB
Time per epoch: 2.1 sec.
Memory usage: Available 7967.4 MB, Allocated 17.7 MB, Max allocated 147.6 MB

Loading model from results/Gold/iTransformer_sl_96_pl_48/3/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:4.6404, mae:1.5446
Upscaling data and removing negatives...
test -- mse:1.2585e+09, mae:12617, rmsle: 0.23225 smape 9.7015

Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='Gold.csv', features='M', n_features=5, target='OT', freq='d', no_scale=False, seq_len=96, label_len=96, pred_len=48, top_k=5, num_kernels=6, d_model=64, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, channel_independence=1, decomp_method='moving_avg', use_norm=1, down_sampling_layers=0, down_sampling_window=1, down_sampling_method=None, seg_len=48, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, dry_run=False, percent=100, model='MICN', use_gpu=True, enc_in=5, dec_in=5, c_out=5, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Gold/MICN_sl_96_pl_48/1

Experiment begins at 2024-09-06 01:47:15

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Epoch: 1 | Time: 2.4 s | Train Loss: 3.502 Vali Loss: 1.6061
Validation loss decreased (inf --> 1.606117).  Saving model ...
Epoch: 2 | Time: 2.09 s | Train Loss: 2.9246 Vali Loss: 1.5514
Validation loss decreased (1.606117 --> 1.551447).  Saving model ...
Epoch: 3 | Time: 2.08 s | Train Loss: 2.7476 Vali Loss: 1.4573
Validation loss decreased (1.551447 --> 1.457349).  Saving model ...
Epoch: 4 | Time: 2.09 s | Train Loss: 2.6084 Vali Loss: 1.6394
EarlyStopping counter: 1 out of 3
Epoch: 5 | Time: 2.08 s | Train Loss: 2.3845 Vali Loss: 1.7016
EarlyStopping counter: 2 out of 3
Epoch: 6 | Time: 2.07 s | Train Loss: 2.0186 Vali Loss: 1.8367
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:47:29.
Model parameters: 371829
Total memory: 7967.4 MB
Allocated memory: 23.4 MB
Max allocated memory: 179.9 MB
Time per epoch: 2.4 sec.
Memory usage: Available 7967.4 MB, Allocated 23.4 MB, Max allocated 179.9 MB

Loading model from results/Gold/MICN_sl_96_pl_48/1/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:3.8182, mae:1.3326
Upscaling data and removing negatives...
test -- mse:8.4285e+08, mae:10288, rmsle: 0.14823 smape 7.7677


>>>> itr_no: 2, seed: 506 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Gold/MICN_sl_96_pl_48/2

Experiment begins at 2024-09-06 01:47:29

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Epoch: 1 | Time: 2.06 s | Train Loss: 3.4759 Vali Loss: 1.5451
Validation loss decreased (inf --> 1.545088).  Saving model ...
Epoch: 2 | Time: 2.09 s | Train Loss: 2.9062 Vali Loss: 1.5086
Validation loss decreased (1.545088 --> 1.508609).  Saving model ...
Epoch: 3 | Time: 2.08 s | Train Loss: 2.7006 Vali Loss: 1.5372
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 2.08 s | Train Loss: 2.5654 Vali Loss: 1.7263
EarlyStopping counter: 2 out of 3
Epoch: 5 | Time: 2.07 s | Train Loss: 2.3553 Vali Loss: 1.6826
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:47:41.
Model parameters: 371829
Total memory: 7967.4 MB
Allocated memory: 23.4 MB
Max allocated memory: 179.9 MB
Time per epoch: 2.2 sec.
Memory usage: Available 7967.4 MB, Allocated 23.4 MB, Max allocated 179.9 MB

Loading model from results/Gold/MICN_sl_96_pl_48/2/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:3.7841, mae:1.3347
Upscaling data and removing negatives...
test -- mse:8.5892e+08, mae:10339, rmsle: 0.15024 smape 7.8364


>>>> itr_no: 3, seed: 608 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Gold/MICN_sl_96_pl_48/3

Experiment begins at 2024-09-06 01:47:41

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Epoch: 1 | Time: 2.05 s | Train Loss: 3.5035 Vali Loss: 1.6517
Validation loss decreased (inf --> 1.651684).  Saving model ...
Epoch: 2 | Time: 2.08 s | Train Loss: 2.9342 Vali Loss: 1.6056
Validation loss decreased (1.651684 --> 1.605578).  Saving model ...
Epoch: 3 | Time: 2.09 s | Train Loss: 2.7374 Vali Loss: 1.5949
Validation loss decreased (1.605578 --> 1.594945).  Saving model ...
Epoch: 4 | Time: 2.09 s | Train Loss: 2.5959 Vali Loss: 1.7153
EarlyStopping counter: 1 out of 3
Epoch: 5 | Time: 2.09 s | Train Loss: 2.3921 Vali Loss: 1.6222
EarlyStopping counter: 2 out of 3
Epoch: 6 | Time: 2.09 s | Train Loss: 2.0838 Vali Loss: 1.7013
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:47:54.
Model parameters: 371829
Total memory: 7967.4 MB
Allocated memory: 23.4 MB
Max allocated memory: 179.9 MB
Time per epoch: 2.2 sec.
Memory usage: Available 7967.4 MB, Allocated 23.4 MB, Max allocated 179.9 MB

Loading model from results/Gold/MICN_sl_96_pl_48/3/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:4.1936, mae:1.3725
Upscaling data and removing negatives...
test -- mse:8.6948e+08, mae:10357, rmsle: 0.15223 smape 7.9363

Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='Gold.csv', features='M', n_features=5, target='OT', freq='d', no_scale=False, seq_len=96, label_len=0, pred_len=48, top_k=5, num_kernels=6, d_model=16, n_heads=4, e_layers=3, d_layers=1, d_ff=32, moving_avg=3, factor=3, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, channel_independence=1, decomp_method='moving_avg', use_norm=1, down_sampling_layers=3, down_sampling_window=2, down_sampling_method='avg', seg_len=48, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, dry_run=False, percent=100, model='TimeMixer', use_gpu=True, enc_in=5, dec_in=5, c_out=5, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Gold/TimeMixer_sl_96_pl_48/1

Experiment begins at 2024-09-06 01:48:03

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Epoch: 1 | Time: 4.19 s | Train Loss: 3.5919 Vali Loss: 1.7523
Validation loss decreased (inf --> 1.752347).  Saving model ...
Epoch: 2 | Time: 3.83 s | Train Loss: 2.8169 Vali Loss: 1.8665
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 3.83 s | Train Loss: 2.462 Vali Loss: 2.2135
EarlyStopping counter: 2 out of 3
Epoch: 4 | Time: 3.8 s | Train Loss: 2.0371 Vali Loss: 2.311
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:48:20.
Model parameters: 95457
Total memory: 7967.4 MB
Allocated memory: 18.3 MB
Max allocated memory: 82.9 MB
Time per epoch: 4.2 sec.
Memory usage: Available 7967.4 MB, Allocated 18.3 MB, Max allocated 82.9 MB

Loading model from results/Gold/TimeMixer_sl_96_pl_48/1/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:4.4796, mae:1.4083
Upscaling data and removing negatives...
test -- mse:1.058e+09, mae:11621, rmsle: 0.1645 smape 8.3755


>>>> itr_no: 2, seed: 506 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Gold/TimeMixer_sl_96_pl_48/2

Experiment begins at 2024-09-06 01:48:20

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Epoch: 1 | Time: 3.89 s | Train Loss: 3.77 Vali Loss: 1.6551
Validation loss decreased (inf --> 1.655082).  Saving model ...
Epoch: 2 | Time: 3.84 s | Train Loss: 2.8639 Vali Loss: 1.6672
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 3.83 s | Train Loss: 2.6247 Vali Loss: 2.043
EarlyStopping counter: 2 out of 3
Epoch: 4 | Time: 3.88 s | Train Loss: 2.3552 Vali Loss: 1.8138
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:48:36.
Model parameters: 95457
Total memory: 7967.4 MB
Allocated memory: 18.3 MB
Max allocated memory: 82.9 MB
Time per epoch: 4.0 sec.
Memory usage: Available 7967.4 MB, Allocated 18.3 MB, Max allocated 82.9 MB

Loading model from results/Gold/TimeMixer_sl_96_pl_48/2/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:4.3187, mae:1.3952
Upscaling data and removing negatives...
test -- mse:9.6654e+08, mae:11078, rmsle: 0.15944 smape 8.1615


>>>> itr_no: 3, seed: 608 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Gold/TimeMixer_sl_96_pl_48/3

Experiment begins at 2024-09-06 01:48:37

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Epoch: 1 | Time: 3.87 s | Train Loss: 4.0426 Vali Loss: 1.6704
Validation loss decreased (inf --> 1.670370).  Saving model ...
Epoch: 2 | Time: 3.89 s | Train Loss: 2.8928 Vali Loss: 1.6361
Validation loss decreased (1.670370 --> 1.636122).  Saving model ...
Epoch: 3 | Time: 3.86 s | Train Loss: 2.7105 Vali Loss: 1.7692
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 3.83 s | Train Loss: 2.5453 Vali Loss: 1.853
EarlyStopping counter: 2 out of 3
Epoch: 5 | Time: 3.72 s | Train Loss: 2.347 Vali Loss: 1.9599
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:48:57.
Model parameters: 95457
Total memory: 7967.4 MB
Allocated memory: 18.3 MB
Max allocated memory: 82.9 MB
Time per epoch: 4.0 sec.
Memory usage: Available 7967.4 MB, Allocated 18.3 MB, Max allocated 82.9 MB

Loading model from results/Gold/TimeMixer_sl_96_pl_48/3/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:4.137, mae:1.3765
Upscaling data and removing negatives...
test -- mse:1.0591e+09, mae:11664, rmsle: 0.1635 smape 8.3145

Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='Gold.csv', features='M', n_features=5, target='OT', freq='d', no_scale=False, seq_len=96, label_len=48, pred_len=48, top_k=5, num_kernels=6, d_model=768, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', dry_run=False, percent=100, model_id='ori', model='CALF', task_loss='l1', distill_loss='l1', logits_loss='l1', tmax=20, r=8, lora_alpha=32, lora_dropout=0.1, word_embedding_path='./utils/wte_pca_500.pt', task_w=1.0, feature_w=0.01, logits_w=1.0, gpt_layers=6, log_fine_name='CALF_result.txt', noise_scale=-100, bootstrap_eval=0, use_gpu=True, enc_in=5, dec_in=5, c_out=5, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
model_id  ori
Experiments will be saved in results/Gold/CALF_sl_96_pl_48_id_ori/1

Experiment begins at 2024-09-06 01:49:08

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Loss function weights: 1.0 1.0 0.01
Orig-- ori
Epoch: 1 | Time: 4.58 s | Train Loss: 2.2162 Vali Loss: 1.5173
Validation loss decreased (inf --> 1.517285).  Saving model ...
Epoch: 2 | Time: 4.48 s | Train Loss: 2.1521 Vali Loss: 1.5822
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 4.55 s | Train Loss: 2.645 Vali Loss: 1.6363
EarlyStopping counter: 2 out of 3
Epoch: 4 | Time: 4.52 s | Train Loss: 3.2843 Vali Loss: 1.4695
Validation loss decreased (1.517285 --> 1.469509).  Saving model ...
Epoch: 5 | Time: 4.52 s | Train Loss: 5.8116 Vali Loss: 1.643
EarlyStopping counter: 1 out of 3
Epoch: 6 | Time: 4.5 s | Train Loss: 6.6474 Vali Loss: 1.6143
EarlyStopping counter: 2 out of 3
Epoch: 7 | Time: 4.37 s | Train Loss: 8.0209 Vali Loss: 1.4668
Validation loss decreased (1.469509 --> 1.466777).  Saving model ...
Epoch: 8 | Time: 4.38 s | Train Loss: 9.3047 Vali Loss: 1.4149
Validation loss decreased (1.466777 --> 1.414858).  Saving model ...
Epoch: 9 | Time: 4.46 s | Train Loss: 10.244 Vali Loss: 1.3625
Validation loss decreased (1.414858 --> 1.362453).  Saving model ...
Epoch: 10 | Time: 4.41 s | Train Loss: 9.9047 Vali Loss: 1.7289
EarlyStopping counter: 1 out of 3

Training completed at 2024-09-06 01:50:34.
Model parameters: 180070448
Total memory: 7967.4 MB
Allocated memory: 949.8 MB
Max allocated memory: 1254.8 MB
Time per epoch: 8.7 sec.
Memory usage: Available 7967.4 MB, Allocated 949.8 MB, Max allocated 1254.8 MB

Loading model from results/Gold/CALF_sl_96_pl_48_id_ori/1/llm.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:5.1005, mae:1.6523
Upscaling data and removing negatives...
test -- mse:1.5172e+09, mae:14297, rmsle: 0.27853 smape 11.065


>>>> itr_no: 2, seed: 506 <<<<<<
Use GPU: cuda:0
model_id  ori
Experiments will be saved in results/Gold/CALF_sl_96_pl_48_id_ori/2

Experiment begins at 2024-09-06 01:50:36

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Loss function weights: 1.0 1.0 0.01
Orig-- ori
Epoch: 1 | Time: 4.28 s | Train Loss: 2.1573 Vali Loss: 1.9029
Validation loss decreased (inf --> 1.902865).  Saving model ...
Epoch: 2 | Time: 4.27 s | Train Loss: 2.1085 Vali Loss: 1.5988
Validation loss decreased (1.902865 --> 1.598842).  Saving model ...
Epoch: 3 | Time: 4.28 s | Train Loss: 2.0961 Vali Loss: 1.7527
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 4.31 s | Train Loss: 2.813 Vali Loss: 1.5165
Validation loss decreased (1.598842 --> 1.516537).  Saving model ...
Epoch: 5 | Time: 4.29 s | Train Loss: 4.2492 Vali Loss: 1.9934
EarlyStopping counter: 1 out of 3
Epoch: 6 | Time: 4.29 s | Train Loss: 5.2203 Vali Loss: 1.7134
EarlyStopping counter: 2 out of 3
Epoch: 7 | Time: 4.31 s | Train Loss: 7.0426 Vali Loss: 1.6364
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:51:30.
Model parameters: 180070448
Total memory: 7967.4 MB
Allocated memory: 954.4 MB
Max allocated memory: 1640.8 MB
Time per epoch: 7.7 sec.
Memory usage: Available 7967.4 MB, Allocated 954.4 MB, Max allocated 1640.8 MB

Loading model from results/Gold/CALF_sl_96_pl_48_id_ori/2/llm.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:4.2268, mae:1.4605
Upscaling data and removing negatives...
test -- mse:1.551e+09, mae:14731, rmsle: 0.19917 smape 9.9151


>>>> itr_no: 3, seed: 608 <<<<<<
Use GPU: cuda:0
model_id  ori
Experiments will be saved in results/Gold/CALF_sl_96_pl_48_id_ori/3

Experiment begins at 2024-09-06 01:51:32

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Loss function weights: 1.0 1.0 0.01
Orig-- ori
Epoch: 1 | Time: 4.3 s | Train Loss: 2.0916 Vali Loss: 1.9583
Validation loss decreased (inf --> 1.958293).  Saving model ...
Epoch: 2 | Time: 4.3 s | Train Loss: 1.9597 Vali Loss: 1.8324
Validation loss decreased (1.958293 --> 1.832433).  Saving model ...
Epoch: 3 | Time: 4.29 s | Train Loss: 2.1251 Vali Loss: 1.9015
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 4.31 s | Train Loss: 2.4022 Vali Loss: 1.7849
Validation loss decreased (1.832433 --> 1.784881).  Saving model ...
Epoch: 5 | Time: 4.3 s | Train Loss: 3.0245 Vali Loss: 1.8448
EarlyStopping counter: 1 out of 3
Epoch: 6 | Time: 4.3 s | Train Loss: 3.9045 Vali Loss: 1.8939
EarlyStopping counter: 2 out of 3
Epoch: 7 | Time: 4.28 s | Train Loss: 5.6248 Vali Loss: 1.7462
Validation loss decreased (1.784881 --> 1.746167).  Saving model ...
Epoch: 8 | Time: 4.31 s | Train Loss: 7.314 Vali Loss: 1.8458
EarlyStopping counter: 1 out of 3
Epoch: 9 | Time: 4.33 s | Train Loss: 9.1381 Vali Loss: 1.5897
Validation loss decreased (1.746167 --> 1.589716).  Saving model ...
Epoch: 10 | Time: 4.3 s | Train Loss: 8.8189 Vali Loss: 1.6498
EarlyStopping counter: 1 out of 3

Training completed at 2024-09-06 01:52:56.
Model parameters: 180070448
Total memory: 7967.4 MB
Allocated memory: 955.1 MB
Max allocated memory: 1643.8 MB
Time per epoch: 8.4 sec.
Memory usage: Available 7967.4 MB, Allocated 955.1 MB, Max allocated 1643.8 MB

Loading model from results/Gold/CALF_sl_96_pl_48_id_ori/3/llm.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:5.0424, mae:1.5559
Upscaling data and removing negatives...
test -- mse:1.1574e+09, mae:12504, rmsle: 0.17897 smape 9.3668

Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='Gold.csv', features='M', n_features=5, target='OT', freq='d', no_scale=False, seq_len=96, label_len=48, pred_len=48, top_k=5, num_kernels=6, d_model=768, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', dry_run=False, percent=100, model_id='ori', model='OFA', gpt_layers=6, is_gpt=1, patch_size=16, kernel_size=25, pretrain=1, freeze=1, stride=8, max_len=-1, hid_dim=16, tmax=20, n_scale=-1, use_gpu=True, enc_in=5, dec_in=5, c_out=5, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Gold/OFA_sl_96_pl_48_id_ori/1

Experiment begins at 2024-09-06 01:53:05

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Epoch: 1 | Time: 5.44 s | Train Loss: 1.2935 Vali Loss: 0.9482
Validation loss decreased (inf --> 0.948199).  Saving model ...
Epoch: 2 | Time: 5.22 s | Train Loss: 1.1772 Vali Loss: 0.93375
Validation loss decreased (0.948199 --> 0.933753).  Saving model ...
Epoch: 3 | Time: 5.2 s | Train Loss: 1.1562 Vali Loss: 0.97478
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 5.18 s | Train Loss: 1.1308 Vali Loss: 0.9587
EarlyStopping counter: 2 out of 3
Epoch: 5 | Time: 5.21 s | Train Loss: 1.1047 Vali Loss: 0.91498
Validation loss decreased (0.933753 --> 0.914977).  Saving model ...
Epoch: 6 | Time: 5.24 s | Train Loss: 1.0584 Vali Loss: 0.99943
EarlyStopping counter: 1 out of 3
Epoch: 7 | Time: 5.21 s | Train Loss: 1.0278 Vali Loss: 0.96015
EarlyStopping counter: 2 out of 3
Epoch: 8 | Time: 5.2 s | Train Loss: 0.96995 Vali Loss: 0.99578
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:54:00.
Model parameters: 82368048
Total memory: 7967.4 MB
Allocated memory: 353.4 MB
Max allocated memory: 1243.0 MB
Time per epoch: 6.9 sec.
Memory usage: Available 7967.4 MB, Allocated 353.4 MB, Max allocated 1243.0 MB

Loading model from results/Gold/OFA_sl_96_pl_48_id_ori/1/llm.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:4.5687, mae:1.4604
Upscaling data and removing negatives...
test -- mse:1.001e+09, mae:11155, rmsle: 0.16688 smape 8.6513


>>>> itr_no: 2, seed: 506 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Gold/OFA_sl_96_pl_48_id_ori/2

Experiment begins at 2024-09-06 01:54:02

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Epoch: 1 | Time: 5.22 s | Train Loss: 1.2583 Vali Loss: 1.0402
Validation loss decreased (inf --> 1.040248).  Saving model ...
Epoch: 2 | Time: 5.27 s | Train Loss: 1.1682 Vali Loss: 0.96666
Validation loss decreased (1.040248 --> 0.966662).  Saving model ...
Epoch: 3 | Time: 5.27 s | Train Loss: 1.1469 Vali Loss: 0.94789
Validation loss decreased (0.966662 --> 0.947889).  Saving model ...
Epoch: 4 | Time: 5.28 s | Train Loss: 1.1178 Vali Loss: 0.99102
EarlyStopping counter: 1 out of 3
Epoch: 5 | Time: 5.23 s | Train Loss: 1.0973 Vali Loss: 0.93977
Validation loss decreased (0.947889 --> 0.939771).  Saving model ...
Epoch: 6 | Time: 5.24 s | Train Loss: 1.045 Vali Loss: 1.0679
EarlyStopping counter: 1 out of 3
Epoch: 7 | Time: 5.21 s | Train Loss: 1.0168 Vali Loss: 1.1217
EarlyStopping counter: 2 out of 3
Epoch: 8 | Time: 5.22 s | Train Loss: 0.97308 Vali Loss: 1.0083
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:54:59.
Model parameters: 82368048
Total memory: 7967.4 MB
Allocated memory: 354.2 MB
Max allocated memory: 1245.3 MB
Time per epoch: 7.2 sec.
Memory usage: Available 7967.4 MB, Allocated 354.2 MB, Max allocated 1245.3 MB

Loading model from results/Gold/OFA_sl_96_pl_48_id_ori/2/llm.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:4.7533, mae:1.5002
Upscaling data and removing negatives...
test -- mse:1.0866e+09, mae:11510, rmsle: 0.17766 smape 8.9502


>>>> itr_no: 3, seed: 608 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Gold/OFA_sl_96_pl_48_id_ori/3

Experiment begins at 2024-09-06 01:55:01

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Epoch: 1 | Time: 5.23 s | Train Loss: 1.2634 Vali Loss: 0.99565
Validation loss decreased (inf --> 0.995648).  Saving model ...
Epoch: 2 | Time: 5.28 s | Train Loss: 1.1791 Vali Loss: 0.99571
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 5.24 s | Train Loss: 1.1588 Vali Loss: 0.95269
Validation loss decreased (0.995648 --> 0.952687).  Saving model ...
Epoch: 4 | Time: 5.26 s | Train Loss: 1.1263 Vali Loss: 0.99351
EarlyStopping counter: 1 out of 3
Epoch: 5 | Time: 5.23 s | Train Loss: 1.1074 Vali Loss: 1.0323
EarlyStopping counter: 2 out of 3
Epoch: 6 | Time: 5.26 s | Train Loss: 1.0661 Vali Loss: 1.0194
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 01:55:40.
Model parameters: 82368048
Total memory: 7967.4 MB
Allocated memory: 354.3 MB
Max allocated memory: 1245.3 MB
Time per epoch: 6.6 sec.
Memory usage: Available 7967.4 MB, Allocated 354.3 MB, Max allocated 1245.3 MB

Loading model from results/Gold/OFA_sl_96_pl_48_id_ori/3/llm.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:4.5208, mae:1.4361
Upscaling data and removing negatives...
test -- mse:1.0492e+09, mae:11424, rmsle: 0.16589 smape 8.5231

Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='Gold.csv', features='M', n_features=5, target='OT', freq='d', no_scale=False, seq_len=96, label_len=48, pred_len=48, top_k=5, num_kernels=6, d_model=16, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=16, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', dry_run=False, percent=100, model_id='ori', model='TimeLLM', patch_len=16, stride=8, prompt_domain=1, llm_model='GPT2', llm_dim=768, llm_layers=6, use_gpu=True, enc_in=5, dec_in=5, c_out=5, task_name='long_term_forecast', content='Gold historical price per day in dollars')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
description: Gold historical price per day in dollars
Experiments will be saved in results/Gold/TimeLLM_sl_96_pl_48_id_ori/1

Experiment begins at 2024-09-06 01:55:49

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Epoch: 1 | Time: 63.9 s | Train Loss: 3.6696 Vali Loss: 1.8136
Validation loss decreased (inf --> 1.813592).  Saving model ...
Epoch: 2 | Time: 61.6 s | Train Loss: 3.395 Vali Loss: 1.7379
Validation loss decreased (1.813592 --> 1.737883).  Saving model ...
Epoch: 3 | Time: 61.7 s | Train Loss: 3.2992 Vali Loss: 1.6766
Validation loss decreased (1.737883 --> 1.676591).  Saving model ...
Epoch: 4 | Time: 61.7 s | Train Loss: 3.2471 Vali Loss: 1.8353
EarlyStopping counter: 1 out of 3
Epoch: 5 | Time: 61.9 s | Train Loss: 3.3987 Vali Loss: 2.1127
EarlyStopping counter: 2 out of 3
Epoch: 6 | Time: 62 s | Train Loss: 3.3288 Vali Loss: 1.5689
Validation loss decreased (1.676591 --> 1.568899).  Saving model ...
Epoch: 7 | Time: 61.5 s | Train Loss: 3.2656 Vali Loss: 1.5774
EarlyStopping counter: 1 out of 3
Epoch: 8 | Time: 61.6 s | Train Loss: 3.2499 Vali Loss: 1.5648
Validation loss decreased (1.568899 --> 1.564805).  Saving model ...
Epoch: 9 | Time: 61.3 s | Train Loss: 3.2465 Vali Loss: 1.5978
EarlyStopping counter: 1 out of 3
Epoch: 10 | Time: 61.4 s | Train Loss: 3.2029 Vali Loss: 1.5995
EarlyStopping counter: 2 out of 3

Training completed at 2024-09-06 02:06:39.
Model parameters: 133434752
Total memory: 7967.4 MB
Allocated memory: 1126.2 MB
Max allocated memory: 6383.1 MB
Time per epoch: 65.1 sec.
Memory usage: Available 7967.4 MB, Allocated 1126.2 MB, Max allocated 6383.1 MB

Loading model from results/Gold/TimeLLM_sl_96_pl_48_id_ori/1/llm.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:4.5452, mae:1.4342
Upscaling data and removing negatives...
test -- mse:1.1313e+09, mae:12053, rmsle: 0.17139 smape 8.6394


>>>> itr_no: 2, seed: 506 <<<<<<
Use GPU: cuda:0
description: Gold historical price per day in dollars
Experiments will be saved in results/Gold/TimeLLM_sl_96_pl_48_id_ori/2

Experiment begins at 2024-09-06 02:06:45

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Epoch: 1 | Time: 63.5 s | Train Loss: 3.799 Vali Loss: 1.6876
Validation loss decreased (inf --> 1.687608).  Saving model ...
Epoch: 2 | Time: 61.2 s | Train Loss: 3.3759 Vali Loss: 1.9202
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 61.4 s | Train Loss: 3.3714 Vali Loss: 1.9635
EarlyStopping counter: 2 out of 3
Epoch: 4 | Time: 61.4 s | Train Loss: 3.3168 Vali Loss: 1.6385
Validation loss decreased (1.687608 --> 1.638480).  Saving model ...
Epoch: 5 | Time: 61.3 s | Train Loss: 3.3014 Vali Loss: 1.64
EarlyStopping counter: 1 out of 3
Epoch: 6 | Time: 61.5 s | Train Loss: 3.2969 Vali Loss: 1.6462
EarlyStopping counter: 2 out of 3
Epoch: 7 | Time: 61.6 s | Train Loss: 3.2655 Vali Loss: 1.6549
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 02:14:10.
Model parameters: 133434752
Total memory: 7967.4 MB
Allocated memory: 1127.8 MB
Max allocated memory: 6383.1 MB
Time per epoch: 63.6 sec.
Memory usage: Available 7967.4 MB, Allocated 1127.8 MB, Max allocated 6383.1 MB

Loading model from results/Gold/TimeLLM_sl_96_pl_48_id_ori/2/llm.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:4.3007, mae:1.4165
Upscaling data and removing negatives...
test -- mse:1.2472e+09, mae:12774, rmsle: 0.19367 smape 9.2215


>>>> itr_no: 3, seed: 608 <<<<<<
Use GPU: cuda:0
description: Gold historical price per day in dollars
Experiments will be saved in results/Gold/TimeLLM_sl_96_pl_48_id_ori/3

Experiment begins at 2024-09-06 02:14:21

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Epoch: 1 | Time: 63.6 s | Train Loss: 3.6911 Vali Loss: 1.8423
Validation loss decreased (inf --> 1.842284).  Saving model ...
Epoch: 2 | Time: 61.5 s | Train Loss: 3.4869 Vali Loss: 1.9515
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 61.8 s | Train Loss: 3.4914 Vali Loss: 1.9923
EarlyStopping counter: 2 out of 3
Epoch: 4 | Time: 61.9 s | Train Loss: 3.6136 Vali Loss: 1.886
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 02:18:37.
Model parameters: 133434752
Total memory: 7967.4 MB
Allocated memory: 1128.6 MB
Max allocated memory: 6384.9 MB
Time per epoch: 63.8 sec.
Memory usage: Available 7967.4 MB, Allocated 1128.6 MB, Max allocated 6384.9 MB

Loading model from results/Gold/TimeLLM_sl_96_pl_48_id_ori/3/llm.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:4.0819, mae:1.4228
Upscaling data and removing negatives...
test -- mse:1.0184e+09, mae:11347, rmsle: 0.1604 smape 8.4401

Running for model:DLinear
Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='MSFT.csv', features='M', n_features=5, target='OT', freq='d', no_scale=False, seq_len=96, label_len=48, pred_len=48, top_k=5, num_kernels=6, d_model=64, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, channel_independence=1, decomp_method='moving_avg', use_norm=1, down_sampling_layers=0, down_sampling_window=1, down_sampling_method=None, seg_len=48, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, dry_run=False, percent=100, model='DLinear', use_gpu=True, enc_in=5, dec_in=5, c_out=5, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/MSFT/DLinear_sl_96_pl_48/1

Experiment begins at 2024-09-06 02:18:47

>>>>>>> start training :>>>>>>>>>>
train 1869
val 206
Epoch: 1 | Time: 2.27 s | Train Loss: 3.4333 Vali Loss: 2.8389
Validation loss decreased (inf --> 2.838937).  Saving model ...
Epoch: 2 | Time: 2.18 s | Train Loss: 2.7308 Vali Loss: 2.5699
Validation loss decreased (2.838937 --> 2.569944).  Saving model ...
Epoch: 3 | Time: 2.16 s | Train Loss: 2.5568 Vali Loss: 2.4337
Validation loss decreased (2.569944 --> 2.433681).  Saving model ...
Epoch: 4 | Time: 2.17 s | Train Loss: 2.458 Vali Loss: 2.3425
Validation loss decreased (2.433681 --> 2.342481).  Saving model ...
Epoch: 5 | Time: 2.17 s | Train Loss: 2.3936 Vali Loss: 2.2657
Validation loss decreased (2.342481 --> 2.265747).  Saving model ...
Epoch: 6 | Time: 2.16 s | Train Loss: 2.3366 Vali Loss: 2.2203
Validation loss decreased (2.265747 --> 2.220299).  Saving model ...
Epoch: 7 | Time: 2.16 s | Train Loss: 2.3138 Vali Loss: 2.1265
Validation loss decreased (2.220299 --> 2.126465).  Saving model ...
Epoch: 8 | Time: 2.15 s | Train Loss: 2.2951 Vali Loss: 2.096
Validation loss decreased (2.126465 --> 2.096045).  Saving model ...
Epoch: 9 | Time: 2.2 s | Train Loss: 2.2773 Vali Loss: 2.0973
EarlyStopping counter: 1 out of 3
Epoch: 10 | Time: 2.2 s | Train Loss: 2.25 Vali Loss: 2.0716
Validation loss decreased (2.096045 --> 2.071611).  Saving model ...

Training completed at 2024-09-06 02:19:11.
Model parameters: 9312
Total memory: 7967.4 MB
Allocated memory: 16.5 MB
Max allocated memory: 17.0 MB
Time per epoch: 2.4 sec.
Memory usage: Available 7967.4 MB, Allocated 16.5 MB, Max allocated 17.0 MB

Loading model from results/MSFT/DLinear_sl_96_pl_48/1/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 204
Preds and Trues shape: (204, 48, 5) (204, 48, 5)
test scaled -- mse:2.5764, mae:1.1486
Upscaling data and removing negatives...
test -- mse:2.0912e+13, mae:1.584e+06, rmsle: 0.18542 smape 9.8175


>>>> itr_no: 2, seed: 506 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/MSFT/DLinear_sl_96_pl_48/2

Experiment begins at 2024-09-06 02:19:11

>>>>>>> start training :>>>>>>>>>>
train 1869
val 206
Epoch: 1 | Time: 2.18 s | Train Loss: 3.4773 Vali Loss: 2.8879
Validation loss decreased (inf --> 2.887852).  Saving model ...
Epoch: 2 | Time: 2.22 s | Train Loss: 2.7717 Vali Loss: 2.6122
Validation loss decreased (2.887852 --> 2.612246).  Saving model ...
Epoch: 3 | Time: 2.17 s | Train Loss: 2.5804 Vali Loss: 2.473
Validation loss decreased (2.612246 --> 2.472975).  Saving model ...
Epoch: 4 | Time: 2.26 s | Train Loss: 2.4684 Vali Loss: 2.3284
Validation loss decreased (2.472975 --> 2.328412).  Saving model ...
Epoch: 5 | Time: 2.16 s | Train Loss: 2.4145 Vali Loss: 2.2454
Validation loss decreased (2.328412 --> 2.245352).  Saving model ...
Epoch: 6 | Time: 2.15 s | Train Loss: 2.3515 Vali Loss: 2.1863
Validation loss decreased (2.245352 --> 2.186309).  Saving model ...
Epoch: 7 | Time: 2.15 s | Train Loss: 2.3168 Vali Loss: 2.1693
Validation loss decreased (2.186309 --> 2.169287).  Saving model ...
Epoch: 8 | Time: 2.15 s | Train Loss: 2.2894 Vali Loss: 2.1114
Validation loss decreased (2.169287 --> 2.111391).  Saving model ...
Epoch: 9 | Time: 2.16 s | Train Loss: 2.2733 Vali Loss: 2.0878
Validation loss decreased (2.111391 --> 2.087821).  Saving model ...
Epoch: 10 | Time: 2.16 s | Train Loss: 2.2577 Vali Loss: 2.0837
Validation loss decreased (2.087821 --> 2.083667).  Saving model ...

Training completed at 2024-09-06 02:19:35.
Model parameters: 9312
Total memory: 7967.4 MB
Allocated memory: 16.5 MB
Max allocated memory: 17.0 MB
Time per epoch: 2.3 sec.
Memory usage: Available 7967.4 MB, Allocated 16.5 MB, Max allocated 17.0 MB

Loading model from results/MSFT/DLinear_sl_96_pl_48/2/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 204
Preds and Trues shape: (204, 48, 5) (204, 48, 5)
test scaled -- mse:2.5895, mae:1.1489
Upscaling data and removing negatives...
test -- mse:2.0742e+13, mae:1.5691e+06, rmsle: 0.18458 smape 9.768


>>>> itr_no: 3, seed: 608 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/MSFT/DLinear_sl_96_pl_48/3

Experiment begins at 2024-09-06 02:19:35

>>>>>>> start training :>>>>>>>>>>
train 1869
val 206
Epoch: 1 | Time: 2.17 s | Train Loss: 3.4307 Vali Loss: 2.8359
Validation loss decreased (inf --> 2.835941).  Saving model ...
Epoch: 2 | Time: 2.21 s | Train Loss: 2.7332 Vali Loss: 2.5736
Validation loss decreased (2.835941 --> 2.573572).  Saving model ...
Epoch: 3 | Time: 2.22 s | Train Loss: 2.546 Vali Loss: 2.4053
Validation loss decreased (2.573572 --> 2.405300).  Saving model ...
Epoch: 4 | Time: 2.23 s | Train Loss: 2.4518 Vali Loss: 2.2943
Validation loss decreased (2.405300 --> 2.294328).  Saving model ...
Epoch: 5 | Time: 2.23 s | Train Loss: 2.4088 Vali Loss: 2.2569
Validation loss decreased (2.294328 --> 2.256861).  Saving model ...
Epoch: 6 | Time: 2.24 s | Train Loss: 2.3608 Vali Loss: 2.2156
Validation loss decreased (2.256861 --> 2.215590).  Saving model ...
Epoch: 7 | Time: 2.2 s | Train Loss: 2.3184 Vali Loss: 2.1549
Validation loss decreased (2.215590 --> 2.154946).  Saving model ...
Epoch: 8 | Time: 2.21 s | Train Loss: 2.2976 Vali Loss: 2.1003
Validation loss decreased (2.154946 --> 2.100334).  Saving model ...
Epoch: 9 | Time: 2.22 s | Train Loss: 2.2703 Vali Loss: 2.0997
Validation loss decreased (2.100334 --> 2.099657).  Saving model ...
Epoch: 10 | Time: 2.21 s | Train Loss: 2.246 Vali Loss: 2.0682
Validation loss decreased (2.099657 --> 2.068231).  Saving model ...

Training completed at 2024-09-06 02:19:59.
Model parameters: 9312
Total memory: 7967.4 MB
Allocated memory: 16.5 MB
Max allocated memory: 17.0 MB
Time per epoch: 2.4 sec.
Memory usage: Available 7967.4 MB, Allocated 16.5 MB, Max allocated 17.0 MB

Loading model from results/MSFT/DLinear_sl_96_pl_48/3/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 204
Preds and Trues shape: (204, 48, 5) (204, 48, 5)
test scaled -- mse:2.5977, mae:1.1505
Upscaling data and removing negatives...
test -- mse:2.0914e+13, mae:1.5802e+06, rmsle: 0.18519 smape 9.7965

Running for model:PatchTST
Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='MSFT.csv', features='M', n_features=5, target='OT', freq='d', no_scale=False, seq_len=96, label_len=48, pred_len=48, top_k=5, num_kernels=6, d_model=64, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, channel_independence=1, decomp_method='moving_avg', use_norm=1, down_sampling_layers=0, down_sampling_window=1, down_sampling_method=None, seg_len=48, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, dry_run=False, percent=100, model='PatchTST', use_gpu=True, enc_in=5, dec_in=5, c_out=5, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/MSFT/PatchTST_sl_96_pl_48/1

Experiment begins at 2024-09-06 02:20:21

>>>>>>> start training :>>>>>>>>>>
train 1869
val 206
Epoch: 1 | Time: 2.93 s | Train Loss: 2.8037 Vali Loss: 2.0173
Validation loss decreased (inf --> 2.017317).  Saving model ...
Epoch: 2 | Time: 2.65 s | Train Loss: 2.4185 Vali Loss: 2.0673
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 2.69 s | Train Loss: 2.253 Vali Loss: 1.8365
Validation loss decreased (2.017317 --> 1.836497).  Saving model ...
Epoch: 4 | Time: 2.61 s | Train Loss: 2.0455 Vali Loss: 1.9188
EarlyStopping counter: 1 out of 3
Epoch: 5 | Time: 2.68 s | Train Loss: 1.8882 Vali Loss: 2.1264
EarlyStopping counter: 2 out of 3
Epoch: 6 | Time: 2.62 s | Train Loss: 1.7546 Vali Loss: 2.1418
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 02:20:38.
Model parameters: 105008
Total memory: 7967.4 MB
Allocated memory: 19.2 MB
Max allocated memory: 169.0 MB
Time per epoch: 2.9 sec.
Memory usage: Available 7967.4 MB, Allocated 19.2 MB, Max allocated 169.0 MB

Loading model from results/MSFT/PatchTST_sl_96_pl_48/1/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 204
Preds and Trues shape: (204, 48, 5) (204, 48, 5)
test scaled -- mse:2.3875, mae:1.1236
Upscaling data and removing negatives...
test -- mse:1.8326e+13, mae:1.3901e+06, rmsle: 0.17311 smape 9.268


>>>> itr_no: 2, seed: 506 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/MSFT/PatchTST_sl_96_pl_48/2

Experiment begins at 2024-09-06 02:20:39

>>>>>>> start training :>>>>>>>>>>
train 1869
val 206
Epoch: 1 | Time: 2.58 s | Train Loss: 2.809 Vali Loss: 2.0395
Validation loss decreased (inf --> 2.039487).  Saving model ...
Epoch: 2 | Time: 2.6 s | Train Loss: 2.4254 Vali Loss: 2.0809
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 2.68 s | Train Loss: 2.2747 Vali Loss: 1.781
Validation loss decreased (2.039487 --> 1.780963).  Saving model ...
Epoch: 4 | Time: 2.68 s | Train Loss: 2.0797 Vali Loss: 1.9986
EarlyStopping counter: 1 out of 3
Epoch: 5 | Time: 2.68 s | Train Loss: 1.9204 Vali Loss: 2.2541
EarlyStopping counter: 2 out of 3
Epoch: 6 | Time: 2.67 s | Train Loss: 1.7933 Vali Loss: 1.9034
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 02:20:56.
Model parameters: 105008
Total memory: 7967.4 MB
Allocated memory: 19.2 MB
Max allocated memory: 169.0 MB
Time per epoch: 2.8 sec.
Memory usage: Available 7967.4 MB, Allocated 19.2 MB, Max allocated 169.0 MB

Loading model from results/MSFT/PatchTST_sl_96_pl_48/2/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 204
Preds and Trues shape: (204, 48, 5) (204, 48, 5)
test scaled -- mse:2.2773, mae:1.0956
Upscaling data and removing negatives...
test -- mse:2.3227e+13, mae:1.6925e+06, rmsle: 0.19507 smape 10.036


>>>> itr_no: 3, seed: 608 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/MSFT/PatchTST_sl_96_pl_48/3

Experiment begins at 2024-09-06 02:20:56

>>>>>>> start training :>>>>>>>>>>
train 1869
val 206
Epoch: 1 | Time: 2.69 s | Train Loss: 2.8473 Vali Loss: 1.9497
Validation loss decreased (inf --> 1.949711).  Saving model ...
Epoch: 2 | Time: 2.67 s | Train Loss: 2.4748 Vali Loss: 2.0007
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 2.7 s | Train Loss: 2.289 Vali Loss: 2.0062
EarlyStopping counter: 2 out of 3
Epoch: 4 | Time: 2.67 s | Train Loss: 2.1125 Vali Loss: 2.0167
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 02:21:07.
Model parameters: 105008
Total memory: 7967.4 MB
Allocated memory: 19.2 MB
Max allocated memory: 169.0 MB
Time per epoch: 2.8 sec.
Memory usage: Available 7967.4 MB, Allocated 19.2 MB, Max allocated 169.0 MB

Loading model from results/MSFT/PatchTST_sl_96_pl_48/3/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 204
Preds and Trues shape: (204, 48, 5) (204, 48, 5)
test scaled -- mse:2.986, mae:1.2093
Upscaling data and removing negatives...
test -- mse:2.3933e+13, mae:1.577e+06, rmsle: 0.1916 smape 9.9438

Running for model:TimesNet
Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='MSFT.csv', features='M', n_features=5, target='OT', freq='d', no_scale=False, seq_len=96, label_len=48, pred_len=48, top_k=5, num_kernels=6, d_model=64, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, channel_independence=1, decomp_method='moving_avg', use_norm=1, down_sampling_layers=0, down_sampling_window=1, down_sampling_method=None, seg_len=48, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, dry_run=False, percent=100, model='TimesNet', use_gpu=True, enc_in=5, dec_in=5, c_out=5, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/MSFT/TimesNet_sl_96_pl_48/1

Experiment begins at 2024-09-06 02:21:14

>>>>>>> start training :>>>>>>>>>>
train 1869
val 206
Epoch: 1 | Time: 24.1 s | Train Loss: 2.903 Vali Loss: 3.154
Validation loss decreased (inf --> 3.153987).  Saving model ...
Epoch: 2 | Time: 22.8 s | Train Loss: 2.3732 Vali Loss: 2.1661
Validation loss decreased (3.153987 --> 2.166142).  Saving model ...
Epoch: 3 | Time: 22.4 s | Train Loss: 2.1841 Vali Loss: 2.377
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 23.1 s | Train Loss: 1.9914 Vali Loss: 2.5734
EarlyStopping counter: 2 out of 3
Epoch: 5 | Time: 25 s | Train Loss: 1.731 Vali Loss: 2.4933
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 02:23:13.
Model parameters: 9389525
Total memory: 7967.4 MB
Allocated memory: 167.2 MB
Max allocated memory: 1768.3 MB
Time per epoch: 23.9 sec.
Memory usage: Available 7967.4 MB, Allocated 167.2 MB, Max allocated 1768.3 MB

Loading model from results/MSFT/TimesNet_sl_96_pl_48/1/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 204
Preds and Trues shape: (204, 48, 5) (204, 48, 5)
test scaled -- mse:2.5791, mae:1.1447
Upscaling data and removing negatives...
test -- mse:1.4718e+13, mae:1.2244e+06, rmsle: 0.15662 smape 8.819


>>>> itr_no: 2, seed: 506 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/MSFT/TimesNet_sl_96_pl_48/2

Experiment begins at 2024-09-06 02:23:15

>>>>>>> start training :>>>>>>>>>>
train 1869
val 206
Epoch: 1 | Time: 30.2 s | Train Loss: 2.9564 Vali Loss: 2.2858
Validation loss decreased (inf --> 2.285775).  Saving model ...
Epoch: 2 | Time: 35.4 s | Train Loss: 2.3013 Vali Loss: 1.9868
Validation loss decreased (2.285775 --> 1.986764).  Saving model ...
Epoch: 3 | Time: 32.1 s | Train Loss: 2.0124 Vali Loss: 1.8879
Validation loss decreased (1.986764 --> 1.887931).  Saving model ...
Epoch: 4 | Time: 30 s | Train Loss: 1.8068 Vali Loss: 1.5008
Validation loss decreased (1.887931 --> 1.500762).  Saving model ...
Epoch: 5 | Time: 31.8 s | Train Loss: 1.549 Vali Loss: 1.6209
EarlyStopping counter: 1 out of 3
Epoch: 6 | Time: 30.1 s | Train Loss: 1.3712 Vali Loss: 1.9417
EarlyStopping counter: 2 out of 3
Epoch: 7 | Time: 29.4 s | Train Loss: 1.1751 Vali Loss: 2.0893
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 02:26:57.
Model parameters: 9389525
Total memory: 7967.4 MB
Allocated memory: 170.2 MB
Max allocated memory: 1782.9 MB
Time per epoch: 31.7 sec.
Memory usage: Available 7967.4 MB, Allocated 170.2 MB, Max allocated 1782.9 MB

Loading model from results/MSFT/TimesNet_sl_96_pl_48/2/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 204
Preds and Trues shape: (204, 48, 5) (204, 48, 5)
test scaled -- mse:2.9017, mae:1.2318
Upscaling data and removing negatives...
test -- mse:1.5379e+13, mae:1.3303e+06, rmsle: 0.1662 smape 9.5561


>>>> itr_no: 3, seed: 608 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/MSFT/TimesNet_sl_96_pl_48/3

Experiment begins at 2024-09-06 02:26:59

>>>>>>> start training :>>>>>>>>>>
train 1869
val 206
Epoch: 1 | Time: 22 s | Train Loss: 2.6783 Vali Loss: 2.5481
Validation loss decreased (inf --> 2.548076).  Saving model ...
Epoch: 2 | Time: 20.9 s | Train Loss: 2.1617 Vali Loss: 2.5502
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 20.8 s | Train Loss: 1.9946 Vali Loss: 2.2946
Validation loss decreased (2.548076 --> 2.294603).  Saving model ...
Epoch: 4 | Time: 20.6 s | Train Loss: 1.7719 Vali Loss: 2.2686
Validation loss decreased (2.294603 --> 2.268580).  Saving model ...
Epoch: 5 | Time: 20.6 s | Train Loss: 1.5088 Vali Loss: 1.9996
Validation loss decreased (2.268580 --> 1.999602).  Saving model ...
Epoch: 6 | Time: 20.5 s | Train Loss: 1.3811 Vali Loss: 2.2774
EarlyStopping counter: 1 out of 3
Epoch: 7 | Time: 20.6 s | Train Loss: 1.23 Vali Loss: 2.1417
EarlyStopping counter: 2 out of 3
Epoch: 8 | Time: 20.8 s | Train Loss: 1.0649 Vali Loss: 2.0533
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 02:29:49.
Model parameters: 9389525
Total memory: 7967.4 MB
Allocated memory: 176.4 MB
Max allocated memory: 1782.9 MB
Time per epoch: 21.2 sec.
Memory usage: Available 7967.4 MB, Allocated 176.4 MB, Max allocated 1782.9 MB

Loading model from results/MSFT/TimesNet_sl_96_pl_48/3/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 204
Preds and Trues shape: (204, 48, 5) (204, 48, 5)
test scaled -- mse:2.9209, mae:1.3323
Upscaling data and removing negatives...
test -- mse:2.7703e+13, mae:1.7791e+06, rmsle: 0.20449 smape 11.223

Running for model:iTransformer
Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='MSFT.csv', features='M', n_features=5, target='OT', freq='d', no_scale=False, seq_len=96, label_len=48, pred_len=48, top_k=5, num_kernels=6, d_model=64, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, channel_independence=1, decomp_method='moving_avg', use_norm=1, down_sampling_layers=0, down_sampling_window=1, down_sampling_method=None, seg_len=48, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, dry_run=False, percent=100, model='iTransformer', use_gpu=True, enc_in=5, dec_in=5, c_out=5, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/MSFT/iTransformer_sl_96_pl_48/1

Experiment begins at 2024-09-06 02:29:56

>>>>>>> start training :>>>>>>>>>>
train 1869
val 206
Epoch: 1 | Time: 2.83 s | Train Loss: 2.9824 Vali Loss: 2.2458
Validation loss decreased (inf --> 2.245764).  Saving model ...
Epoch: 2 | Time: 2.55 s | Train Loss: 2.2247 Vali Loss: 1.9378
Validation loss decreased (2.245764 --> 1.937826).  Saving model ...
Epoch: 3 | Time: 2.59 s | Train Loss: 1.9474 Vali Loss: 1.9929
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 2.64 s | Train Loss: 1.6214 Vali Loss: 2.0513
EarlyStopping counter: 2 out of 3
Epoch: 5 | Time: 2.55 s | Train Loss: 1.432 Vali Loss: 2.0738
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 02:30:11.
Model parameters: 76400
Total memory: 7967.4 MB
Allocated memory: 17.6 MB
Max allocated memory: 147.6 MB
Time per epoch: 2.9 sec.
Memory usage: Available 7967.4 MB, Allocated 17.6 MB, Max allocated 147.6 MB

Loading model from results/MSFT/iTransformer_sl_96_pl_48/1/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 204
Preds and Trues shape: (204, 48, 5) (204, 48, 5)
test scaled -- mse:3.2504, mae:1.3351
Upscaling data and removing negatives...
test -- mse:1.9934e+13, mae:1.4315e+06, rmsle: 0.18382 smape 10.309


>>>> itr_no: 2, seed: 506 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/MSFT/iTransformer_sl_96_pl_48/2

Experiment begins at 2024-09-06 02:30:11

>>>>>>> start training :>>>>>>>>>>
train 1869
val 206
Epoch: 1 | Time: 2.56 s | Train Loss: 3.0165 Vali Loss: 2.234
Validation loss decreased (inf --> 2.234008).  Saving model ...
Epoch: 2 | Time: 2.54 s | Train Loss: 2.1847 Vali Loss: 2.2042
Validation loss decreased (2.234008 --> 2.204238).  Saving model ...
Epoch: 3 | Time: 2.57 s | Train Loss: 1.8503 Vali Loss: 2.2812
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 2.57 s | Train Loss: 1.5896 Vali Loss: 2.4459
EarlyStopping counter: 2 out of 3
Epoch: 5 | Time: 2.47 s | Train Loss: 1.3985 Vali Loss: 2.3284
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 02:30:25.
Model parameters: 76400
Total memory: 7967.4 MB
Allocated memory: 17.6 MB
Max allocated memory: 147.6 MB
Time per epoch: 2.7 sec.
Memory usage: Available 7967.4 MB, Allocated 17.6 MB, Max allocated 147.6 MB

Loading model from results/MSFT/iTransformer_sl_96_pl_48/2/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 204
Preds and Trues shape: (204, 48, 5) (204, 48, 5)
test scaled -- mse:2.7259, mae:1.2148
Upscaling data and removing negatives...
test -- mse:3.0241e+13, mae:1.9302e+06, rmsle: 0.21797 smape 11.163


>>>> itr_no: 3, seed: 608 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/MSFT/iTransformer_sl_96_pl_48/3

Experiment begins at 2024-09-06 02:30:25

>>>>>>> start training :>>>>>>>>>>
train 1869
val 206
Epoch: 1 | Time: 2.46 s | Train Loss: 3.0267 Vali Loss: 2.2408
Validation loss decreased (inf --> 2.240805).  Saving model ...
Epoch: 2 | Time: 2.47 s | Train Loss: 2.217 Vali Loss: 1.9081
Validation loss decreased (2.240805 --> 1.908144).  Saving model ...
Epoch: 3 | Time: 2.46 s | Train Loss: 1.9114 Vali Loss: 2.0861
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 2.47 s | Train Loss: 1.6165 Vali Loss: 2.2017
EarlyStopping counter: 2 out of 3
Epoch: 5 | Time: 2.47 s | Train Loss: 1.3911 Vali Loss: 2.2161
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 02:30:38.
Model parameters: 76400
Total memory: 7967.4 MB
Allocated memory: 17.6 MB
Max allocated memory: 147.6 MB
Time per epoch: 2.6 sec.
Memory usage: Available 7967.4 MB, Allocated 17.6 MB, Max allocated 147.6 MB

Loading model from results/MSFT/iTransformer_sl_96_pl_48/3/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 204
Preds and Trues shape: (204, 48, 5) (204, 48, 5)
test scaled -- mse:3.1912, mae:1.2805
Upscaling data and removing negatives...
test -- mse:2.3064e+13, mae:1.5688e+06, rmsle: 0.19769 smape 10.479

Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='MSFT.csv', features='M', n_features=5, target='OT', freq='d', no_scale=False, seq_len=96, label_len=96, pred_len=48, top_k=5, num_kernels=6, d_model=64, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, channel_independence=1, decomp_method='moving_avg', use_norm=1, down_sampling_layers=0, down_sampling_window=1, down_sampling_method=None, seg_len=48, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, dry_run=False, percent=100, model='MICN', use_gpu=True, enc_in=5, dec_in=5, c_out=5, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/MSFT/MICN_sl_96_pl_48/1

Experiment begins at 2024-09-06 02:30:43

>>>>>>> start training :>>>>>>>>>>
train 1869
val 206
Epoch: 1 | Time: 3.01 s | Train Loss: 2.6957 Vali Loss: 2.5315
Validation loss decreased (inf --> 2.531548).  Saving model ...
Epoch: 2 | Time: 2.81 s | Train Loss: 2.2545 Vali Loss: 2.3146
Validation loss decreased (2.531548 --> 2.314568).  Saving model ...
Epoch: 3 | Time: 2.77 s | Train Loss: 2.119 Vali Loss: 2.2641
Validation loss decreased (2.314568 --> 2.264101).  Saving model ...
Epoch: 4 | Time: 2.83 s | Train Loss: 1.9785 Vali Loss: 2.1534
Validation loss decreased (2.264101 --> 2.153365).  Saving model ...
Epoch: 5 | Time: 2.73 s | Train Loss: 1.7883 Vali Loss: 2.1054
Validation loss decreased (2.153365 --> 2.105356).  Saving model ...
Epoch: 6 | Time: 2.8 s | Train Loss: 1.5936 Vali Loss: 2.1739
EarlyStopping counter: 1 out of 3
Epoch: 7 | Time: 2.78 s | Train Loss: 1.3116 Vali Loss: 2.4413
EarlyStopping counter: 2 out of 3
Epoch: 8 | Time: 2.81 s | Train Loss: 1.0747 Vali Loss: 2.2484
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 02:31:08.
Model parameters: 371829
Total memory: 7967.4 MB
Allocated memory: 23.3 MB
Max allocated memory: 179.9 MB
Time per epoch: 3.0 sec.
Memory usage: Available 7967.4 MB, Allocated 23.3 MB, Max allocated 179.9 MB

Loading model from results/MSFT/MICN_sl_96_pl_48/1/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 204
Preds and Trues shape: (204, 48, 5) (204, 48, 5)
test scaled -- mse:2.2965, mae:1.0994
Upscaling data and removing negatives...
test -- mse:1.4947e+13, mae:1.2606e+06, rmsle: 0.15894 smape 8.829


>>>> itr_no: 2, seed: 506 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/MSFT/MICN_sl_96_pl_48/2

Experiment begins at 2024-09-06 02:31:08

>>>>>>> start training :>>>>>>>>>>
train 1869
val 206
Epoch: 1 | Time: 2.71 s | Train Loss: 2.707 Vali Loss: 2.4948
Validation loss decreased (inf --> 2.494792).  Saving model ...
Epoch: 2 | Time: 2.7 s | Train Loss: 2.2775 Vali Loss: 2.3605
Validation loss decreased (2.494792 --> 2.360514).  Saving model ...
Epoch: 3 | Time: 2.71 s | Train Loss: 2.1708 Vali Loss: 2.1152
Validation loss decreased (2.360514 --> 2.115244).  Saving model ...
Epoch: 4 | Time: 2.7 s | Train Loss: 2.0238 Vali Loss: 1.9911
Validation loss decreased (2.115244 --> 1.991133).  Saving model ...
Epoch: 5 | Time: 2.71 s | Train Loss: 1.8557 Vali Loss: 1.9998
EarlyStopping counter: 1 out of 3
Epoch: 6 | Time: 2.7 s | Train Loss: 1.639 Vali Loss: 1.9571
Validation loss decreased (1.991133 --> 1.957122).  Saving model ...
Epoch: 7 | Time: 2.7 s | Train Loss: 1.381 Vali Loss: 2.1096
EarlyStopping counter: 1 out of 3
Epoch: 8 | Time: 2.71 s | Train Loss: 1.1501 Vali Loss: 2.0657
EarlyStopping counter: 2 out of 3
Epoch: 9 | Time: 2.69 s | Train Loss: 0.95613 Vali Loss: 2.1201
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 02:31:34.
Model parameters: 371829
Total memory: 7967.4 MB
Allocated memory: 23.3 MB
Max allocated memory: 179.9 MB
Time per epoch: 2.8 sec.
Memory usage: Available 7967.4 MB, Allocated 23.3 MB, Max allocated 179.9 MB

Loading model from results/MSFT/MICN_sl_96_pl_48/2/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 204
Preds and Trues shape: (204, 48, 5) (204, 48, 5)
test scaled -- mse:2.5423, mae:1.1349
Upscaling data and removing negatives...
test -- mse:1.4967e+13, mae:1.2568e+06, rmsle: 0.15957 smape 8.9249


>>>> itr_no: 3, seed: 608 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/MSFT/MICN_sl_96_pl_48/3

Experiment begins at 2024-09-06 02:31:34

>>>>>>> start training :>>>>>>>>>>
train 1869
val 206
Epoch: 1 | Time: 2.79 s | Train Loss: 2.7171 Vali Loss: 2.4853
Validation loss decreased (inf --> 2.485320).  Saving model ...
Epoch: 2 | Time: 2.76 s | Train Loss: 2.2351 Vali Loss: 2.1878
Validation loss decreased (2.485320 --> 2.187755).  Saving model ...
Epoch: 3 | Time: 2.82 s | Train Loss: 2.1135 Vali Loss: 2.1159
Validation loss decreased (2.187755 --> 2.115891).  Saving model ...
Epoch: 4 | Time: 2.72 s | Train Loss: 2.0173 Vali Loss: 2.0825
Validation loss decreased (2.115891 --> 2.082512).  Saving model ...
Epoch: 5 | Time: 2.75 s | Train Loss: 1.8293 Vali Loss: 2.1455
EarlyStopping counter: 1 out of 3
Epoch: 6 | Time: 2.67 s | Train Loss: 1.553 Vali Loss: 2.344
EarlyStopping counter: 2 out of 3
Epoch: 7 | Time: 2.66 s | Train Loss: 1.271 Vali Loss: 2.4135
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 02:31:55.
Model parameters: 371829
Total memory: 7967.4 MB
Allocated memory: 23.3 MB
Max allocated memory: 179.9 MB
Time per epoch: 2.9 sec.
Memory usage: Available 7967.4 MB, Allocated 23.3 MB, Max allocated 179.9 MB

Loading model from results/MSFT/MICN_sl_96_pl_48/3/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 204
Preds and Trues shape: (204, 48, 5) (204, 48, 5)
test scaled -- mse:2.1889, mae:1.0412
Upscaling data and removing negatives...
test -- mse:1.4471e+13, mae:1.2003e+06, rmsle: 0.15363 smape 8.2935

Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='MSFT.csv', features='M', n_features=5, target='OT', freq='d', no_scale=False, seq_len=96, label_len=0, pred_len=48, top_k=5, num_kernels=6, d_model=16, n_heads=4, e_layers=3, d_layers=1, d_ff=32, moving_avg=3, factor=3, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, channel_independence=1, decomp_method='moving_avg', use_norm=1, down_sampling_layers=3, down_sampling_window=2, down_sampling_method='avg', seg_len=48, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, dry_run=False, percent=100, model='TimeMixer', use_gpu=True, enc_in=5, dec_in=5, c_out=5, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/MSFT/TimeMixer_sl_96_pl_48/1

Experiment begins at 2024-09-06 02:32:03

>>>>>>> start training :>>>>>>>>>>
train 1869
val 206
Epoch: 1 | Time: 4.35 s | Train Loss: 2.9066 Vali Loss: 2.018
Validation loss decreased (inf --> 2.017965).  Saving model ...
Epoch: 2 | Time: 4.06 s | Train Loss: 2.059 Vali Loss: 1.607
Validation loss decreased (2.017965 --> 1.607004).  Saving model ...
Epoch: 3 | Time: 4.06 s | Train Loss: 1.7394 Vali Loss: 1.7935
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 4.06 s | Train Loss: 1.5193 Vali Loss: 1.9676
EarlyStopping counter: 2 out of 3
Epoch: 5 | Time: 4.07 s | Train Loss: 1.3345 Vali Loss: 2.2381
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 02:32:25.
Model parameters: 95457
Total memory: 7967.4 MB
Allocated memory: 18.2 MB
Max allocated memory: 82.9 MB
Time per epoch: 4.4 sec.
Memory usage: Available 7967.4 MB, Allocated 18.2 MB, Max allocated 82.9 MB

Loading model from results/MSFT/TimeMixer_sl_96_pl_48/1/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 204
Preds and Trues shape: (204, 48, 5) (204, 48, 5)
test scaled -- mse:2.1872, mae:1.0547
Upscaling data and removing negatives...
test -- mse:1.8953e+13, mae:1.5009e+06, rmsle: 0.17754 smape 9.2887


>>>> itr_no: 2, seed: 506 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/MSFT/TimeMixer_sl_96_pl_48/2

Experiment begins at 2024-09-06 02:32:25

>>>>>>> start training :>>>>>>>>>>
train 1869
val 206
Epoch: 1 | Time: 4.13 s | Train Loss: 3.145 Vali Loss: 2.233
Validation loss decreased (inf --> 2.232993).  Saving model ...
Epoch: 2 | Time: 4.04 s | Train Loss: 2.2228 Vali Loss: 1.69
Validation loss decreased (2.232993 --> 1.690029).  Saving model ...
Epoch: 3 | Time: 4.05 s | Train Loss: 1.8862 Vali Loss: 1.9382
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 4.05 s | Train Loss: 1.6184 Vali Loss: 2.1972
EarlyStopping counter: 2 out of 3
Epoch: 5 | Time: 4.06 s | Train Loss: 1.4149 Vali Loss: 2.2546
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 02:32:46.
Model parameters: 95457
Total memory: 7967.4 MB
Allocated memory: 18.2 MB
Max allocated memory: 82.9 MB
Time per epoch: 4.2 sec.
Memory usage: Available 7967.4 MB, Allocated 18.2 MB, Max allocated 82.9 MB

Loading model from results/MSFT/TimeMixer_sl_96_pl_48/2/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 204
Preds and Trues shape: (204, 48, 5) (204, 48, 5)
test scaled -- mse:2.6275, mae:1.1641
Upscaling data and removing negatives...
test -- mse:1.8444e+13, mae:1.458e+06, rmsle: 0.17641 smape 9.578


>>>> itr_no: 3, seed: 608 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/MSFT/TimeMixer_sl_96_pl_48/3

Experiment begins at 2024-09-06 02:32:47

>>>>>>> start training :>>>>>>>>>>
train 1869
val 206
Epoch: 1 | Time: 4.16 s | Train Loss: 3.9468 Vali Loss: 2.4035
Validation loss decreased (inf --> 2.403476).  Saving model ...
Epoch: 2 | Time: 4.07 s | Train Loss: 2.2512 Vali Loss: 1.7139
Validation loss decreased (2.403476 --> 1.713884).  Saving model ...
Epoch: 3 | Time: 4.08 s | Train Loss: 1.9922 Vali Loss: 1.6807
Validation loss decreased (1.713884 --> 1.680711).  Saving model ...
Epoch: 4 | Time: 4.08 s | Train Loss: 1.7493 Vali Loss: 1.9881
EarlyStopping counter: 1 out of 3
Epoch: 5 | Time: 4.09 s | Train Loss: 1.517 Vali Loss: 2.5945
EarlyStopping counter: 2 out of 3
Epoch: 6 | Time: 4.08 s | Train Loss: 1.3823 Vali Loss: 2.3578
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 02:33:13.
Model parameters: 95457
Total memory: 7967.4 MB
Allocated memory: 18.2 MB
Max allocated memory: 82.9 MB
Time per epoch: 4.2 sec.
Memory usage: Available 7967.4 MB, Allocated 18.2 MB, Max allocated 82.9 MB

Loading model from results/MSFT/TimeMixer_sl_96_pl_48/3/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 204
Preds and Trues shape: (204, 48, 5) (204, 48, 5)
test scaled -- mse:2.6498, mae:1.1305
Upscaling data and removing negatives...
test -- mse:1.6336e+13, mae:1.2763e+06, rmsle: 0.16409 smape 8.8308

Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='MSFT.csv', features='M', n_features=5, target='OT', freq='d', no_scale=False, seq_len=96, label_len=48, pred_len=48, top_k=5, num_kernels=6, d_model=768, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', dry_run=False, percent=100, model_id='ori', model='CALF', task_loss='l1', distill_loss='l1', logits_loss='l1', tmax=20, r=8, lora_alpha=32, lora_dropout=0.1, word_embedding_path='./utils/wte_pca_500.pt', task_w=1.0, feature_w=0.01, logits_w=1.0, gpt_layers=6, log_fine_name='CALF_result.txt', noise_scale=-100, bootstrap_eval=0, use_gpu=True, enc_in=5, dec_in=5, c_out=5, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
model_id  ori
Experiments will be saved in results/MSFT/CALF_sl_96_pl_48_id_ori/1

Experiment begins at 2024-09-06 02:33:22

>>>>>>> start training :>>>>>>>>>>
train 1869
val 206
Loss function weights: 1.0 1.0 0.01
Orig-- ori
Epoch: 1 | Time: 5 s | Train Loss: 2.1929 Vali Loss: 2.1923
Validation loss decreased (inf --> 2.192307).  Saving model ...
Epoch: 2 | Time: 4.76 s | Train Loss: 1.858 Vali Loss: 2.2157
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 4.8 s | Train Loss: 1.8747 Vali Loss: 2.4388
EarlyStopping counter: 2 out of 3
Epoch: 4 | Time: 4.79 s | Train Loss: 2.1721 Vali Loss: 2.5992
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 02:33:51.
Model parameters: 180070448
Total memory: 7967.4 MB
Allocated memory: 946.8 MB
Max allocated memory: 1254.8 MB
Time per epoch: 7.1 sec.
Memory usage: Available 7967.4 MB, Allocated 946.8 MB, Max allocated 1254.8 MB

Loading model from results/MSFT/CALF_sl_96_pl_48_id_ori/1/llm.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 204
Preds and Trues shape: (204, 48, 5) (204, 48, 5)
test scaled -- mse:3.2692, mae:1.2828
Upscaling data and removing negatives...
test -- mse:1.5811e+13, mae:1.2275e+06, rmsle: 0.1622 smape 9.2756


>>>> itr_no: 2, seed: 506 <<<<<<
Use GPU: cuda:0
model_id  ori
Experiments will be saved in results/MSFT/CALF_sl_96_pl_48_id_ori/2

Experiment begins at 2024-09-06 02:33:53

>>>>>>> start training :>>>>>>>>>>
train 1869
val 206
Loss function weights: 1.0 1.0 0.01
Orig-- ori
Epoch: 1 | Time: 4.86 s | Train Loss: 2.1994 Vali Loss: 2.3118
Validation loss decreased (inf --> 2.311778).  Saving model ...
Epoch: 2 | Time: 4.82 s | Train Loss: 1.9711 Vali Loss: 2.1054
Validation loss decreased (2.311778 --> 2.105359).  Saving model ...
Epoch: 3 | Time: 4.84 s | Train Loss: 1.9602 Vali Loss: 2.3273
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 4.84 s | Train Loss: 2.6668 Vali Loss: 2.2528
EarlyStopping counter: 2 out of 3
Epoch: 5 | Time: 4.84 s | Train Loss: 3.0001 Vali Loss: 2.2493
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 02:34:34.
Model parameters: 180070448
Total memory: 7967.4 MB
Allocated memory: 950.0 MB
Max allocated memory: 1637.3 MB
Time per epoch: 8.1 sec.
Memory usage: Available 7967.4 MB, Allocated 950.0 MB, Max allocated 1637.3 MB

Loading model from results/MSFT/CALF_sl_96_pl_48_id_ori/2/llm.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 204
Preds and Trues shape: (204, 48, 5) (204, 48, 5)
test scaled -- mse:3.7131, mae:1.3876
Upscaling data and removing negatives...
test -- mse:2.8532e+13, mae:1.8456e+06, rmsle: 0.209 smape 11.325


>>>> itr_no: 3, seed: 608 <<<<<<
Use GPU: cuda:0
model_id  ori
Experiments will be saved in results/MSFT/CALF_sl_96_pl_48_id_ori/3

Experiment begins at 2024-09-06 02:34:35

>>>>>>> start training :>>>>>>>>>>
train 1869
val 206
Loss function weights: 1.0 1.0 0.01
Orig-- ori
Epoch: 1 | Time: 4.9 s | Train Loss: 2.2078 Vali Loss: 2.2073
Validation loss decreased (inf --> 2.207339).  Saving model ...
Epoch: 2 | Time: 4.87 s | Train Loss: 2.3082 Vali Loss: 2.2189
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 4.85 s | Train Loss: 2.3576 Vali Loss: 2.4531
EarlyStopping counter: 2 out of 3
Epoch: 4 | Time: 4.87 s | Train Loss: 3.55 Vali Loss: 2.2711
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 02:35:03.
Model parameters: 180070448
Total memory: 7967.4 MB
Allocated memory: 948.3 MB
Max allocated memory: 1638.4 MB
Time per epoch: 6.9 sec.
Memory usage: Available 7967.4 MB, Allocated 948.3 MB, Max allocated 1638.4 MB

Loading model from results/MSFT/CALF_sl_96_pl_48_id_ori/3/llm.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 204
Preds and Trues shape: (204, 48, 5) (204, 48, 5)
test scaled -- mse:2.915, mae:1.2254
Upscaling data and removing negatives...
test -- mse:1.6668e+13, mae:1.3596e+06, rmsle: 0.16806 smape 9.4741

Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='MSFT.csv', features='M', n_features=5, target='OT', freq='d', no_scale=False, seq_len=96, label_len=48, pred_len=48, top_k=5, num_kernels=6, d_model=768, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', dry_run=False, percent=100, model_id='ori', model='OFA', gpt_layers=6, is_gpt=1, patch_size=16, kernel_size=25, pretrain=1, freeze=1, stride=8, max_len=-1, hid_dim=16, tmax=20, n_scale=-1, use_gpu=True, enc_in=5, dec_in=5, c_out=5, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/MSFT/OFA_sl_96_pl_48_id_ori/1

Experiment begins at 2024-09-06 02:35:13

>>>>>>> start training :>>>>>>>>>>
train 1869
val 206
Epoch: 1 | Time: 5.45 s | Train Loss: 1.2017 Vali Loss: 1.0898
Validation loss decreased (inf --> 1.089804).  Saving model ...
Epoch: 2 | Time: 5.24 s | Train Loss: 1.0779 Vali Loss: 1.0404
Validation loss decreased (1.089804 --> 1.040373).  Saving model ...
Epoch: 3 | Time: 5.24 s | Train Loss: 1.0412 Vali Loss: 1.0941
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 5.2 s | Train Loss: 1.0114 Vali Loss: 1.088
EarlyStopping counter: 2 out of 3
Epoch: 5 | Time: 5.21 s | Train Loss: 0.97649 Vali Loss: 1.0155
Validation loss decreased (1.040373 --> 1.015530).  Saving model ...
Epoch: 6 | Time: 5.27 s | Train Loss: 0.9373 Vali Loss: 1.1241
EarlyStopping counter: 1 out of 3
Epoch: 7 | Time: 5.23 s | Train Loss: 0.9193 Vali Loss: 1.0099
Validation loss decreased (1.015530 --> 1.009868).  Saving model ...
Epoch: 8 | Time: 5.32 s | Train Loss: 0.8879 Vali Loss: 1.0425
EarlyStopping counter: 1 out of 3
Epoch: 9 | Time: 5.26 s | Train Loss: 0.86463 Vali Loss: 1.0721
EarlyStopping counter: 2 out of 3
Epoch: 10 | Time: 5.28 s | Train Loss: 0.84959 Vali Loss: 1.0708
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 02:36:22.
Model parameters: 82368048
Total memory: 7967.4 MB
Allocated memory: 353.4 MB
Max allocated memory: 1243.0 MB
Time per epoch: 6.9 sec.
Memory usage: Available 7967.4 MB, Allocated 353.4 MB, Max allocated 1243.0 MB

Loading model from results/MSFT/OFA_sl_96_pl_48_id_ori/1/llm.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 204
Preds and Trues shape: (204, 48, 5) (204, 48, 5)
test scaled -- mse:2.6288, mae:1.1086
Upscaling data and removing negatives...
test -- mse:1.7645e+13, mae:1.3844e+06, rmsle: 0.17144 smape 9.1088


>>>> itr_no: 2, seed: 506 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/MSFT/OFA_sl_96_pl_48_id_ori/2

Experiment begins at 2024-09-06 02:36:23

>>>>>>> start training :>>>>>>>>>>
train 1869
val 206
Epoch: 1 | Time: 5.28 s | Train Loss: 1.1741 Vali Loss: 1.0576
Validation loss decreased (inf --> 1.057631).  Saving model ...
Epoch: 2 | Time: 5.33 s | Train Loss: 1.0702 Vali Loss: 1.0568
Validation loss decreased (1.057631 --> 1.056766).  Saving model ...
Epoch: 3 | Time: 5.32 s | Train Loss: 1.0349 Vali Loss: 1.0146
Validation loss decreased (1.056766 --> 1.014554).  Saving model ...
Epoch: 4 | Time: 5.33 s | Train Loss: 1.0087 Vali Loss: 0.99569
Validation loss decreased (1.014554 --> 0.995690).  Saving model ...
Epoch: 5 | Time: 5.29 s | Train Loss: 0.99545 Vali Loss: 0.9865
Validation loss decreased (0.995690 --> 0.986498).  Saving model ...
Epoch: 6 | Time: 5.26 s | Train Loss: 0.95472 Vali Loss: 1.0371
EarlyStopping counter: 1 out of 3
Epoch: 7 | Time: 5.22 s | Train Loss: 0.93297 Vali Loss: 1.0689
EarlyStopping counter: 2 out of 3
Epoch: 8 | Time: 5.25 s | Train Loss: 0.9059 Vali Loss: 1.0243
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 02:37:26.
Model parameters: 82368048
Total memory: 7967.4 MB
Allocated memory: 354.5 MB
Max allocated memory: 1245.0 MB
Time per epoch: 7.8 sec.
Memory usage: Available 7967.4 MB, Allocated 354.5 MB, Max allocated 1245.0 MB

Loading model from results/MSFT/OFA_sl_96_pl_48_id_ori/2/llm.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 204
Preds and Trues shape: (204, 48, 5) (204, 48, 5)
test scaled -- mse:2.5424, mae:1.0955
Upscaling data and removing negatives...
test -- mse:1.7301e+13, mae:1.313e+06, rmsle: 0.16706 smape 8.7965


>>>> itr_no: 3, seed: 608 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/MSFT/OFA_sl_96_pl_48_id_ori/3

Experiment begins at 2024-09-06 02:37:27

>>>>>>> start training :>>>>>>>>>>
train 1869
val 206
Epoch: 1 | Time: 5.28 s | Train Loss: 1.185 Vali Loss: 1.0759
Validation loss decreased (inf --> 1.075879).  Saving model ...
Epoch: 2 | Time: 5.33 s | Train Loss: 1.0563 Vali Loss: 1.0473
Validation loss decreased (1.075879 --> 1.047348).  Saving model ...
Epoch: 3 | Time: 5.32 s | Train Loss: 1.0335 Vali Loss: 1.0493
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 5.25 s | Train Loss: 1.0109 Vali Loss: 1.0223
Validation loss decreased (1.047348 --> 1.022322).  Saving model ...
Epoch: 5 | Time: 5.3 s | Train Loss: 0.98696 Vali Loss: 1.0298
EarlyStopping counter: 1 out of 3
Epoch: 6 | Time: 5.26 s | Train Loss: 0.97986 Vali Loss: 1.0127
Validation loss decreased (1.022322 --> 1.012652).  Saving model ...
Epoch: 7 | Time: 5.3 s | Train Loss: 0.94207 Vali Loss: 1.0783
EarlyStopping counter: 1 out of 3
Epoch: 8 | Time: 5.28 s | Train Loss: 0.90035 Vali Loss: 0.9993
Validation loss decreased (1.012652 --> 0.999302).  Saving model ...
Epoch: 9 | Time: 5.3 s | Train Loss: 0.86973 Vali Loss: 1.0209
EarlyStopping counter: 1 out of 3
Epoch: 10 | Time: 5.24 s | Train Loss: 0.84977 Vali Loss: 1.1062
EarlyStopping counter: 2 out of 3

Training completed at 2024-09-06 02:38:40.
Model parameters: 82368048
Total memory: 7967.4 MB
Allocated memory: 353.1 MB
Max allocated memory: 1245.0 MB
Time per epoch: 7.2 sec.
Memory usage: Available 7967.4 MB, Allocated 353.1 MB, Max allocated 1245.0 MB

Loading model from results/MSFT/OFA_sl_96_pl_48_id_ori/3/llm.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 204
Preds and Trues shape: (204, 48, 5) (204, 48, 5)
test scaled -- mse:2.5866, mae:1.1203
Upscaling data and removing negatives...
test -- mse:1.8164e+13, mae:1.3835e+06, rmsle: 0.17367 smape 9.1526

Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='MSFT.csv', features='M', n_features=5, target='OT', freq='d', no_scale=False, seq_len=96, label_len=48, pred_len=48, top_k=5, num_kernels=6, d_model=16, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=16, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', dry_run=False, percent=100, model_id='ori', model='TimeLLM', patch_len=16, stride=8, prompt_domain=1, llm_model='GPT2', llm_dim=768, llm_layers=6, use_gpu=True, enc_in=5, dec_in=5, c_out=5, task_name='long_term_forecast', content='Microsoft Corporation stock prices.Microsoft develops and licenses consumer and enterprise software.')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
description: Microsoft Corporation stock prices.Microsoft develops and licenses consumer and enterprise software.
Experiments will be saved in results/MSFT/TimeLLM_sl_96_pl_48_id_ori/1

Experiment begins at 2024-09-06 02:38:50

>>>>>>> start training :>>>>>>>>>>
train 1869
val 206
Epoch: 1 | Time: 67.9 s | Train Loss: 3.2537 Vali Loss: 2.4615
Validation loss decreased (inf --> 2.461509).  Saving model ...
Epoch: 2 | Time: 65.7 s | Train Loss: 2.7072 Vali Loss: 2.6297
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 65.9 s | Train Loss: 2.7051 Vali Loss: 2.2252
Validation loss decreased (2.461509 --> 2.225176).  Saving model ...
Epoch: 4 | Time: 65.7 s | Train Loss: 2.7282 Vali Loss: 2.3836
EarlyStopping counter: 1 out of 3
Epoch: 5 | Time: 65.8 s | Train Loss: 2.6813 Vali Loss: 2.5886
EarlyStopping counter: 2 out of 3
Epoch: 6 | Time: 65.9 s | Train Loss: 2.6189 Vali Loss: 2.4246
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 02:45:40.
Model parameters: 133434752
Total memory: 7967.4 MB
Allocated memory: 1126.7 MB
Max allocated memory: 6735.2 MB
Time per epoch: 68.4 sec.
Memory usage: Available 7967.4 MB, Allocated 1126.7 MB, Max allocated 6735.2 MB

Loading model from results/MSFT/TimeLLM_sl_96_pl_48_id_ori/1/llm.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 204
Preds and Trues shape: (204, 48, 5) (204, 48, 5)
test scaled -- mse:2.6077, mae:1.1559
Upscaling data and removing negatives...
test -- mse:2.254e+13, mae:1.6206e+06, rmsle: 0.18937 smape 9.8491


>>>> itr_no: 2, seed: 506 <<<<<<
Use GPU: cuda:0
description: Microsoft Corporation stock prices.Microsoft develops and licenses consumer and enterprise software.
Experiments will be saved in results/MSFT/TimeLLM_sl_96_pl_48_id_ori/2

Experiment begins at 2024-09-06 02:45:46

>>>>>>> start training :>>>>>>>>>>
train 1869
val 206
Epoch: 1 | Time: 67.9 s | Train Loss: 2.9887 Vali Loss: 2.466
Validation loss decreased (inf --> 2.465999).  Saving model ...
Epoch: 2 | Time: 65.7 s | Train Loss: 2.684 Vali Loss: 2.4832
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 65.9 s | Train Loss: 2.777 Vali Loss: 2.1797
Validation loss decreased (2.465999 --> 2.179704).  Saving model ...
Epoch: 4 | Time: 65.6 s | Train Loss: 2.7428 Vali Loss: 2.7838
EarlyStopping counter: 1 out of 3
Epoch: 5 | Time: 65.9 s | Train Loss: 2.7796 Vali Loss: 2.2068
EarlyStopping counter: 2 out of 3
Epoch: 6 | Time: 65.8 s | Train Loss: 2.6437 Vali Loss: 2.2582
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 02:52:35.
Model parameters: 133434752
Total memory: 7967.4 MB
Allocated memory: 1125.0 MB
Max allocated memory: 6735.2 MB
Time per epoch: 68.3 sec.
Memory usage: Available 7967.4 MB, Allocated 1125.0 MB, Max allocated 6735.2 MB

Loading model from results/MSFT/TimeLLM_sl_96_pl_48_id_ori/2/llm.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 204
Preds and Trues shape: (204, 48, 5) (204, 48, 5)
test scaled -- mse:2.7511, mae:1.1951
Upscaling data and removing negatives...
test -- mse:2.3006e+13, mae:1.5604e+06, rmsle: 0.18829 smape 9.8197


>>>> itr_no: 3, seed: 608 <<<<<<
Use GPU: cuda:0
description: Microsoft Corporation stock prices.Microsoft develops and licenses consumer and enterprise software.
Experiments will be saved in results/MSFT/TimeLLM_sl_96_pl_48_id_ori/3

Experiment begins at 2024-09-06 02:52:44

>>>>>>> start training :>>>>>>>>>>
train 1869
val 206
Epoch: 1 | Time: 68 s | Train Loss: 3.2561 Vali Loss: 2.2617
Validation loss decreased (inf --> 2.261687).  Saving model ...
Epoch: 2 | Time: 65.6 s | Train Loss: 2.7459 Vali Loss: 2.6823
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 66 s | Train Loss: 2.7176 Vali Loss: 2.2905
EarlyStopping counter: 2 out of 3
Epoch: 4 | Time: 65.9 s | Train Loss: 2.6421 Vali Loss: 2.2881
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 02:57:16.
Model parameters: 133434752
Total memory: 7967.4 MB
Allocated memory: 1126.7 MB
Max allocated memory: 6735.2 MB
Time per epoch: 68.0 sec.
Memory usage: Available 7967.4 MB, Allocated 1126.7 MB, Max allocated 6735.2 MB

Loading model from results/MSFT/TimeLLM_sl_96_pl_48_id_ori/3/llm.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 204
Preds and Trues shape: (204, 48, 5) (204, 48, 5)
test scaled -- mse:2.5923, mae:1.1852
Upscaling data and removing negatives...
test -- mse:2.5365e+13, mae:1.7948e+06, rmsle: 0.2025 smape 10.552

Running for model:DLinear
Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='Natural_Gas.csv', features='M', n_features=5, target='OT', freq='d', no_scale=False, seq_len=96, label_len=48, pred_len=48, top_k=5, num_kernels=6, d_model=64, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, channel_independence=1, decomp_method='moving_avg', use_norm=1, down_sampling_layers=0, down_sampling_window=1, down_sampling_method=None, seg_len=48, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, dry_run=False, percent=100, model='DLinear', use_gpu=True, enc_in=5, dec_in=5, c_out=5, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Natural_Gas/DLinear_sl_96_pl_48/1

Experiment begins at 2024-09-06 02:57:27

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Epoch: 1 | Time: 1.74 s | Train Loss: 4.4234 Vali Loss: 1.9006
Validation loss decreased (inf --> 1.900623).  Saving model ...
Epoch: 2 | Time: 1.68 s | Train Loss: 3.9002 Vali Loss: 1.9606
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 1.65 s | Train Loss: 3.7656 Vali Loss: 1.9282
EarlyStopping counter: 2 out of 3
Epoch: 4 | Time: 1.65 s | Train Loss: 3.687 Vali Loss: 1.9188
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 02:57:34.
Model parameters: 9312
Total memory: 7967.4 MB
Allocated memory: 16.6 MB
Max allocated memory: 17.1 MB
Time per epoch: 1.9 sec.
Memory usage: Available 7967.4 MB, Allocated 16.6 MB, Max allocated 17.1 MB

Loading model from results/Natural_Gas/DLinear_sl_96_pl_48/1/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:3.0452, mae:1.4021
Upscaling data and removing negatives...
test -- mse:5.7205e+08, mae:8237.3, rmsle: 0.43336 smape 24.351


>>>> itr_no: 2, seed: 506 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Natural_Gas/DLinear_sl_96_pl_48/2

Experiment begins at 2024-09-06 02:57:35

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Epoch: 1 | Time: 1.65 s | Train Loss: 4.5055 Vali Loss: 1.8704
Validation loss decreased (inf --> 1.870391).  Saving model ...
Epoch: 2 | Time: 1.66 s | Train Loss: 3.9254 Vali Loss: 1.872
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 1.67 s | Train Loss: 3.7854 Vali Loss: 1.8506
Validation loss decreased (1.870391 --> 1.850638).  Saving model ...
Epoch: 4 | Time: 1.66 s | Train Loss: 3.6804 Vali Loss: 1.8921
EarlyStopping counter: 1 out of 3
Epoch: 5 | Time: 1.68 s | Train Loss: 3.6398 Vali Loss: 1.9043
EarlyStopping counter: 2 out of 3
Epoch: 6 | Time: 1.66 s | Train Loss: 3.593 Vali Loss: 1.9047
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 02:57:46.
Model parameters: 9312
Total memory: 7967.4 MB
Allocated memory: 16.6 MB
Max allocated memory: 17.1 MB
Time per epoch: 1.8 sec.
Memory usage: Available 7967.4 MB, Allocated 16.6 MB, Max allocated 17.1 MB

Loading model from results/Natural_Gas/DLinear_sl_96_pl_48/2/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:3.0027, mae:1.3666
Upscaling data and removing negatives...
test -- mse:5.0107e+08, mae:7952.8, rmsle: 0.41298 smape 23.406


>>>> itr_no: 3, seed: 608 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Natural_Gas/DLinear_sl_96_pl_48/3

Experiment begins at 2024-09-06 02:57:46

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Epoch: 1 | Time: 1.62 s | Train Loss: 4.4493 Vali Loss: 1.9127
Validation loss decreased (inf --> 1.912729).  Saving model ...
Epoch: 2 | Time: 1.7 s | Train Loss: 3.9056 Vali Loss: 1.8832
Validation loss decreased (1.912729 --> 1.883164).  Saving model ...
Epoch: 3 | Time: 1.68 s | Train Loss: 3.7573 Vali Loss: 1.9178
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 1.64 s | Train Loss: 3.6854 Vali Loss: 1.9025
EarlyStopping counter: 2 out of 3
Epoch: 5 | Time: 1.64 s | Train Loss: 3.629 Vali Loss: 1.9116
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 02:57:55.
Model parameters: 9312
Total memory: 7967.4 MB
Allocated memory: 16.6 MB
Max allocated memory: 17.1 MB
Time per epoch: 1.8 sec.
Memory usage: Available 7967.4 MB, Allocated 16.6 MB, Max allocated 17.1 MB

Loading model from results/Natural_Gas/DLinear_sl_96_pl_48/3/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:3.0161, mae:1.377
Upscaling data and removing negatives...
test -- mse:5.1529e+08, mae:7989.4, rmsle: 0.41931 smape 23.612

Running for model:PatchTST
Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='Natural_Gas.csv', features='M', n_features=5, target='OT', freq='d', no_scale=False, seq_len=96, label_len=48, pred_len=48, top_k=5, num_kernels=6, d_model=64, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, channel_independence=1, decomp_method='moving_avg', use_norm=1, down_sampling_layers=0, down_sampling_window=1, down_sampling_method=None, seg_len=48, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, dry_run=False, percent=100, model='PatchTST', use_gpu=True, enc_in=5, dec_in=5, c_out=5, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Natural_Gas/PatchTST_sl_96_pl_48/1

Experiment begins at 2024-09-06 02:58:00

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Epoch: 1 | Time: 2.29 s | Train Loss: 3.9359 Vali Loss: 2.3217
Validation loss decreased (inf --> 2.321651).  Saving model ...
Epoch: 2 | Time: 2.03 s | Train Loss: 3.4 Vali Loss: 3.0901
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 2.03 s | Train Loss: 2.9464 Vali Loss: 3.7818
EarlyStopping counter: 2 out of 3
Epoch: 4 | Time: 2.05 s | Train Loss: 2.6195 Vali Loss: 3.9037
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 02:58:09.
Model parameters: 105008
Total memory: 7967.4 MB
Allocated memory: 19.3 MB
Max allocated memory: 169.0 MB
Time per epoch: 2.4 sec.
Memory usage: Available 7967.4 MB, Allocated 19.3 MB, Max allocated 169.0 MB

Loading model from results/Natural_Gas/PatchTST_sl_96_pl_48/1/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:3.2841, mae:1.4093
Upscaling data and removing negatives...
test -- mse:5.9631e+08, mae:8642, rmsle: 0.43124 smape 25.393


>>>> itr_no: 2, seed: 506 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Natural_Gas/PatchTST_sl_96_pl_48/2

Experiment begins at 2024-09-06 02:58:10

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Epoch: 1 | Time: 2.03 s | Train Loss: 3.9636 Vali Loss: 3.0983
Validation loss decreased (inf --> 3.098336).  Saving model ...
Epoch: 2 | Time: 2.03 s | Train Loss: 3.509 Vali Loss: 2.5566
Validation loss decreased (3.098336 --> 2.556563).  Saving model ...
Epoch: 3 | Time: 2.02 s | Train Loss: 3.1567 Vali Loss: 2.497
Validation loss decreased (2.556563 --> 2.496965).  Saving model ...
Epoch: 4 | Time: 2.11 s | Train Loss: 2.8367 Vali Loss: 4.6626
EarlyStopping counter: 1 out of 3
Epoch: 5 | Time: 2.08 s | Train Loss: 2.4523 Vali Loss: 4.5639
EarlyStopping counter: 2 out of 3
Epoch: 6 | Time: 2.09 s | Train Loss: 2.1904 Vali Loss: 4.8602
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 02:58:23.
Model parameters: 105008
Total memory: 7967.4 MB
Allocated memory: 19.3 MB
Max allocated memory: 169.0 MB
Time per epoch: 2.2 sec.
Memory usage: Available 7967.4 MB, Allocated 19.3 MB, Max allocated 169.0 MB

Loading model from results/Natural_Gas/PatchTST_sl_96_pl_48/2/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:3.3274, mae:1.3653
Upscaling data and removing negatives...
test -- mse:6.006e+08, mae:8729.4, rmsle: 0.39985 smape 23.682


>>>> itr_no: 3, seed: 608 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Natural_Gas/PatchTST_sl_96_pl_48/3

Experiment begins at 2024-09-06 02:58:24

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Epoch: 1 | Time: 2.1 s | Train Loss: 4.0459 Vali Loss: 2.3417
Validation loss decreased (inf --> 2.341743).  Saving model ...
Epoch: 2 | Time: 2.06 s | Train Loss: 3.5484 Vali Loss: 2.0135
Validation loss decreased (2.341743 --> 2.013499).  Saving model ...
Epoch: 3 | Time: 2.12 s | Train Loss: 3.3742 Vali Loss: 3.2549
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 2.09 s | Train Loss: 3.1152 Vali Loss: 2.9337
EarlyStopping counter: 2 out of 3
Epoch: 5 | Time: 2.09 s | Train Loss: 2.6422 Vali Loss: 3.6302
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 02:58:35.
Model parameters: 105008
Total memory: 7967.4 MB
Allocated memory: 19.3 MB
Max allocated memory: 169.0 MB
Time per epoch: 2.2 sec.
Memory usage: Available 7967.4 MB, Allocated 19.3 MB, Max allocated 169.0 MB

Loading model from results/Natural_Gas/PatchTST_sl_96_pl_48/3/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:3.62, mae:1.4283
Upscaling data and removing negatives...
test -- mse:5.4684e+08, mae:8264.1, rmsle: 0.39999 smape 24.346

Running for model:TimesNet
Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='Natural_Gas.csv', features='M', n_features=5, target='OT', freq='d', no_scale=False, seq_len=96, label_len=48, pred_len=48, top_k=5, num_kernels=6, d_model=64, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, channel_independence=1, decomp_method='moving_avg', use_norm=1, down_sampling_layers=0, down_sampling_window=1, down_sampling_method=None, seg_len=48, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, dry_run=False, percent=100, model='TimesNet', use_gpu=True, enc_in=5, dec_in=5, c_out=5, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Natural_Gas/TimesNet_sl_96_pl_48/1

Experiment begins at 2024-09-06 02:58:41

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Epoch: 1 | Time: 41.3 s | Train Loss: 3.9557 Vali Loss: 2.0551
Validation loss decreased (inf --> 2.055138).  Saving model ...
Epoch: 2 | Time: 37.2 s | Train Loss: 3.4744 Vali Loss: 3.0665
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 33.5 s | Train Loss: 2.8676 Vali Loss: 3.1979
EarlyStopping counter: 2 out of 3
Epoch: 4 | Time: 34 s | Train Loss: 2.3541 Vali Loss: 2.8373
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 03:01:09.
Model parameters: 9389525
Total memory: 7967.4 MB
Allocated memory: 165.2 MB
Max allocated memory: 1773.6 MB
Time per epoch: 36.9 sec.
Memory usage: Available 7967.4 MB, Allocated 165.2 MB, Max allocated 1773.6 MB

Loading model from results/Natural_Gas/TimesNet_sl_96_pl_48/1/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:3.6173, mae:1.5183
Upscaling data and removing negatives...
test -- mse:6.6336e+08, mae:8595.3, rmsle: 0.45316 smape 26.229


>>>> itr_no: 2, seed: 506 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Natural_Gas/TimesNet_sl_96_pl_48/2

Experiment begins at 2024-09-06 03:01:12

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Epoch: 1 | Time: 46.3 s | Train Loss: 4.1692 Vali Loss: 2.1633
Validation loss decreased (inf --> 2.163349).  Saving model ...
Epoch: 2 | Time: 53.1 s | Train Loss: 3.6308 Vali Loss: 2.283
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 49.4 s | Train Loss: 3.3632 Vali Loss: 2.3908
EarlyStopping counter: 2 out of 3
Epoch: 4 | Time: 51.3 s | Train Loss: 3.1428 Vali Loss: 2.2639
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 03:04:33.
Model parameters: 9389525
Total memory: 7967.4 MB
Allocated memory: 168.3 MB
Max allocated memory: 1778.4 MB
Time per epoch: 50.2 sec.
Memory usage: Available 7967.4 MB, Allocated 168.3 MB, Max allocated 1778.4 MB

Loading model from results/Natural_Gas/TimesNet_sl_96_pl_48/2/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:3.4357, mae:1.4248
Upscaling data and removing negatives...
test -- mse:6.7205e+08, mae:8762, rmsle: 0.44516 smape 24.232


>>>> itr_no: 3, seed: 608 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Natural_Gas/TimesNet_sl_96_pl_48/3

Experiment begins at 2024-09-06 03:04:37

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Epoch: 1 | Time: 29.2 s | Train Loss: 3.9757 Vali Loss: 2.2434
Validation loss decreased (inf --> 2.243422).  Saving model ...
Epoch: 2 | Time: 27.4 s | Train Loss: 3.3271 Vali Loss: 2.2326
Validation loss decreased (2.243422 --> 2.232628).  Saving model ...
Epoch: 3 | Time: 26.6 s | Train Loss: 2.9478 Vali Loss: 2.5694
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 26.2 s | Train Loss: 2.6832 Vali Loss: 2.6901
EarlyStopping counter: 2 out of 3
Epoch: 5 | Time: 25.8 s | Train Loss: 2.3875 Vali Loss: 3.0347
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 03:06:53.
Model parameters: 9389525
Total memory: 7967.4 MB
Allocated memory: 168.2 MB
Max allocated memory: 1780.5 MB
Time per epoch: 27.3 sec.
Memory usage: Available 7967.4 MB, Allocated 168.2 MB, Max allocated 1780.5 MB

Loading model from results/Natural_Gas/TimesNet_sl_96_pl_48/3/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:2.7068, mae:1.2929
Upscaling data and removing negatives...
test -- mse:6.6266e+08, mae:8772.3, rmsle: 0.43539 smape 23.232

Running for model:iTransformer
Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='Natural_Gas.csv', features='M', n_features=5, target='OT', freq='d', no_scale=False, seq_len=96, label_len=48, pred_len=48, top_k=5, num_kernels=6, d_model=64, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, channel_independence=1, decomp_method='moving_avg', use_norm=1, down_sampling_layers=0, down_sampling_window=1, down_sampling_method=None, seg_len=48, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, dry_run=False, percent=100, model='iTransformer', use_gpu=True, enc_in=5, dec_in=5, c_out=5, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Natural_Gas/iTransformer_sl_96_pl_48/1

Experiment begins at 2024-09-06 03:07:01

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Epoch: 1 | Time: 2.22 s | Train Loss: 4.2201 Vali Loss: 1.9029
Validation loss decreased (inf --> 1.902862).  Saving model ...
Epoch: 2 | Time: 1.99 s | Train Loss: 3.3361 Vali Loss: 2.5569
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 1.97 s | Train Loss: 2.732 Vali Loss: 3.0975
EarlyStopping counter: 2 out of 3
Epoch: 4 | Time: 1.98 s | Train Loss: 2.3837 Vali Loss: 2.9456
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 03:07:11.
Model parameters: 76400
Total memory: 7967.4 MB
Allocated memory: 17.7 MB
Max allocated memory: 147.6 MB
Time per epoch: 2.3 sec.
Memory usage: Available 7967.4 MB, Allocated 17.7 MB, Max allocated 147.6 MB

Loading model from results/Natural_Gas/iTransformer_sl_96_pl_48/1/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:3.1172, mae:1.3992
Upscaling data and removing negatives...
test -- mse:8.6749e+08, mae:10436, rmsle: 0.45476 smape 25.21


>>>> itr_no: 2, seed: 506 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Natural_Gas/iTransformer_sl_96_pl_48/2

Experiment begins at 2024-09-06 03:07:11

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Epoch: 1 | Time: 1.96 s | Train Loss: 4.2647 Vali Loss: 2.0833
Validation loss decreased (inf --> 2.083263).  Saving model ...
Epoch: 2 | Time: 1.97 s | Train Loss: 3.2967 Vali Loss: 2.501
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 1.97 s | Train Loss: 2.7585 Vali Loss: 3.386
EarlyStopping counter: 2 out of 3
Epoch: 4 | Time: 2.06 s | Train Loss: 2.3738 Vali Loss: 3.1551
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 03:07:20.
Model parameters: 76400
Total memory: 7967.4 MB
Allocated memory: 17.7 MB
Max allocated memory: 147.6 MB
Time per epoch: 2.1 sec.
Memory usage: Available 7967.4 MB, Allocated 17.7 MB, Max allocated 147.6 MB

Loading model from results/Natural_Gas/iTransformer_sl_96_pl_48/2/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:2.9462, mae:1.3455
Upscaling data and removing negatives...
test -- mse:8.38e+08, mae:10224, rmsle: 0.44753 smape 23.87


>>>> itr_no: 3, seed: 608 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Natural_Gas/iTransformer_sl_96_pl_48/3

Experiment begins at 2024-09-06 03:07:20

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Epoch: 1 | Time: 2.03 s | Train Loss: 4.2456 Vali Loss: 2.5565
Validation loss decreased (inf --> 2.556494).  Saving model ...
Epoch: 2 | Time: 2.05 s | Train Loss: 3.3337 Vali Loss: 2.6762
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 2.03 s | Train Loss: 2.773 Vali Loss: 3.5696
EarlyStopping counter: 2 out of 3
Epoch: 4 | Time: 2.05 s | Train Loss: 2.3746 Vali Loss: 3.4219
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 03:07:29.
Model parameters: 76400
Total memory: 7967.4 MB
Allocated memory: 17.7 MB
Max allocated memory: 147.6 MB
Time per epoch: 2.1 sec.
Memory usage: Available 7967.4 MB, Allocated 17.7 MB, Max allocated 147.6 MB

Loading model from results/Natural_Gas/iTransformer_sl_96_pl_48/3/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:3.0203, mae:1.3517
Upscaling data and removing negatives...
test -- mse:9.8875e+08, mae:11096, rmsle: 0.45528 smape 23.559

Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='Natural_Gas.csv', features='M', n_features=5, target='OT', freq='d', no_scale=False, seq_len=96, label_len=96, pred_len=48, top_k=5, num_kernels=6, d_model=64, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, channel_independence=1, decomp_method='moving_avg', use_norm=1, down_sampling_layers=0, down_sampling_window=1, down_sampling_method=None, seg_len=48, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, dry_run=False, percent=100, model='MICN', use_gpu=True, enc_in=5, dec_in=5, c_out=5, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Natural_Gas/MICN_sl_96_pl_48/1

Experiment begins at 2024-09-06 03:07:34

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Epoch: 1 | Time: 2.48 s | Train Loss: 4.2668 Vali Loss: 2.0622
Validation loss decreased (inf --> 2.062198).  Saving model ...
Epoch: 2 | Time: 2.22 s | Train Loss: 3.6093 Vali Loss: 2.1612
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 2.15 s | Train Loss: 3.3473 Vali Loss: 1.953
Validation loss decreased (2.062198 --> 1.952965).  Saving model ...
Epoch: 4 | Time: 2.1 s | Train Loss: 2.9729 Vali Loss: 2.1385
EarlyStopping counter: 1 out of 3
Epoch: 5 | Time: 2.09 s | Train Loss: 2.3179 Vali Loss: 2.3599
EarlyStopping counter: 2 out of 3
Epoch: 6 | Time: 2.1 s | Train Loss: 1.7911 Vali Loss: 2.2376
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 03:07:49.
Model parameters: 371829
Total memory: 7967.4 MB
Allocated memory: 23.4 MB
Max allocated memory: 179.9 MB
Time per epoch: 2.4 sec.
Memory usage: Available 7967.4 MB, Allocated 23.4 MB, Max allocated 179.9 MB

Loading model from results/Natural_Gas/MICN_sl_96_pl_48/1/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:2.9197, mae:1.3249
Upscaling data and removing negatives...
test -- mse:4.4229e+08, mae:7412, rmsle: 0.39321 smape 22.688


>>>> itr_no: 2, seed: 506 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Natural_Gas/MICN_sl_96_pl_48/2

Experiment begins at 2024-09-06 03:07:49

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Epoch: 1 | Time: 2.1 s | Train Loss: 4.2172 Vali Loss: 2.053
Validation loss decreased (inf --> 2.052974).  Saving model ...
Epoch: 2 | Time: 2.14 s | Train Loss: 3.6165 Vali Loss: 1.9197
Validation loss decreased (2.052974 --> 1.919747).  Saving model ...
Epoch: 3 | Time: 2.1 s | Train Loss: 3.3832 Vali Loss: 2.2413
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 2.13 s | Train Loss: 3.06 Vali Loss: 1.7114
Validation loss decreased (1.919747 --> 1.711419).  Saving model ...
Epoch: 5 | Time: 2.11 s | Train Loss: 2.3925 Vali Loss: 1.9925
EarlyStopping counter: 1 out of 3
Epoch: 6 | Time: 2.12 s | Train Loss: 1.7993 Vali Loss: 2.3766
EarlyStopping counter: 2 out of 3
Epoch: 7 | Time: 2.14 s | Train Loss: 1.3881 Vali Loss: 2.1491
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 03:08:05.
Model parameters: 371829
Total memory: 7967.4 MB
Allocated memory: 23.4 MB
Max allocated memory: 179.9 MB
Time per epoch: 2.2 sec.
Memory usage: Available 7967.4 MB, Allocated 23.4 MB, Max allocated 179.9 MB

Loading model from results/Natural_Gas/MICN_sl_96_pl_48/2/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:2.9592, mae:1.3358
Upscaling data and removing negatives...
test -- mse:4.4595e+08, mae:7407.7, rmsle: 0.39022 smape 23.324


>>>> itr_no: 3, seed: 608 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Natural_Gas/MICN_sl_96_pl_48/3

Experiment begins at 2024-09-06 03:08:05

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Epoch: 1 | Time: 2.17 s | Train Loss: 4.2531 Vali Loss: 1.9445
Validation loss decreased (inf --> 1.944476).  Saving model ...
Epoch: 2 | Time: 2.21 s | Train Loss: 3.6454 Vali Loss: 2.0387
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 2.17 s | Train Loss: 3.4055 Vali Loss: 1.7035
Validation loss decreased (1.944476 --> 1.703540).  Saving model ...
Epoch: 4 | Time: 2.2 s | Train Loss: 3.1487 Vali Loss: 2.0002
EarlyStopping counter: 1 out of 3
Epoch: 5 | Time: 2.13 s | Train Loss: 2.5329 Vali Loss: 2.2566
EarlyStopping counter: 2 out of 3
Epoch: 6 | Time: 2.17 s | Train Loss: 1.9327 Vali Loss: 2.2345
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 03:08:19.
Model parameters: 371829
Total memory: 7967.4 MB
Allocated memory: 23.4 MB
Max allocated memory: 179.9 MB
Time per epoch: 2.3 sec.
Memory usage: Available 7967.4 MB, Allocated 23.4 MB, Max allocated 179.9 MB

Loading model from results/Natural_Gas/MICN_sl_96_pl_48/3/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:3.0946, mae:1.3734
Upscaling data and removing negatives...
test -- mse:4.4192e+08, mae:7363.5, rmsle: 0.39438 smape 23.785

Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='Natural_Gas.csv', features='M', n_features=5, target='OT', freq='d', no_scale=False, seq_len=96, label_len=0, pred_len=48, top_k=5, num_kernels=6, d_model=16, n_heads=4, e_layers=3, d_layers=1, d_ff=32, moving_avg=3, factor=3, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, channel_independence=1, decomp_method='moving_avg', use_norm=1, down_sampling_layers=3, down_sampling_window=2, down_sampling_method='avg', seg_len=48, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, dry_run=False, percent=100, model='TimeMixer', use_gpu=True, enc_in=5, dec_in=5, c_out=5, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Natural_Gas/TimeMixer_sl_96_pl_48/1

Experiment begins at 2024-09-06 03:08:27

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Epoch: 1 | Time: 3.96 s | Train Loss: 4.4425 Vali Loss: 2.3664
Validation loss decreased (inf --> 2.366439).  Saving model ...
Epoch: 2 | Time: 3.64 s | Train Loss: 3.2578 Vali Loss: 3.4227
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 3.77 s | Train Loss: 2.7163 Vali Loss: 4.3736
EarlyStopping counter: 2 out of 3
Epoch: 4 | Time: 3.8 s | Train Loss: 2.1739 Vali Loss: 4.1873
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 03:08:44.
Model parameters: 95457
Total memory: 7967.4 MB
Allocated memory: 18.3 MB
Max allocated memory: 82.9 MB
Time per epoch: 4.1 sec.
Memory usage: Available 7967.4 MB, Allocated 18.3 MB, Max allocated 82.9 MB

Loading model from results/Natural_Gas/TimeMixer_sl_96_pl_48/1/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:3.6492, mae:1.4685
Upscaling data and removing negatives...
test -- mse:8.2349e+08, mae:9809, rmsle: 0.46477 smape 24.775


>>>> itr_no: 2, seed: 506 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Natural_Gas/TimeMixer_sl_96_pl_48/2

Experiment begins at 2024-09-06 03:08:44

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Epoch: 1 | Time: 3.83 s | Train Loss: 4.4371 Vali Loss: 2.3838
Validation loss decreased (inf --> 2.383758).  Saving model ...
Epoch: 2 | Time: 3.84 s | Train Loss: 3.2661 Vali Loss: 3.5753
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 3.87 s | Train Loss: 2.7661 Vali Loss: 3.5951
EarlyStopping counter: 2 out of 3
Epoch: 4 | Time: 3.78 s | Train Loss: 2.3681 Vali Loss: 3.7191
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 03:09:00.
Model parameters: 95457
Total memory: 7967.4 MB
Allocated memory: 18.3 MB
Max allocated memory: 82.9 MB
Time per epoch: 3.9 sec.
Memory usage: Available 7967.4 MB, Allocated 18.3 MB, Max allocated 82.9 MB

Loading model from results/Natural_Gas/TimeMixer_sl_96_pl_48/2/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:3.9642, mae:1.562
Upscaling data and removing negatives...
test -- mse:7.6625e+08, mae:9535.3, rmsle: 0.46035 smape 26.499


>>>> itr_no: 3, seed: 608 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Natural_Gas/TimeMixer_sl_96_pl_48/3

Experiment begins at 2024-09-06 03:09:01

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Epoch: 1 | Time: 3.85 s | Train Loss: 4.8933 Vali Loss: 2.5221
Validation loss decreased (inf --> 2.522115).  Saving model ...
Epoch: 2 | Time: 3.86 s | Train Loss: 3.5177 Vali Loss: 2.3045
Validation loss decreased (2.522115 --> 2.304504).  Saving model ...
Epoch: 3 | Time: 3.8 s | Train Loss: 3.1154 Vali Loss: 3.9068
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 3.83 s | Train Loss: 2.7432 Vali Loss: 3.4352
EarlyStopping counter: 2 out of 3
Epoch: 5 | Time: 3.85 s | Train Loss: 2.2871 Vali Loss: 3.5672
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 03:09:21.
Model parameters: 95457
Total memory: 7967.4 MB
Allocated memory: 18.3 MB
Max allocated memory: 82.9 MB
Time per epoch: 4.0 sec.
Memory usage: Available 7967.4 MB, Allocated 18.3 MB, Max allocated 82.9 MB

Loading model from results/Natural_Gas/TimeMixer_sl_96_pl_48/3/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:3.5517, mae:1.4586
Upscaling data and removing negatives...
test -- mse:6.2836e+08, mae:8769.7, rmsle: 0.43419 smape 25.06

Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='Natural_Gas.csv', features='M', n_features=5, target='OT', freq='d', no_scale=False, seq_len=96, label_len=48, pred_len=48, top_k=5, num_kernels=6, d_model=768, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', dry_run=False, percent=100, model_id='ori', model='CALF', task_loss='l1', distill_loss='l1', logits_loss='l1', tmax=20, r=8, lora_alpha=32, lora_dropout=0.1, word_embedding_path='./utils/wte_pca_500.pt', task_w=1.0, feature_w=0.01, logits_w=1.0, gpt_layers=6, log_fine_name='CALF_result.txt', noise_scale=-100, bootstrap_eval=0, use_gpu=True, enc_in=5, dec_in=5, c_out=5, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
model_id  ori
Experiments will be saved in results/Natural_Gas/CALF_sl_96_pl_48_id_ori/1

Experiment begins at 2024-09-06 03:09:28

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Loss function weights: 1.0 1.0 0.01
Orig-- ori
Epoch: 1 | Time: 4.6 s | Train Loss: 2.15 Vali Loss: 2.0018
Validation loss decreased (inf --> 2.001764).  Saving model ...
Epoch: 2 | Time: 4.48 s | Train Loss: 1.9962 Vali Loss: 2.1748
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 4.52 s | Train Loss: 2.0965 Vali Loss: 2.2785
EarlyStopping counter: 2 out of 3
Epoch: 4 | Time: 4.56 s | Train Loss: 2.5772 Vali Loss: 1.9955
Validation loss decreased (2.001764 --> 1.995457).  Saving model ...
Epoch: 5 | Time: 4.52 s | Train Loss: 4.0679 Vali Loss: 1.9843
Validation loss decreased (1.995457 --> 1.984261).  Saving model ...
Epoch: 6 | Time: 4.54 s | Train Loss: 5.1727 Vali Loss: 1.9055
Validation loss decreased (1.984261 --> 1.905465).  Saving model ...
Epoch: 7 | Time: 4.44 s | Train Loss: 4.7874 Vali Loss: 2.0275
EarlyStopping counter: 1 out of 3
Epoch: 8 | Time: 4.43 s | Train Loss: 6.6637 Vali Loss: 1.7695
Validation loss decreased (1.905465 --> 1.769549).  Saving model ...
Epoch: 9 | Time: 4.54 s | Train Loss: 8.1384 Vali Loss: 1.8599
EarlyStopping counter: 1 out of 3
Epoch: 10 | Time: 4.55 s | Train Loss: 10.056 Vali Loss: 1.9396
EarlyStopping counter: 2 out of 3

Training completed at 2024-09-06 03:10:54.
Model parameters: 180070448
Total memory: 7967.4 MB
Allocated memory: 949.8 MB
Max allocated memory: 1254.8 MB
Time per epoch: 8.6 sec.
Memory usage: Available 7967.4 MB, Allocated 949.8 MB, Max allocated 1254.8 MB

Loading model from results/Natural_Gas/CALF_sl_96_pl_48_id_ori/1/llm.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:2.7045, mae:1.2873
Upscaling data and removing negatives...
test -- mse:8.5678e+08, mae:10255, rmsle: 0.4502 smape 24.056


>>>> itr_no: 2, seed: 506 <<<<<<
Use GPU: cuda:0
model_id  ori
Experiments will be saved in results/Natural_Gas/CALF_sl_96_pl_48_id_ori/2

Experiment begins at 2024-09-06 03:10:56

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Loss function weights: 1.0 1.0 0.01
Orig-- ori
Epoch: 1 | Time: 4.45 s | Train Loss: 2.1919 Vali Loss: 1.8427
Validation loss decreased (inf --> 1.842662).  Saving model ...
Epoch: 2 | Time: 4.32 s | Train Loss: 2.0336 Vali Loss: 2.3113
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 4.34 s | Train Loss: 2.0156 Vali Loss: 2.3061
EarlyStopping counter: 2 out of 3
Epoch: 4 | Time: 4.34 s | Train Loss: 2.7022 Vali Loss: 2.3904
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 03:11:22.
Model parameters: 180070448
Total memory: 7967.4 MB
Allocated memory: 954.4 MB
Max allocated memory: 1640.8 MB
Time per epoch: 6.4 sec.
Memory usage: Available 7967.4 MB, Allocated 954.4 MB, Max allocated 1640.8 MB

Loading model from results/Natural_Gas/CALF_sl_96_pl_48_id_ori/2/llm.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:3.0107, mae:1.3719
Upscaling data and removing negatives...
test -- mse:7.4727e+08, mae:9489.2, rmsle: 0.44756 smape 24.574


>>>> itr_no: 3, seed: 608 <<<<<<
Use GPU: cuda:0
model_id  ori
Experiments will be saved in results/Natural_Gas/CALF_sl_96_pl_48_id_ori/3

Experiment begins at 2024-09-06 03:11:24

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Loss function weights: 1.0 1.0 0.01
Orig-- ori
Epoch: 1 | Time: 4.34 s | Train Loss: 2.3842 Vali Loss: 2.3234
Validation loss decreased (inf --> 2.323385).  Saving model ...
Epoch: 2 | Time: 4.48 s | Train Loss: 2.0529 Vali Loss: 2.2834
Validation loss decreased (2.323385 --> 2.283374).  Saving model ...
Epoch: 3 | Time: 4.53 s | Train Loss: 2.3021 Vali Loss: 2.1968
Validation loss decreased (2.283374 --> 2.196814).  Saving model ...
Epoch: 4 | Time: 4.51 s | Train Loss: 3.8969 Vali Loss: 2.0014
Validation loss decreased (2.196814 --> 2.001445).  Saving model ...
Epoch: 5 | Time: 4.51 s | Train Loss: 4.4646 Vali Loss: 2.2412
EarlyStopping counter: 1 out of 3
Epoch: 6 | Time: 4.52 s | Train Loss: 5.4768 Vali Loss: 2.2549
EarlyStopping counter: 2 out of 3
Epoch: 7 | Time: 4.53 s | Train Loss: 7.3649 Vali Loss: 2.0808
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 03:12:27.
Model parameters: 180070448
Total memory: 7967.4 MB
Allocated memory: 955.1 MB
Max allocated memory: 1643.8 MB
Time per epoch: 9.1 sec.
Memory usage: Available 7967.4 MB, Allocated 955.1 MB, Max allocated 1643.8 MB

Loading model from results/Natural_Gas/CALF_sl_96_pl_48_id_ori/3/llm.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:2.8599, mae:1.3205
Upscaling data and removing negatives...
test -- mse:8.0483e+08, mae:9717.8, rmsle: 0.45249 smape 23.739

Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='Natural_Gas.csv', features='M', n_features=5, target='OT', freq='d', no_scale=False, seq_len=96, label_len=48, pred_len=48, top_k=5, num_kernels=6, d_model=768, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', dry_run=False, percent=100, model_id='ori', model='OFA', gpt_layers=6, is_gpt=1, patch_size=16, kernel_size=25, pretrain=1, freeze=1, stride=8, max_len=-1, hid_dim=16, tmax=20, n_scale=-1, use_gpu=True, enc_in=5, dec_in=5, c_out=5, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Natural_Gas/OFA_sl_96_pl_48_id_ori/1

Experiment begins at 2024-09-06 03:12:35

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Epoch: 1 | Time: 5.43 s | Train Loss: 1.2969 Vali Loss: 0.9561
Validation loss decreased (inf --> 0.956102).  Saving model ...
Epoch: 2 | Time: 5.18 s | Train Loss: 1.1741 Vali Loss: 0.97328
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 5.16 s | Train Loss: 1.1501 Vali Loss: 1.0788
EarlyStopping counter: 2 out of 3
Epoch: 4 | Time: 5.18 s | Train Loss: 1.1234 Vali Loss: 1.1182
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 03:13:01.
Model parameters: 82368048
Total memory: 7967.4 MB
Allocated memory: 353.4 MB
Max allocated memory: 1243.0 MB
Time per epoch: 6.4 sec.
Memory usage: Available 7967.4 MB, Allocated 353.4 MB, Max allocated 1243.0 MB

Loading model from results/Natural_Gas/OFA_sl_96_pl_48_id_ori/1/llm.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:2.9984, mae:1.3585
Upscaling data and removing negatives...
test -- mse:4.8237e+08, mae:7777, rmsle: 0.40678 smape 23.763


>>>> itr_no: 2, seed: 506 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Natural_Gas/OFA_sl_96_pl_48_id_ori/2

Experiment begins at 2024-09-06 03:13:02

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Epoch: 1 | Time: 5.21 s | Train Loss: 1.3032 Vali Loss: 0.94422
Validation loss decreased (inf --> 0.944217).  Saving model ...
Epoch: 2 | Time: 5.27 s | Train Loss: 1.1874 Vali Loss: 0.99397
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 5.23 s | Train Loss: 1.167 Vali Loss: 0.99961
EarlyStopping counter: 2 out of 3
Epoch: 4 | Time: 5.24 s | Train Loss: 1.1262 Vali Loss: 1.1105
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 03:13:27.
Model parameters: 82368048
Total memory: 7967.4 MB
Allocated memory: 354.2 MB
Max allocated memory: 1245.3 MB
Time per epoch: 6.3 sec.
Memory usage: Available 7967.4 MB, Allocated 354.2 MB, Max allocated 1245.3 MB

Loading model from results/Natural_Gas/OFA_sl_96_pl_48_id_ori/2/llm.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:2.8435, mae:1.3445
Upscaling data and removing negatives...
test -- mse:5.1112e+08, mae:7994, rmsle: 0.40398 smape 24.58


>>>> itr_no: 3, seed: 608 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/Natural_Gas/OFA_sl_96_pl_48_id_ori/3

Experiment begins at 2024-09-06 03:13:29

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Epoch: 1 | Time: 5.22 s | Train Loss: 1.3083 Vali Loss: 0.98024
Validation loss decreased (inf --> 0.980244).  Saving model ...
Epoch: 2 | Time: 5.26 s | Train Loss: 1.1971 Vali Loss: 1.001
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 5.22 s | Train Loss: 1.1557 Vali Loss: 1.0259
EarlyStopping counter: 2 out of 3
Epoch: 4 | Time: 5.22 s | Train Loss: 1.1158 Vali Loss: 1.1623
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 03:13:54.
Model parameters: 82368048
Total memory: 7967.4 MB
Allocated memory: 354.3 MB
Max allocated memory: 1245.3 MB
Time per epoch: 6.3 sec.
Memory usage: Available 7967.4 MB, Allocated 354.3 MB, Max allocated 1245.3 MB

Loading model from results/Natural_Gas/OFA_sl_96_pl_48_id_ori/3/llm.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:2.814, mae:1.3006
Upscaling data and removing negatives...
test -- mse:5.3131e+08, mae:8159.7, rmsle: 0.41849 smape 22.562

Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='Natural_Gas.csv', features='M', n_features=5, target='OT', freq='d', no_scale=False, seq_len=96, label_len=48, pred_len=48, top_k=5, num_kernels=6, d_model=16, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=16, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', dry_run=False, percent=100, model_id='ori', model='TimeLLM', patch_len=16, stride=8, prompt_domain=1, llm_model='GPT2', llm_dim=768, llm_layers=6, use_gpu=True, enc_in=5, dec_in=5, c_out=5, task_name='long_term_forecast', content='Natural gas historical price per day in dollars')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
description: Natural gas historical price per day in dollars
Experiments will be saved in results/Natural_Gas/TimeLLM_sl_96_pl_48_id_ori/1

Experiment begins at 2024-09-06 03:14:02

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Epoch: 1 | Time: 64.5 s | Train Loss: 4.6111 Vali Loss: 2.4847
Validation loss decreased (inf --> 2.484664).  Saving model ...
Epoch: 2 | Time: 62.4 s | Train Loss: 4.0134 Vali Loss: 3.4816
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 62.6 s | Train Loss: 4.0558 Vali Loss: 2.4528
Validation loss decreased (2.484664 --> 2.452837).  Saving model ...
Epoch: 4 | Time: 62.2 s | Train Loss: 4.0629 Vali Loss: 2.2941
Validation loss decreased (2.452837 --> 2.294052).  Saving model ...
Epoch: 5 | Time: 62.3 s | Train Loss: 3.9418 Vali Loss: 2.257
Validation loss decreased (2.294052 --> 2.257048).  Saving model ...
Epoch: 6 | Time: 62.3 s | Train Loss: 4.0036 Vali Loss: 2.8439
EarlyStopping counter: 1 out of 3
Epoch: 7 | Time: 62.4 s | Train Loss: 3.9218 Vali Loss: 2.4012
EarlyStopping counter: 2 out of 3
Epoch: 8 | Time: 62.4 s | Train Loss: 3.7612 Vali Loss: 2.3063
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 03:22:48.
Model parameters: 133434752
Total memory: 7967.4 MB
Allocated memory: 1126.9 MB
Max allocated memory: 6454.7 MB
Time per epoch: 65.8 sec.
Memory usage: Available 7967.4 MB, Allocated 1126.9 MB, Max allocated 6454.7 MB

Loading model from results/Natural_Gas/TimeLLM_sl_96_pl_48_id_ori/1/llm.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:2.8837, mae:1.3322
Upscaling data and removing negatives...
test -- mse:7.3498e+08, mae:9416.5, rmsle: 0.44301 smape 23.553


>>>> itr_no: 2, seed: 506 <<<<<<
Use GPU: cuda:0
description: Natural gas historical price per day in dollars
Experiments will be saved in results/Natural_Gas/TimeLLM_sl_96_pl_48_id_ori/2

Experiment begins at 2024-09-06 03:22:58

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Epoch: 1 | Time: 64.2 s | Train Loss: 4.4976 Vali Loss: 2.3264
Validation loss decreased (inf --> 2.326446).  Saving model ...
Epoch: 2 | Time: 62.2 s | Train Loss: 4.0987 Vali Loss: 1.832
Validation loss decreased (2.326446 --> 1.831976).  Saving model ...
Epoch: 3 | Time: 62.3 s | Train Loss: 4.0747 Vali Loss: 2.7193
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 62.6 s | Train Loss: 4.0268 Vali Loss: 2.179
EarlyStopping counter: 2 out of 3
Epoch: 5 | Time: 62.6 s | Train Loss: 3.9525 Vali Loss: 2.1858
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 03:28:24.
Model parameters: 133434752
Total memory: 7967.4 MB
Allocated memory: 1128.6 MB
Max allocated memory: 6456.9 MB
Time per epoch: 65.3 sec.
Memory usage: Available 7967.4 MB, Allocated 1128.6 MB, Max allocated 6456.9 MB

Loading model from results/Natural_Gas/TimeLLM_sl_96_pl_48_id_ori/2/llm.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:2.9628, mae:1.3821
Upscaling data and removing negatives...
test -- mse:7.9354e+08, mae:9968.8, rmsle: 0.44821 smape 25.258


>>>> itr_no: 3, seed: 608 <<<<<<
Use GPU: cuda:0
description: Natural gas historical price per day in dollars
Experiments will be saved in results/Natural_Gas/TimeLLM_sl_96_pl_48_id_ori/3

Experiment begins at 2024-09-06 03:28:29

>>>>>>> start training :>>>>>>>>>>
train 1880
val 207
Epoch: 1 | Time: 64.6 s | Train Loss: 4.7349 Vali Loss: 2.547
Validation loss decreased (inf --> 2.546971).  Saving model ...
Epoch: 2 | Time: 62.3 s | Train Loss: 4.0436 Vali Loss: 2.3883
Validation loss decreased (2.546971 --> 2.388265).  Saving model ...
Epoch: 3 | Time: 62.3 s | Train Loss: 3.9499 Vali Loss: 2.0246
Validation loss decreased (2.388265 --> 2.024649).  Saving model ...
Epoch: 4 | Time: 62.1 s | Train Loss: 4.0237 Vali Loss: 2.0396
EarlyStopping counter: 1 out of 3
Epoch: 5 | Time: 62.6 s | Train Loss: 4.1642 Vali Loss: 2.5141
EarlyStopping counter: 2 out of 3
Epoch: 6 | Time: 62.6 s | Train Loss: 3.8248 Vali Loss: 2.3817
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 03:35:05.
Model parameters: 133434752
Total memory: 7967.4 MB
Allocated memory: 1128.4 MB
Max allocated memory: 6456.9 MB
Time per epoch: 65.9 sec.
Memory usage: Available 7967.4 MB, Allocated 1128.4 MB, Max allocated 6456.9 MB

Loading model from results/Natural_Gas/TimeLLM_sl_96_pl_48_id_ori/3/llm.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 5) (205, 48, 5)
test scaled -- mse:2.7577, mae:1.3187
Upscaling data and removing negatives...
test -- mse:7.2779e+08, mae:9372, rmsle: 0.44369 smape 24.415

Running for model:DLinear
Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='SPX500.csv', features='M', n_features=4, target='OT', freq='d', no_scale=False, seq_len=96, label_len=48, pred_len=48, top_k=5, num_kernels=6, d_model=64, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, channel_independence=1, decomp_method='moving_avg', use_norm=1, down_sampling_layers=0, down_sampling_window=1, down_sampling_method=None, seg_len=48, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, dry_run=False, percent=100, model='DLinear', use_gpu=True, enc_in=4, dec_in=4, c_out=4, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/SPX500/DLinear_sl_96_pl_48/1

Experiment begins at 2024-09-06 03:35:15

>>>>>>> start training :>>>>>>>>>>
train 1879
val 207
Epoch: 1 | Time: 1.77 s | Train Loss: 3.2494 Vali Loss: 2.6573
Validation loss decreased (inf --> 2.657262).  Saving model ...
Epoch: 2 | Time: 1.65 s | Train Loss: 2.6594 Vali Loss: 2.5226
Validation loss decreased (2.657262 --> 2.522590).  Saving model ...
Epoch: 3 | Time: 1.69 s | Train Loss: 2.5127 Vali Loss: 2.2303
Validation loss decreased (2.522590 --> 2.230284).  Saving model ...
Epoch: 4 | Time: 1.62 s | Train Loss: 2.4256 Vali Loss: 2.1109
Validation loss decreased (2.230284 --> 2.110923).  Saving model ...
Epoch: 5 | Time: 1.62 s | Train Loss: 2.3837 Vali Loss: 1.9771
Validation loss decreased (2.110923 --> 1.977112).  Saving model ...
Epoch: 6 | Time: 1.62 s | Train Loss: 2.3596 Vali Loss: 1.9904
EarlyStopping counter: 1 out of 3
Epoch: 7 | Time: 1.63 s | Train Loss: 2.3254 Vali Loss: 1.8189
Validation loss decreased (1.977112 --> 1.818927).  Saving model ...
Epoch: 8 | Time: 1.62 s | Train Loss: 2.3004 Vali Loss: 1.8345
EarlyStopping counter: 1 out of 3
Epoch: 9 | Time: 1.62 s | Train Loss: 2.2877 Vali Loss: 1.8336
EarlyStopping counter: 2 out of 3
Epoch: 10 | Time: 1.62 s | Train Loss: 2.273 Vali Loss: 1.8364
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 03:35:34.
Model parameters: 9312
Total memory: 7967.4 MB
Allocated memory: 16.6 MB
Max allocated memory: 17.0 MB
Time per epoch: 1.8 sec.
Memory usage: Available 7967.4 MB, Allocated 16.6 MB, Max allocated 17.0 MB

Loading model from results/SPX500/DLinear_sl_96_pl_48/1/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 4) (205, 48, 4)
test scaled -- mse:2.3158, mae:1.1643
Upscaling data and removing negatives...
test -- mse:41057, mae:167.99, rmsle: 0.042307 smape 3.4673


>>>> itr_no: 2, seed: 506 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/SPX500/DLinear_sl_96_pl_48/2

Experiment begins at 2024-09-06 03:35:34

>>>>>>> start training :>>>>>>>>>>
train 1879
val 207
Epoch: 1 | Time: 1.6 s | Train Loss: 3.2876 Vali Loss: 2.669
Validation loss decreased (inf --> 2.668957).  Saving model ...
Epoch: 2 | Time: 1.61 s | Train Loss: 2.6736 Vali Loss: 2.4545
Validation loss decreased (2.668957 --> 2.454493).  Saving model ...
Epoch: 3 | Time: 1.62 s | Train Loss: 2.52 Vali Loss: 2.34
Validation loss decreased (2.454493 --> 2.340047).  Saving model ...
Epoch: 4 | Time: 1.68 s | Train Loss: 2.4372 Vali Loss: 2.1726
Validation loss decreased (2.340047 --> 2.172630).  Saving model ...
Epoch: 5 | Time: 1.71 s | Train Loss: 2.3912 Vali Loss: 2.0481
Validation loss decreased (2.172630 --> 2.048081).  Saving model ...
Epoch: 6 | Time: 1.62 s | Train Loss: 2.3446 Vali Loss: 2.0327
Validation loss decreased (2.048081 --> 2.032702).  Saving model ...
Epoch: 7 | Time: 1.62 s | Train Loss: 2.3274 Vali Loss: 1.964
Validation loss decreased (2.032702 --> 1.963954).  Saving model ...
Epoch: 8 | Time: 1.63 s | Train Loss: 2.304 Vali Loss: 1.8942
Validation loss decreased (1.963954 --> 1.894189).  Saving model ...
Epoch: 9 | Time: 1.62 s | Train Loss: 2.2904 Vali Loss: 1.8987
EarlyStopping counter: 1 out of 3
Epoch: 10 | Time: 1.62 s | Train Loss: 2.2785 Vali Loss: 1.7924
Validation loss decreased (1.894189 --> 1.792406).  Saving model ...

Training completed at 2024-09-06 03:35:52.
Model parameters: 9312
Total memory: 7967.4 MB
Allocated memory: 16.6 MB
Max allocated memory: 17.0 MB
Time per epoch: 1.8 sec.
Memory usage: Available 7967.4 MB, Allocated 16.6 MB, Max allocated 17.0 MB

Loading model from results/SPX500/DLinear_sl_96_pl_48/2/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 4) (205, 48, 4)
test scaled -- mse:2.2143, mae:1.1424
Upscaling data and removing negatives...
test -- mse:40275, mae:165.81, rmsle: 0.041803 smape 3.42


>>>> itr_no: 3, seed: 608 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/SPX500/DLinear_sl_96_pl_48/3

Experiment begins at 2024-09-06 03:35:52

>>>>>>> start training :>>>>>>>>>>
train 1879
val 207
Epoch: 1 | Time: 1.61 s | Train Loss: 3.2617 Vali Loss: 2.6919
Validation loss decreased (inf --> 2.691850).  Saving model ...
Epoch: 2 | Time: 1.63 s | Train Loss: 2.6719 Vali Loss: 2.5243
Validation loss decreased (2.691850 --> 2.524258).  Saving model ...
Epoch: 3 | Time: 1.62 s | Train Loss: 2.5187 Vali Loss: 2.3077
Validation loss decreased (2.524258 --> 2.307683).  Saving model ...
Epoch: 4 | Time: 1.63 s | Train Loss: 2.4334 Vali Loss: 2.2132
Validation loss decreased (2.307683 --> 2.213214).  Saving model ...
Epoch: 5 | Time: 1.62 s | Train Loss: 2.3785 Vali Loss: 2.0736
Validation loss decreased (2.213214 --> 2.073562).  Saving model ...
Epoch: 6 | Time: 1.62 s | Train Loss: 2.3445 Vali Loss: 1.9686
Validation loss decreased (2.073562 --> 1.968578).  Saving model ...
Epoch: 7 | Time: 1.62 s | Train Loss: 2.3217 Vali Loss: 1.9148
Validation loss decreased (1.968578 --> 1.914825).  Saving model ...
Epoch: 8 | Time: 1.62 s | Train Loss: 2.302 Vali Loss: 1.9067
Validation loss decreased (1.914825 --> 1.906731).  Saving model ...
Epoch: 9 | Time: 1.62 s | Train Loss: 2.2928 Vali Loss: 1.882
Validation loss decreased (1.906731 --> 1.881971).  Saving model ...
Epoch: 10 | Time: 1.63 s | Train Loss: 2.2809 Vali Loss: 1.8381
Validation loss decreased (1.881971 --> 1.838100).  Saving model ...

Training completed at 2024-09-06 03:36:10.
Model parameters: 9312
Total memory: 7967.4 MB
Allocated memory: 16.6 MB
Max allocated memory: 17.0 MB
Time per epoch: 1.7 sec.
Memory usage: Available 7967.4 MB, Allocated 16.6 MB, Max allocated 17.0 MB

Loading model from results/SPX500/DLinear_sl_96_pl_48/3/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 4) (205, 48, 4)
test scaled -- mse:2.1902, mae:1.1429
Upscaling data and removing negatives...
test -- mse:40253, mae:166.33, rmsle: 0.041667 smape 3.4263

Running for model:PatchTST
Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='SPX500.csv', features='M', n_features=4, target='OT', freq='d', no_scale=False, seq_len=96, label_len=48, pred_len=48, top_k=5, num_kernels=6, d_model=64, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, channel_independence=1, decomp_method='moving_avg', use_norm=1, down_sampling_layers=0, down_sampling_window=1, down_sampling_method=None, seg_len=48, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, dry_run=False, percent=100, model='PatchTST', use_gpu=True, enc_in=4, dec_in=4, c_out=4, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/SPX500/PatchTST_sl_96_pl_48/1

Experiment begins at 2024-09-06 03:36:17

>>>>>>> start training :>>>>>>>>>>
train 1879
val 207
Epoch: 1 | Time: 2.44 s | Train Loss: 2.8065 Vali Loss: 1.7365
Validation loss decreased (inf --> 1.736459).  Saving model ...
Epoch: 2 | Time: 2.17 s | Train Loss: 2.4768 Vali Loss: 1.3373
Validation loss decreased (1.736459 --> 1.337302).  Saving model ...
Epoch: 3 | Time: 2.18 s | Train Loss: 2.3608 Vali Loss: 1.4989
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 2.16 s | Train Loss: 2.192 Vali Loss: 1.8794
EarlyStopping counter: 2 out of 3
Epoch: 5 | Time: 2.19 s | Train Loss: 2.0324 Vali Loss: 1.4313
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 03:36:29.
Model parameters: 105008
Total memory: 7967.4 MB
Allocated memory: 19.3 MB
Max allocated memory: 163.8 MB
Time per epoch: 2.5 sec.
Memory usage: Available 7967.4 MB, Allocated 19.3 MB, Max allocated 163.8 MB

Loading model from results/SPX500/PatchTST_sl_96_pl_48/1/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 4) (205, 48, 4)
test scaled -- mse:2.1103, mae:1.0684
Upscaling data and removing negatives...
test -- mse:35852, mae:153.32, rmsle: 0.040056 smape 3.1826


>>>> itr_no: 2, seed: 506 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/SPX500/PatchTST_sl_96_pl_48/2

Experiment begins at 2024-09-06 03:36:30

>>>>>>> start training :>>>>>>>>>>
train 1879
val 207
Epoch: 1 | Time: 2.08 s | Train Loss: 2.825 Vali Loss: 2.0851
Validation loss decreased (inf --> 2.085108).  Saving model ...
Epoch: 2 | Time: 2.18 s | Train Loss: 2.5306 Vali Loss: 1.8404
Validation loss decreased (2.085108 --> 1.840361).  Saving model ...
Epoch: 3 | Time: 2.17 s | Train Loss: 2.3995 Vali Loss: 1.8628
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 2.15 s | Train Loss: 2.2629 Vali Loss: 1.5843
Validation loss decreased (1.840361 --> 1.584312).  Saving model ...
Epoch: 5 | Time: 2.19 s | Train Loss: 2.0978 Vali Loss: 1.5391
Validation loss decreased (1.584312 --> 1.539125).  Saving model ...
Epoch: 6 | Time: 2.12 s | Train Loss: 2.0061 Vali Loss: 1.9707
EarlyStopping counter: 1 out of 3
Epoch: 7 | Time: 2.17 s | Train Loss: 1.9371 Vali Loss: 2.1158
EarlyStopping counter: 2 out of 3
Epoch: 8 | Time: 2.18 s | Train Loss: 1.7813 Vali Loss: 1.8367
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 03:36:48.
Model parameters: 105008
Total memory: 7967.4 MB
Allocated memory: 19.3 MB
Max allocated memory: 163.8 MB
Time per epoch: 2.3 sec.
Memory usage: Available 7967.4 MB, Allocated 19.3 MB, Max allocated 163.8 MB

Loading model from results/SPX500/PatchTST_sl_96_pl_48/2/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 4) (205, 48, 4)
test scaled -- mse:2.1509, mae:1.0705
Upscaling data and removing negatives...
test -- mse:38698, mae:155.28, rmsle: 0.041628 smape 3.2301


>>>> itr_no: 3, seed: 608 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/SPX500/PatchTST_sl_96_pl_48/3

Experiment begins at 2024-09-06 03:36:49

>>>>>>> start training :>>>>>>>>>>
train 1879
val 207
Epoch: 1 | Time: 2.13 s | Train Loss: 2.8432 Vali Loss: 2.1483
Validation loss decreased (inf --> 2.148268).  Saving model ...
Epoch: 2 | Time: 2.17 s | Train Loss: 2.4884 Vali Loss: 1.7513
Validation loss decreased (2.148268 --> 1.751261).  Saving model ...
Epoch: 3 | Time: 2.18 s | Train Loss: 2.4103 Vali Loss: 1.4627
Validation loss decreased (1.751261 --> 1.462739).  Saving model ...
Epoch: 4 | Time: 2.11 s | Train Loss: 2.2629 Vali Loss: 1.6229
EarlyStopping counter: 1 out of 3
Epoch: 5 | Time: 2.09 s | Train Loss: 2.1326 Vali Loss: 1.665
EarlyStopping counter: 2 out of 3
Epoch: 6 | Time: 2.09 s | Train Loss: 1.9621 Vali Loss: 1.6942
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 03:37:02.
Model parameters: 105008
Total memory: 7967.4 MB
Allocated memory: 19.3 MB
Max allocated memory: 163.8 MB
Time per epoch: 2.3 sec.
Memory usage: Available 7967.4 MB, Allocated 19.3 MB, Max allocated 163.8 MB

Loading model from results/SPX500/PatchTST_sl_96_pl_48/3/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 4) (205, 48, 4)
test scaled -- mse:1.8994, mae:1.0885
Upscaling data and removing negatives...
test -- mse:40048, mae:165.21, rmsle: 0.041232 smape 3.391

Running for model:TimesNet
Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='SPX500.csv', features='M', n_features=4, target='OT', freq='d', no_scale=False, seq_len=96, label_len=48, pred_len=48, top_k=5, num_kernels=6, d_model=64, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, channel_independence=1, decomp_method='moving_avg', use_norm=1, down_sampling_layers=0, down_sampling_window=1, down_sampling_method=None, seg_len=48, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, dry_run=False, percent=100, model='TimesNet', use_gpu=True, enc_in=4, dec_in=4, c_out=4, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/SPX500/TimesNet_sl_96_pl_48/1

Experiment begins at 2024-09-06 03:37:08

>>>>>>> start training :>>>>>>>>>>
train 1879
val 207
Epoch: 1 | Time: 33.2 s | Train Loss: 2.6768 Vali Loss: 2.3286
Validation loss decreased (inf --> 2.328612).  Saving model ...
Epoch: 2 | Time: 31.6 s | Train Loss: 2.2399 Vali Loss: 2.1209
Validation loss decreased (2.328612 --> 2.120938).  Saving model ...
Epoch: 3 | Time: 30.4 s | Train Loss: 1.977 Vali Loss: 2.3857
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 30.3 s | Train Loss: 1.7406 Vali Loss: 2.704
EarlyStopping counter: 2 out of 3
Epoch: 5 | Time: 30.6 s | Train Loss: 1.5098 Vali Loss: 2.5922
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 03:39:46.
Model parameters: 9389268
Total memory: 7967.4 MB
Allocated memory: 166.9 MB
Max allocated memory: 1781.1 MB
Time per epoch: 31.6 sec.
Memory usage: Available 7967.4 MB, Allocated 166.9 MB, Max allocated 1781.1 MB

Loading model from results/SPX500/TimesNet_sl_96_pl_48/1/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 4) (205, 48, 4)
test scaled -- mse:2.5466, mae:1.1719
Upscaling data and removing negatives...
test -- mse:44007, mae:167.81, rmsle: 0.044731 smape 3.5024


>>>> itr_no: 2, seed: 506 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/SPX500/TimesNet_sl_96_pl_48/2

Experiment begins at 2024-09-06 03:39:48

>>>>>>> start training :>>>>>>>>>>
train 1879
val 207
Epoch: 1 | Time: 36.7 s | Train Loss: 2.8065 Vali Loss: 2.0331
Validation loss decreased (inf --> 2.033149).  Saving model ...
Epoch: 2 | Time: 29.7 s | Train Loss: 2.2457 Vali Loss: 1.8051
Validation loss decreased (2.033149 --> 1.805085).  Saving model ...
Epoch: 3 | Time: 27.4 s | Train Loss: 2.0816 Vali Loss: 2.1003
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 24.9 s | Train Loss: 1.8662 Vali Loss: 2.2551
EarlyStopping counter: 2 out of 3
Epoch: 5 | Time: 24.9 s | Train Loss: 1.5752 Vali Loss: 2.2354
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 03:42:13.
Model parameters: 9389268
Total memory: 7967.4 MB
Allocated memory: 169.9 MB
Max allocated memory: 1784.2 MB
Time per epoch: 29.0 sec.
Memory usage: Available 7967.4 MB, Allocated 169.9 MB, Max allocated 1784.2 MB

Loading model from results/SPX500/TimesNet_sl_96_pl_48/2/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 4) (205, 48, 4)
test scaled -- mse:2.187, mae:1.124
Upscaling data and removing negatives...
test -- mse:39620, mae:162.85, rmsle: 0.041765 smape 3.3685


>>>> itr_no: 3, seed: 608 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/SPX500/TimesNet_sl_96_pl_48/3

Experiment begins at 2024-09-06 03:42:16

>>>>>>> start training :>>>>>>>>>>
train 1879
val 207
Epoch: 1 | Time: 22.7 s | Train Loss: 2.846 Vali Loss: 2.5865
Validation loss decreased (inf --> 2.586472).  Saving model ...
Epoch: 2 | Time: 24.3 s | Train Loss: 2.299 Vali Loss: 2.1956
Validation loss decreased (2.586472 --> 2.195566).  Saving model ...
Epoch: 3 | Time: 24.5 s | Train Loss: 2.068 Vali Loss: 2.4357
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 23.6 s | Train Loss: 1.952 Vali Loss: 2.4543
EarlyStopping counter: 2 out of 3
Epoch: 5 | Time: 23.7 s | Train Loss: 1.7043 Vali Loss: 2.4612
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 03:44:16.
Model parameters: 9389268
Total memory: 7967.4 MB
Allocated memory: 168.0 MB
Max allocated memory: 1784.2 MB
Time per epoch: 24.0 sec.
Memory usage: Available 7967.4 MB, Allocated 168.0 MB, Max allocated 1784.2 MB

Loading model from results/SPX500/TimesNet_sl_96_pl_48/3/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 4) (205, 48, 4)
test scaled -- mse:2.1722, mae:1.0911
Upscaling data and removing negatives...
test -- mse:38656, mae:157.03, rmsle: 0.041685 smape 3.2624

Running for model:iTransformer
Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='SPX500.csv', features='M', n_features=4, target='OT', freq='d', no_scale=False, seq_len=96, label_len=48, pred_len=48, top_k=5, num_kernels=6, d_model=64, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, channel_independence=1, decomp_method='moving_avg', use_norm=1, down_sampling_layers=0, down_sampling_window=1, down_sampling_method=None, seg_len=48, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, dry_run=False, percent=100, model='iTransformer', use_gpu=True, enc_in=4, dec_in=4, c_out=4, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/SPX500/iTransformer_sl_96_pl_48/1

Experiment begins at 2024-09-06 03:44:24

>>>>>>> start training :>>>>>>>>>>
train 1879
val 207
Epoch: 1 | Time: 2.37 s | Train Loss: 2.9258 Vali Loss: 2.16
Validation loss decreased (inf --> 2.160000).  Saving model ...
Epoch: 2 | Time: 2.09 s | Train Loss: 2.2587 Vali Loss: 1.7758
Validation loss decreased (2.160000 --> 1.775828).  Saving model ...
Epoch: 3 | Time: 2.1 s | Train Loss: 2.0768 Vali Loss: 1.7119
Validation loss decreased (1.775828 --> 1.711931).  Saving model ...
Epoch: 4 | Time: 2.08 s | Train Loss: 1.9302 Vali Loss: 1.7307
EarlyStopping counter: 1 out of 3
Epoch: 5 | Time: 2.1 s | Train Loss: 1.7466 Vali Loss: 1.7505
EarlyStopping counter: 2 out of 3
Epoch: 6 | Time: 2.11 s | Train Loss: 1.531 Vali Loss: 1.9161
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 03:44:39.
Model parameters: 76400
Total memory: 7967.4 MB
Allocated memory: 17.6 MB
Max allocated memory: 147.2 MB
Time per epoch: 2.4 sec.
Memory usage: Available 7967.4 MB, Allocated 17.6 MB, Max allocated 147.2 MB

Loading model from results/SPX500/iTransformer_sl_96_pl_48/1/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 4) (205, 48, 4)
test scaled -- mse:2.6683, mae:1.2886
Upscaling data and removing negatives...
test -- mse:67350, mae:205.07, rmsle: 0.054276 smape 4.2501


>>>> itr_no: 2, seed: 506 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/SPX500/iTransformer_sl_96_pl_48/2

Experiment begins at 2024-09-06 03:44:39

>>>>>>> start training :>>>>>>>>>>
train 1879
val 207
Epoch: 1 | Time: 2.05 s | Train Loss: 2.8607 Vali Loss: 2.2336
Validation loss decreased (inf --> 2.233622).  Saving model ...
Epoch: 2 | Time: 2.08 s | Train Loss: 2.1609 Vali Loss: 1.5147
Validation loss decreased (2.233622 --> 1.514714).  Saving model ...
Epoch: 3 | Time: 2.08 s | Train Loss: 1.9551 Vali Loss: 1.8167
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 2.07 s | Train Loss: 1.8024 Vali Loss: 1.8532
EarlyStopping counter: 2 out of 3
Epoch: 5 | Time: 2.08 s | Train Loss: 1.6036 Vali Loss: 1.8856
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 03:44:50.
Model parameters: 76400
Total memory: 7967.4 MB
Allocated memory: 17.6 MB
Max allocated memory: 147.2 MB
Time per epoch: 2.2 sec.
Memory usage: Available 7967.4 MB, Allocated 17.6 MB, Max allocated 147.2 MB

Loading model from results/SPX500/iTransformer_sl_96_pl_48/2/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 4) (205, 48, 4)
test scaled -- mse:2.5014, mae:1.2357
Upscaling data and removing negatives...
test -- mse:53809, mae:187.66, rmsle: 0.048742 smape 3.8948


>>>> itr_no: 3, seed: 608 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/SPX500/iTransformer_sl_96_pl_48/3

Experiment begins at 2024-09-06 03:44:50

>>>>>>> start training :>>>>>>>>>>
train 1879
val 207
Epoch: 1 | Time: 2.05 s | Train Loss: 2.9025 Vali Loss: 2.2263
Validation loss decreased (inf --> 2.226300).  Saving model ...
Epoch: 2 | Time: 2.07 s | Train Loss: 2.2176 Vali Loss: 1.9793
Validation loss decreased (2.226300 --> 1.979299).  Saving model ...
Epoch: 3 | Time: 2.06 s | Train Loss: 2.0582 Vali Loss: 1.7277
Validation loss decreased (1.979299 --> 1.727693).  Saving model ...
Epoch: 4 | Time: 2.09 s | Train Loss: 1.9186 Vali Loss: 1.9912
EarlyStopping counter: 1 out of 3
Epoch: 5 | Time: 2.07 s | Train Loss: 1.7708 Vali Loss: 2.2377
EarlyStopping counter: 2 out of 3
Epoch: 6 | Time: 2.07 s | Train Loss: 1.6192 Vali Loss: 1.9646
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 03:45:04.
Model parameters: 76400
Total memory: 7967.4 MB
Allocated memory: 17.6 MB
Max allocated memory: 147.2 MB
Time per epoch: 2.2 sec.
Memory usage: Available 7967.4 MB, Allocated 17.6 MB, Max allocated 147.2 MB

Loading model from results/SPX500/iTransformer_sl_96_pl_48/3/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 4) (205, 48, 4)
test scaled -- mse:2.6868, mae:1.2574
Upscaling data and removing negatives...
test -- mse:59727, mae:194.67, rmsle: 0.051221 smape 4.0288

Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='SPX500.csv', features='M', n_features=4, target='OT', freq='d', no_scale=False, seq_len=96, label_len=96, pred_len=48, top_k=5, num_kernels=6, d_model=64, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, channel_independence=1, decomp_method='moving_avg', use_norm=1, down_sampling_layers=0, down_sampling_window=1, down_sampling_method=None, seg_len=48, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, dry_run=False, percent=100, model='MICN', use_gpu=True, enc_in=4, dec_in=4, c_out=4, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/SPX500/MICN_sl_96_pl_48/1

Experiment begins at 2024-09-06 03:45:09

>>>>>>> start training :>>>>>>>>>>
train 1879
val 207
Epoch: 1 | Time: 2.58 s | Train Loss: 2.9963 Vali Loss: 2.254
Validation loss decreased (inf --> 2.254009).  Saving model ...
Epoch: 2 | Time: 2.26 s | Train Loss: 2.4516 Vali Loss: 1.9589
Validation loss decreased (2.254009 --> 1.958905).  Saving model ...
Epoch: 3 | Time: 2.23 s | Train Loss: 2.2933 Vali Loss: 1.7933
Validation loss decreased (1.958905 --> 1.793298).  Saving model ...
Epoch: 4 | Time: 2.24 s | Train Loss: 2.1757 Vali Loss: 1.7593
Validation loss decreased (1.793298 --> 1.759278).  Saving model ...
Epoch: 5 | Time: 2.26 s | Train Loss: 1.9791 Vali Loss: 1.7202
Validation loss decreased (1.759278 --> 1.720188).  Saving model ...
Epoch: 6 | Time: 2.24 s | Train Loss: 1.8181 Vali Loss: 1.8242
EarlyStopping counter: 1 out of 3
Epoch: 7 | Time: 2.23 s | Train Loss: 1.5993 Vali Loss: 1.8442
EarlyStopping counter: 2 out of 3
Epoch: 8 | Time: 2.23 s | Train Loss: 1.3293 Vali Loss: 1.9082
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 03:45:29.
Model parameters: 371572
Total memory: 7967.4 MB
Allocated memory: 23.4 MB
Max allocated memory: 179.8 MB
Time per epoch: 2.5 sec.
Memory usage: Available 7967.4 MB, Allocated 23.4 MB, Max allocated 179.8 MB

Loading model from results/SPX500/MICN_sl_96_pl_48/1/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 4) (205, 48, 4)
test scaled -- mse:1.5568, mae:0.98533
Upscaling data and removing negatives...
test -- mse:32964, mae:149.14, rmsle: 0.037411 smape 3.0461


>>>> itr_no: 2, seed: 506 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/SPX500/MICN_sl_96_pl_48/2

Experiment begins at 2024-09-06 03:45:30

>>>>>>> start training :>>>>>>>>>>
train 1879
val 207
Epoch: 1 | Time: 2.19 s | Train Loss: 2.9277 Vali Loss: 1.9552
Validation loss decreased (inf --> 1.955162).  Saving model ...
Epoch: 2 | Time: 2.23 s | Train Loss: 2.4573 Vali Loss: 2.0353
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 2.23 s | Train Loss: 2.3108 Vali Loss: 1.7463
Validation loss decreased (1.955162 --> 1.746346).  Saving model ...
Epoch: 4 | Time: 2.23 s | Train Loss: 2.1996 Vali Loss: 2.0505
EarlyStopping counter: 1 out of 3
Epoch: 5 | Time: 2.29 s | Train Loss: 2.0804 Vali Loss: 1.6628
Validation loss decreased (1.746346 --> 1.662775).  Saving model ...
Epoch: 6 | Time: 2.24 s | Train Loss: 1.8718 Vali Loss: 1.8237
EarlyStopping counter: 1 out of 3
Epoch: 7 | Time: 2.22 s | Train Loss: 1.6664 Vali Loss: 1.906
EarlyStopping counter: 2 out of 3
Epoch: 8 | Time: 2.22 s | Train Loss: 1.3394 Vali Loss: 1.8439
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 03:45:49.
Model parameters: 371572
Total memory: 7967.4 MB
Allocated memory: 23.4 MB
Max allocated memory: 179.8 MB
Time per epoch: 2.4 sec.
Memory usage: Available 7967.4 MB, Allocated 23.4 MB, Max allocated 179.8 MB

Loading model from results/SPX500/MICN_sl_96_pl_48/2/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 4) (205, 48, 4)
test scaled -- mse:1.6539, mae:1.0069
Upscaling data and removing negatives...
test -- mse:33728, mae:150.84, rmsle: 0.037955 smape 3.088


>>>> itr_no: 3, seed: 608 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/SPX500/MICN_sl_96_pl_48/3

Experiment begins at 2024-09-06 03:45:49

>>>>>>> start training :>>>>>>>>>>
train 1879
val 207
Epoch: 1 | Time: 2.19 s | Train Loss: 2.9821 Vali Loss: 2.1845
Validation loss decreased (inf --> 2.184499).  Saving model ...
Epoch: 2 | Time: 2.23 s | Train Loss: 2.4483 Vali Loss: 2.028
Validation loss decreased (2.184499 --> 2.028001).  Saving model ...
Epoch: 3 | Time: 2.21 s | Train Loss: 2.314 Vali Loss: 1.7768
Validation loss decreased (2.028001 --> 1.776782).  Saving model ...
Epoch: 4 | Time: 2.22 s | Train Loss: 2.2152 Vali Loss: 1.7627
Validation loss decreased (1.776782 --> 1.762670).  Saving model ...
Epoch: 5 | Time: 2.21 s | Train Loss: 2.0982 Vali Loss: 1.7715
EarlyStopping counter: 1 out of 3
Epoch: 6 | Time: 2.22 s | Train Loss: 1.9198 Vali Loss: 1.7892
EarlyStopping counter: 2 out of 3
Epoch: 7 | Time: 2.21 s | Train Loss: 1.6853 Vali Loss: 1.7141
Validation loss decreased (1.762670 --> 1.714092).  Saving model ...
Epoch: 8 | Time: 2.22 s | Train Loss: 1.549 Vali Loss: 1.7402
EarlyStopping counter: 1 out of 3
Epoch: 9 | Time: 2.22 s | Train Loss: 1.4855 Vali Loss: 1.7879
EarlyStopping counter: 2 out of 3
Epoch: 10 | Time: 2.21 s | Train Loss: 1.4381 Vali Loss: 1.7853
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 03:46:13.
Model parameters: 371572
Total memory: 7967.4 MB
Allocated memory: 23.4 MB
Max allocated memory: 179.8 MB
Time per epoch: 2.4 sec.
Memory usage: Available 7967.4 MB, Allocated 23.4 MB, Max allocated 179.8 MB

Loading model from results/SPX500/MICN_sl_96_pl_48/3/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 4) (205, 48, 4)
test scaled -- mse:1.8718, mae:1.0835
Upscaling data and removing negatives...
test -- mse:41753, mae:166.11, rmsle: 0.041671 smape 3.3884

Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='SPX500.csv', features='M', n_features=4, target='OT', freq='d', no_scale=False, seq_len=96, label_len=0, pred_len=48, top_k=5, num_kernels=6, d_model=16, n_heads=4, e_layers=3, d_layers=1, d_ff=32, moving_avg=3, factor=3, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, channel_independence=1, decomp_method='moving_avg', use_norm=1, down_sampling_layers=3, down_sampling_window=2, down_sampling_method='avg', seg_len=48, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, dry_run=False, percent=100, model='TimeMixer', use_gpu=True, enc_in=4, dec_in=4, c_out=4, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/SPX500/TimeMixer_sl_96_pl_48/1

Experiment begins at 2024-09-06 03:46:20

>>>>>>> start training :>>>>>>>>>>
train 1879
val 207
Epoch: 1 | Time: 4.11 s | Train Loss: 3.0549 Vali Loss: 2.2865
Validation loss decreased (inf --> 2.286466).  Saving model ...
Epoch: 2 | Time: 3.84 s | Train Loss: 2.2855 Vali Loss: 1.8573
Validation loss decreased (2.286466 --> 1.857291).  Saving model ...
Epoch: 3 | Time: 3.81 s | Train Loss: 2.0395 Vali Loss: 1.7547
Validation loss decreased (1.857291 --> 1.754748).  Saving model ...
Epoch: 4 | Time: 3.8 s | Train Loss: 1.8518 Vali Loss: 2.0543
EarlyStopping counter: 1 out of 3
Epoch: 5 | Time: 3.8 s | Train Loss: 1.7071 Vali Loss: 2.3134
EarlyStopping counter: 2 out of 3
Epoch: 6 | Time: 3.8 s | Train Loss: 1.5268 Vali Loss: 2.3432
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 03:46:44.
Model parameters: 95449
Total memory: 7967.4 MB
Allocated memory: 18.3 MB
Max allocated memory: 69.5 MB
Time per epoch: 4.1 sec.
Memory usage: Available 7967.4 MB, Allocated 18.3 MB, Max allocated 69.5 MB

Loading model from results/SPX500/TimeMixer_sl_96_pl_48/1/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 4) (205, 48, 4)
test scaled -- mse:1.4624, mae:0.89939
Upscaling data and removing negatives...
test -- mse:27660, mae:132.59, rmsle: 0.03498 smape 2.7388


>>>> itr_no: 2, seed: 506 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/SPX500/TimeMixer_sl_96_pl_48/2

Experiment begins at 2024-09-06 03:46:45

>>>>>>> start training :>>>>>>>>>>
train 1879
val 207
Epoch: 1 | Time: 3.79 s | Train Loss: 3.2345 Vali Loss: 2.3598
Validation loss decreased (inf --> 2.359803).  Saving model ...
Epoch: 2 | Time: 3.82 s | Train Loss: 2.3918 Vali Loss: 1.6312
Validation loss decreased (2.359803 --> 1.631217).  Saving model ...
Epoch: 3 | Time: 3.81 s | Train Loss: 2.1017 Vali Loss: 1.8189
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 3.82 s | Train Loss: 1.9671 Vali Loss: 1.74
EarlyStopping counter: 2 out of 3
Epoch: 5 | Time: 3.82 s | Train Loss: 1.8061 Vali Loss: 2.0963
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 03:47:05.
Model parameters: 95449
Total memory: 7967.4 MB
Allocated memory: 18.3 MB
Max allocated memory: 69.5 MB
Time per epoch: 3.9 sec.
Memory usage: Available 7967.4 MB, Allocated 18.3 MB, Max allocated 69.5 MB

Loading model from results/SPX500/TimeMixer_sl_96_pl_48/2/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 4) (205, 48, 4)
test scaled -- mse:1.6585, mae:0.98046
Upscaling data and removing negatives...
test -- mse:31003, mae:143.68, rmsle: 0.036991 smape 2.9698


>>>> itr_no: 3, seed: 608 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/SPX500/TimeMixer_sl_96_pl_48/3

Experiment begins at 2024-09-06 03:47:05

>>>>>>> start training :>>>>>>>>>>
train 1879
val 207
Epoch: 1 | Time: 3.79 s | Train Loss: 3.7107 Vali Loss: 2.3451
Validation loss decreased (inf --> 2.345082).  Saving model ...
Epoch: 2 | Time: 3.81 s | Train Loss: 2.3979 Vali Loss: 1.8081
Validation loss decreased (2.345082 --> 1.808138).  Saving model ...
Epoch: 3 | Time: 3.81 s | Train Loss: 2.1885 Vali Loss: 1.5479
Validation loss decreased (1.808138 --> 1.547880).  Saving model ...
Epoch: 4 | Time: 3.82 s | Train Loss: 2.0876 Vali Loss: 1.4501
Validation loss decreased (1.547880 --> 1.450056).  Saving model ...
Epoch: 5 | Time: 3.82 s | Train Loss: 1.955 Vali Loss: 1.6757
EarlyStopping counter: 1 out of 3
Epoch: 6 | Time: 3.82 s | Train Loss: 1.8637 Vali Loss: 1.8929
EarlyStopping counter: 2 out of 3
Epoch: 7 | Time: 3.8 s | Train Loss: 1.7277 Vali Loss: 1.7917
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 03:47:33.
Model parameters: 95449
Total memory: 7967.4 MB
Allocated memory: 18.3 MB
Max allocated memory: 69.5 MB
Time per epoch: 3.9 sec.
Memory usage: Available 7967.4 MB, Allocated 18.3 MB, Max allocated 69.5 MB

Loading model from results/SPX500/TimeMixer_sl_96_pl_48/3/checkpoint.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 4) (205, 48, 4)
test scaled -- mse:1.4073, mae:0.9177
Upscaling data and removing negatives...
test -- mse:29039, mae:138.69, rmsle: 0.035493 smape 2.8532

Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='SPX500.csv', features='M', n_features=4, target='OT', freq='d', no_scale=False, seq_len=96, label_len=48, pred_len=48, top_k=5, num_kernels=6, d_model=768, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', dry_run=False, percent=100, model_id='ori', model='CALF', task_loss='l1', distill_loss='l1', logits_loss='l1', tmax=20, r=8, lora_alpha=32, lora_dropout=0.1, word_embedding_path='./utils/wte_pca_500.pt', task_w=1.0, feature_w=0.01, logits_w=1.0, gpt_layers=6, log_fine_name='CALF_result.txt', noise_scale=-100, bootstrap_eval=0, use_gpu=True, enc_in=4, dec_in=4, c_out=4, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
model_id  ori
Experiments will be saved in results/SPX500/CALF_sl_96_pl_48_id_ori/1

Experiment begins at 2024-09-06 03:47:40

>>>>>>> start training :>>>>>>>>>>
train 1879
val 207
Loss function weights: 1.0 1.0 0.01
Orig-- ori
Epoch: 1 | Time: 4.68 s | Train Loss: 2.1491 Vali Loss: 1.9995
Validation loss decreased (inf --> 1.999480).  Saving model ...
Epoch: 2 | Time: 4.47 s | Train Loss: 1.8462 Vali Loss: 1.5675
Validation loss decreased (1.999480 --> 1.567483).  Saving model ...
Epoch: 3 | Time: 4.46 s | Train Loss: 2.0017 Vali Loss: 1.6317
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 4.61 s | Train Loss: 2.2015 Vali Loss: 1.9228
EarlyStopping counter: 2 out of 3
Epoch: 5 | Time: 4.54 s | Train Loss: 2.8139 Vali Loss: 2.1546
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 03:48:19.
Model parameters: 180070448
Total memory: 7967.4 MB
Allocated memory: 949.0 MB
Max allocated memory: 1251.9 MB
Time per epoch: 7.8 sec.
Memory usage: Available 7967.4 MB, Allocated 949.0 MB, Max allocated 1251.9 MB

Loading model from results/SPX500/CALF_sl_96_pl_48_id_ori/1/llm.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 4) (205, 48, 4)
test scaled -- mse:2.1266, mae:1.1266
Upscaling data and removing negatives...
test -- mse:42720, mae:166.93, rmsle: 0.043431 smape 3.4457


>>>> itr_no: 2, seed: 506 <<<<<<
Use GPU: cuda:0
model_id  ori
Experiments will be saved in results/SPX500/CALF_sl_96_pl_48_id_ori/2

Experiment begins at 2024-09-06 03:48:21

>>>>>>> start training :>>>>>>>>>>
train 1879
val 207
Loss function weights: 1.0 1.0 0.01
Orig-- ori
Epoch: 1 | Time: 4.54 s | Train Loss: 2.1082 Vali Loss: 1.8772
Validation loss decreased (inf --> 1.877189).  Saving model ...
Epoch: 2 | Time: 4.52 s | Train Loss: 1.8738 Vali Loss: 2.2316
EarlyStopping counter: 1 out of 3
Epoch: 3 | Time: 4.53 s | Train Loss: 2.0369 Vali Loss: 2.7832
EarlyStopping counter: 2 out of 3
Epoch: 4 | Time: 4.52 s | Train Loss: 2.6575 Vali Loss: 2.0904
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 03:48:48.
Model parameters: 180070448
Total memory: 7967.4 MB
Allocated memory: 954.2 MB
Max allocated memory: 1640.3 MB
Time per epoch: 6.7 sec.
Memory usage: Available 7967.4 MB, Allocated 954.2 MB, Max allocated 1640.3 MB

Loading model from results/SPX500/CALF_sl_96_pl_48_id_ori/2/llm.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 4) (205, 48, 4)
test scaled -- mse:1.6922, mae:1.0044
Upscaling data and removing negatives...
test -- mse:33612, mae:149.08, rmsle: 0.038212 smape 3.0631


>>>> itr_no: 3, seed: 608 <<<<<<
Use GPU: cuda:0
model_id  ori
Experiments will be saved in results/SPX500/CALF_sl_96_pl_48_id_ori/3

Experiment begins at 2024-09-06 03:48:50

>>>>>>> start training :>>>>>>>>>>
train 1879
val 207
Loss function weights: 1.0 1.0 0.01
Orig-- ori
Epoch: 1 | Time: 4.48 s | Train Loss: 2.0738 Vali Loss: 2.0682
Validation loss decreased (inf --> 2.068153).  Saving model ...
Epoch: 2 | Time: 4.53 s | Train Loss: 2.0574 Vali Loss: 1.6004
Validation loss decreased (2.068153 --> 1.600435).  Saving model ...
Epoch: 3 | Time: 4.54 s | Train Loss: 2.198 Vali Loss: 1.6996
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 4.49 s | Train Loss: 2.9604 Vali Loss: 2.288
EarlyStopping counter: 2 out of 3
Epoch: 5 | Time: 4.54 s | Train Loss: 3.9092 Vali Loss: 2.2563
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 03:49:29.
Model parameters: 180070448
Total memory: 7967.4 MB
Allocated memory: 950.8 MB
Max allocated memory: 1644.8 MB
Time per epoch: 7.8 sec.
Memory usage: Available 7967.4 MB, Allocated 950.8 MB, Max allocated 1644.8 MB

Loading model from results/SPX500/CALF_sl_96_pl_48_id_ori/3/llm.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 4) (205, 48, 4)
test scaled -- mse:2.1086, mae:1.1089
Upscaling data and removing negatives...
test -- mse:38764, mae:160.3, rmsle: 0.041538 smape 3.3219

Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='SPX500.csv', features='M', n_features=4, target='OT', freq='d', no_scale=False, seq_len=96, label_len=48, pred_len=48, top_k=5, num_kernels=6, d_model=768, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', dry_run=False, percent=100, model_id='ori', model='OFA', gpt_layers=6, is_gpt=1, patch_size=16, kernel_size=25, pretrain=1, freeze=1, stride=8, max_len=-1, hid_dim=16, tmax=20, n_scale=-1, use_gpu=True, enc_in=4, dec_in=4, c_out=4, task_name='long_term_forecast')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/SPX500/OFA_sl_96_pl_48_id_ori/1

Experiment begins at 2024-09-06 03:49:37

>>>>>>> start training :>>>>>>>>>>
train 1879
val 207
Epoch: 1 | Time: 4.49 s | Train Loss: 1.111 Vali Loss: 1.0605
Validation loss decreased (inf --> 1.060483).  Saving model ...
Epoch: 2 | Time: 4.26 s | Train Loss: 0.96891 Vali Loss: 1.0101
Validation loss decreased (1.060483 --> 1.010088).  Saving model ...
Epoch: 3 | Time: 4.25 s | Train Loss: 0.94562 Vali Loss: 1.0056
Validation loss decreased (1.010088 --> 1.005647).  Saving model ...
Epoch: 4 | Time: 4.26 s | Train Loss: 0.92028 Vali Loss: 1.023
EarlyStopping counter: 1 out of 3
Epoch: 5 | Time: 4.21 s | Train Loss: 0.90134 Vali Loss: 1.0581
EarlyStopping counter: 2 out of 3
Epoch: 6 | Time: 4.21 s | Train Loss: 0.87908 Vali Loss: 1.1914
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 03:50:15.
Model parameters: 82368048
Total memory: 7967.4 MB
Allocated memory: 353.5 MB
Max allocated memory: 1063.2 MB
Time per epoch: 6.3 sec.
Memory usage: Available 7967.4 MB, Allocated 353.5 MB, Max allocated 1063.2 MB

Loading model from results/SPX500/OFA_sl_96_pl_48_id_ori/1/llm.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 4) (205, 48, 4)
test scaled -- mse:1.7786, mae:0.98361
Upscaling data and removing negatives...
test -- mse:31053, mae:141.7, rmsle: 0.036973 smape 2.927


>>>> itr_no: 2, seed: 506 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/SPX500/OFA_sl_96_pl_48_id_ori/2

Experiment begins at 2024-09-06 03:50:16

>>>>>>> start training :>>>>>>>>>>
train 1879
val 207
Epoch: 1 | Time: 4.22 s | Train Loss: 1.1254 Vali Loss: 1.1273
Validation loss decreased (inf --> 1.127265).  Saving model ...
Epoch: 2 | Time: 4.26 s | Train Loss: 0.99595 Vali Loss: 0.96758
Validation loss decreased (1.127265 --> 0.967580).  Saving model ...
Epoch: 3 | Time: 4.29 s | Train Loss: 0.9418 Vali Loss: 0.98848
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 4.22 s | Train Loss: 0.92253 Vali Loss: 1.0145
EarlyStopping counter: 2 out of 3
Epoch: 5 | Time: 4.23 s | Train Loss: 0.90709 Vali Loss: 1.0042
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 03:50:45.
Model parameters: 82368048
Total memory: 7967.4 MB
Allocated memory: 355.2 MB
Max allocated memory: 1064.2 MB
Time per epoch: 5.8 sec.
Memory usage: Available 7967.4 MB, Allocated 355.2 MB, Max allocated 1064.2 MB

Loading model from results/SPX500/OFA_sl_96_pl_48_id_ori/2/llm.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 4) (205, 48, 4)
test scaled -- mse:1.7361, mae:0.95358
Upscaling data and removing negatives...
test -- mse:33648, mae:140.92, rmsle: 0.038355 smape 2.9037


>>>> itr_no: 3, seed: 608 <<<<<<
Use GPU: cuda:0
Experiments will be saved in results/SPX500/OFA_sl_96_pl_48_id_ori/3

Experiment begins at 2024-09-06 03:50:46

>>>>>>> start training :>>>>>>>>>>
train 1879
val 207
Epoch: 1 | Time: 4.24 s | Train Loss: 1.1143 Vali Loss: 1.0413
Validation loss decreased (inf --> 1.041275).  Saving model ...
Epoch: 2 | Time: 4.27 s | Train Loss: 0.97031 Vali Loss: 0.99847
Validation loss decreased (1.041275 --> 0.998475).  Saving model ...
Epoch: 3 | Time: 4.26 s | Train Loss: 0.93549 Vali Loss: 1.0064
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 4.23 s | Train Loss: 0.93652 Vali Loss: 1.0454
EarlyStopping counter: 2 out of 3
Epoch: 5 | Time: 4.24 s | Train Loss: 0.89683 Vali Loss: 1.0168
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 03:51:15.
Model parameters: 82368048
Total memory: 7967.4 MB
Allocated memory: 354.4 MB
Max allocated memory: 1064.2 MB
Time per epoch: 5.8 sec.
Memory usage: Available 7967.4 MB, Allocated 354.4 MB, Max allocated 1064.2 MB

Loading model from results/SPX500/OFA_sl_96_pl_48_id_ori/3/llm.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 4) (205, 48, 4)
test scaled -- mse:1.3751, mae:0.87959
Upscaling data and removing negatives...
test -- mse:29532, mae:134.15, rmsle: 0.035667 smape 2.746

Quadro RTX 4000
Args in experiment: Namespace(test=False, seed=2024, result_path='results', disable_progress=True, root_path='./data', data_path='SPX500.csv', features='M', n_features=4, target='OT', freq='d', no_scale=False, seq_len=96, label_len=48, pred_len=48, top_k=5, num_kernels=6, d_model=16, n_heads=4, e_layers=2, d_layers=1, d_ff=128, moving_avg=3, factor=1, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itrs=3, itr_no=None, train_epochs=10, batch_size=16, patience=3, learning_rate=0.001, des=None, loss='MSE', lradj='type1', gpu=0, use_multi_gpu=False, devices='0,1,2,3', dry_run=False, percent=100, model_id='ori', model='TimeLLM', patch_len=16, stride=8, prompt_domain=1, llm_model='GPT2', llm_dim=768, llm_layers=6, use_gpu=True, enc_in=4, dec_in=4, c_out=4, task_name='long_term_forecast', content=' "S&P 500 stock prices"')

>>>> itr_no: 1, seed: 648 <<<<<<
Use GPU: cuda:0
description:  "S&P 500 stock prices"
Experiments will be saved in results/SPX500/TimeLLM_sl_96_pl_48_id_ori/1

Experiment begins at 2024-09-06 03:51:23

>>>>>>> start training :>>>>>>>>>>
train 1879
val 207
Epoch: 1 | Time: 52.7 s | Train Loss: 3.1462 Vali Loss: 2.1101
Validation loss decreased (inf --> 2.110051).  Saving model ...
Epoch: 2 | Time: 50.9 s | Train Loss: 2.7794 Vali Loss: 1.7453
Validation loss decreased (2.110051 --> 1.745328).  Saving model ...
Epoch: 3 | Time: 50.8 s | Train Loss: 2.6823 Vali Loss: 1.7075
Validation loss decreased (1.745328 --> 1.707504).  Saving model ...
Epoch: 4 | Time: 50.9 s | Train Loss: 2.7633 Vali Loss: 2.0811
EarlyStopping counter: 1 out of 3
Epoch: 5 | Time: 51 s | Train Loss: 2.7548 Vali Loss: 1.8833
EarlyStopping counter: 2 out of 3
Epoch: 6 | Time: 51 s | Train Loss: 2.6176 Vali Loss: 1.9075
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 03:56:50.
Model parameters: 133434752
Total memory: 7967.4 MB
Allocated memory: 1126.4 MB
Max allocated memory: 5360.5 MB
Time per epoch: 54.5 sec.
Memory usage: Available 7967.4 MB, Allocated 1126.4 MB, Max allocated 5360.5 MB

Loading model from results/SPX500/TimeLLM_sl_96_pl_48_id_ori/1/llm.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 4) (205, 48, 4)
test scaled -- mse:2.3698, mae:1.1698
Upscaling data and removing negatives...
test -- mse:41755, mae:168.21, rmsle: 0.042638 smape 3.475


>>>> itr_no: 2, seed: 506 <<<<<<
Use GPU: cuda:0
description:  "S&P 500 stock prices"
Experiments will be saved in results/SPX500/TimeLLM_sl_96_pl_48_id_ori/2

Experiment begins at 2024-09-06 03:56:57

>>>>>>> start training :>>>>>>>>>>
train 1879
val 207
Epoch: 1 | Time: 52.6 s | Train Loss: 3.4021 Vali Loss: 1.9749
Validation loss decreased (inf --> 1.974888).  Saving model ...
Epoch: 2 | Time: 50.8 s | Train Loss: 2.9027 Vali Loss: 1.6823
Validation loss decreased (1.974888 --> 1.682329).  Saving model ...
Epoch: 3 | Time: 50.8 s | Train Loss: 3.0212 Vali Loss: 2.5227
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 50.9 s | Train Loss: 3.0435 Vali Loss: 2.3187
EarlyStopping counter: 2 out of 3
Epoch: 5 | Time: 51 s | Train Loss: 2.8516 Vali Loss: 2.0479
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 04:01:26.
Model parameters: 133434752
Total memory: 7967.4 MB
Allocated memory: 1128.5 MB
Max allocated memory: 5363.2 MB
Time per epoch: 53.8 sec.
Memory usage: Available 7967.4 MB, Allocated 1128.5 MB, Max allocated 5363.2 MB

Loading model from results/SPX500/TimeLLM_sl_96_pl_48_id_ori/2/llm.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 4) (205, 48, 4)
test scaled -- mse:1.6824, mae:1.0145
Upscaling data and removing negatives...
test -- mse:33600, mae:150.74, rmsle: 0.038134 smape 3.0972


>>>> itr_no: 3, seed: 608 <<<<<<
Use GPU: cuda:0
description:  "S&P 500 stock prices"
Experiments will be saved in results/SPX500/TimeLLM_sl_96_pl_48_id_ori/3

Experiment begins at 2024-09-06 04:01:31

>>>>>>> start training :>>>>>>>>>>
train 1879
val 207
Epoch: 1 | Time: 52.7 s | Train Loss: 3.1949 Vali Loss: 1.9426
Validation loss decreased (inf --> 1.942575).  Saving model ...
Epoch: 2 | Time: 50.8 s | Train Loss: 2.8397 Vali Loss: 1.76
Validation loss decreased (1.942575 --> 1.759970).  Saving model ...
Epoch: 3 | Time: 50.8 s | Train Loss: 2.7531 Vali Loss: 2.3515
EarlyStopping counter: 1 out of 3
Epoch: 4 | Time: 51 s | Train Loss: 2.819 Vali Loss: 2.6954
EarlyStopping counter: 2 out of 3
Epoch: 5 | Time: 51 s | Train Loss: 2.9776 Vali Loss: 2.4374
EarlyStopping counter: 3 out of 3
Early stopping

Training completed at 2024-09-06 04:05:59.
Model parameters: 133434752
Total memory: 7967.4 MB
Allocated memory: 1126.5 MB
Max allocated memory: 5363.2 MB
Time per epoch: 53.6 sec.
Memory usage: Available 7967.4 MB, Allocated 1126.5 MB, Max allocated 5363.2 MB

Loading model from results/SPX500/TimeLLM_sl_96_pl_48_id_ori/3/llm.pth

>>>>>>> testing :  <<<<<<<<<<<<<<<<<<<
test 205
Preds and Trues shape: (205, 48, 4) (205, 48, 4)
test scaled -- mse:2.2413, mae:1.149
Upscaling data and removing negatives...
test -- mse:39795, mae:166.83, rmsle: 0.041662 smape 3.4413

